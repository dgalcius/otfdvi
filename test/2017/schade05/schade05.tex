%BeginFileInfo
%%Publisher=DGBOOK
%%Project=SCHADE
%%Manuscript=SCHADE05
%%MS position=
%%Stage=202
%%TID=juraten
%%Pages=0
%%Format=2016
%%Distribution=vtex
%%Destination=PDF
%%PDF type=print
%%PDF.Maker=pdfwf_luatex
%%History1=2018.05.31 09:38
%EndFileInfo
\documentclass[]{schade}
\usepackage{book-aux-toc}
\usepackage[left]{vmkcol}
\usepackage{comment}
\usepackage{wrapfig}
\usepackage{array}
\usepackage{blkarray}
\usepackage{delarray}
%\usepackage{etoolbox}
%\usepackage{hhline}
%\usepackage{longtable}
\usepackage{enumerate}
%\usepackage{ifthen}
%\usepackage{latexsym}
%\usepackage[english]{varioref}
%\usepackage[normalem]{ulem}
\usepackage{mathrsfs}

\makeindex

\startlocaldefs
%author defs here:
\allowdisplaybreaks

\newlength{\tempwidth}
\newcommand{\alphaequation}[1][0]%
{\setcounter{saveequation}{\value{equation}}%
\setcounter{equation}{#1}%
\setlength{\savemathindent}{\mathindent}%
\setlength{\mathindent}{0pt}%
\renewcommand{\theequation}{\mbox{\alph{equation}}}}
\newcommand{\arabicequation}[1][0]%
{\setcounter{saveequation}{\value{equation}}%
\setcounter{equation}{#1}%
\setlength{\savemathindent}{\mathindent}%
\setlength{\mathindent}{0pt}%
\renewcommand{\theequation}{\mbox{\arabic{equation}}}}

\newenvironment{refequation}[1][0]% erzeugt eine Absatzformel mit Zeiger
%                                   auf die sp"ater Bezug genommen wird
{\alphaequation[#1]%
\begin{equation}}%
{\end{equation}%
\resetequation}% Wo ist das blo"s definiert?

\newcommand{\InitNtelBox}{
            \addtolength{\tempwidth}{-\mathindent}
            \addtolength{\tempwidth}{-15mm}}
            % Formelzeiger + Abstand ber"ucksichtigen!
\newenvironment{NtelPar}[1][2]%  teilt die Satzspiegelbreite gleichm"a"sig
{\setlength{\tempwidth}{\textwidth}%
\divide \tempwidth #1%
\begin{minipage}[t]{\tempwidth}$\Ds}%
{$\end{minipage}}


\def\itemg {\item[ ]}
\def\itemss {\smallskip \item}
\def\itemms {\medskip \item}
\def\itembs {\bigskip \item}
\def\itemp {\bigskip \item[$\bullet$]}
\def\itemb {\bigskip \item[$\Box$]}
\def\beq {\begin{equation}}
\def\eeq {\end{equation}}
\def\beqa {\begin{eqnarray}}
\def\eeqa {\end{eqnarray}}
\def\bc {\begin{center}}
\def\ec {\end{center}}

\newcolumntype{C}{>{$}c<{$}}
\newcolumntype{L}{>{$}l<{$}}
\newcolumntype{R}{>{$}r<{$}}
\newcommand {\sS} {\scriptsize}
\newcommand {\fnS}{\footnotesize}
\newcommand {\nS} {\normalsize}
\newcommand {\Ds} {\displaystyle}
\newcommand {\Ts} {\textstyle}
\newcommand {\Ss} {\scriptstyle}
\newcommand {\Sss}{\scriptscriptstyle}
\newcommand {\ol} {\overline}
%\newcommand {\ul} {\underline}
\newcommand {\Ul}[1]{\underline{#1}}
\renewcommand {\Vec}[1]{\settoheight{\tempwidth}{\ensuremath{#1}}%
                      \addtolength{\tempwidth}{.35ex}%
                      \ensuremath{\overrightarrow{#1\rule{0ex}{\tempwidth}}}}
\newcommand {\Lb} [1][4]{\linebreak[#1]}
\newcommand {\nLb}[1][4]{\nolinebreak[#1]}
\newcommand {\Pb} [1][4]{\pagebreak[#1]}
%%\newcommand {\Pb} [1][4]{\typeout{#1}}
\newcommand {\nPb}[1][4]{\nopagebreak[#1]}
\newcommand{\rr}{\raggedright}
\newcommand{\rl}{\raggedleft}
\newcommand{\fr}{\flushright}
\newcommand{\fl}{\flushleft}
\newcommand {\e}  {\varepsilon}
\newcommand {\p}  {\varphi}
\newcommand {\Dehn}[1]{\renewcommand{\baselinestretch}{#1}\selectfont}
\newcommand {\Dehna}[1]{\renewcommand{\arraystretch}{#1}\selectfont}

\newcommand{\pts}{\nLb \dots}
\newcommand{\dsP}{\cdot \! \cdot \:}
\newcommand{\tsP}{\cdot \! \cdot \! \cdot \,}
\newcommand{\Impl}[1][3ex]{\ensuremath{\hspace{#1} \Longrightarrow \hspace{#1}}}
\newcommand{\Equi}[1][3ex]{\ensuremath{\hspace{#1} \Longleftrightarrow \hspace{#1}}}
\newcommand{\dEqui}[1][3ex]{\ensuremath{\hspace{#1} :\Longleftrightarrow \hspace{#1}}}
\newcommand{\Subj}[1][3ex]{\ensuremath{\hspace{#1} \longrightarrow \hspace{#1}}}
\newcommand{\equal}{\ensuremath{\,\, =}}
\newcommand{\MaK}{{\it Ma}}
\newcommand{\PrK}{{\it Pr}}
\newcommand{\ReK}{{\it Re}}
%\newcommand{\Rho}{\ensuremath{\rho \:}}
\newcommand{\MaA}{\ensuremath{\MaK_\infty}}
\newcommand{\PrA}{\ensuremath{\PrK_\infty}}
\newcommand{\ReA}{\ensuremath{\ReK_\infty}}
\edef\int {\int\limits}
\edef\oint {\oint\limits}
\newcommand{\IDT}{\:}
\newcommand{\Int}[2][V]{\ensuremath{\int #2 \IDT \Dd #1}}
\newcommand{\IInt}[3]{\ensuremath{\int \! \! \int #1 \IDT \Dd #2 \IDT \Dd #3}}
\newcommand{\IIInt}[4]{\ensuremath{\int \! \! \int \! \! \int #1 \IDT
                                   \Dd #2 \IDT \Dd #3 \IDT \Dd #4}}
\newcommand{\bInt}[4][V]{\ensuremath{\int^{\ #3\ }_{\ #2\ } #4 \IDT \Dd #1}}
\newcommand{\bIInt}[7]{\ensuremath{\int^{\ #2\ }_{#1} \! \!
                               \int^{\ #4\ }_{\ #3\ } #5 \IDT \Dd #6 \IDT \Dd #7}}
\renewcommand{\iint}[1]{\ensuremath{\int \! \! \int #1 \IDT \Dd x \IDT \Dd y}}
\renewcommand{\iiint}[1]{\ensuremath{\int \! \! \int \! \! \int #1 \IDT
                                   \Dd x \IDT \Dd y \IDT \Dd z}}
\newcommand{\bint}[3]{\ensuremath{\int^{\ #2\ }_{#1} #3 \IDT \Dd x}}
\newcommand{\biint}[5]{\ensuremath{\int^{\ #2\ }_{#1} \! \!
                                   \int^{\ #4\ }_{\ #3\ } #5 \IDT \Dd x \IDT \Dd y}}
\newcommand{\biiint}[7]{\ensuremath{\int^{\ #2\ }_{#1} \! \!
                                    \int^{\ #4\ }_{\ #3\ } \! \!
                                    \int^{\ #6\ }_{\ #5\ } #7 \IDT
                                    \Dd x \IDT \Dd y \IDT \Dd z}}
\newcommand{\intb}[4][x]{\ensuremath{\int^{\ #3\ }_{\ #2\ } \Dd #1 \IDT #4}}
\newcommand{\iintb}[5]{\ensuremath{\int^{\ #2\ }_{#1} \Dd x
                                   \int^{\ #4\ }_{\ #3\ } \Dd y \IDT #5}}
\newcommand{\iiintb}[7]{\ensuremath{\int^{\ #2\ }_{#1} \Dd x
                                    \int^{\ #4\ }_{\ #3\ } \Dd y
                                    \int^{\ #6\ }_{\ #5\ } \Dd z \IDT #7}}
\newcommand{\Oint}[2][\Ul{A}]{\ensuremath{\oint #2 \IDT \Dd #1}}
\newcommand{\IntO}[1]{\ensuremath{\oint\limits_{\partial V} #1 \IDT \Dd \Ul{A}}}
\newcommand{\Into}[1]{\ensuremath{\oint\limits_{\partial V} #1 \IDT \Dd A}}
\newcommand{\IntV}[1]{\ensuremath{\int\limits_V #1 \IDT \Dd \Ul{V}}}
\newcommand{\Intv}[1]{\ensuremath{\int\limits_V #1 \IDT \Dd V}}
\newcommand{\vInt}[3] {\ensuremath{#1 \int\limits_{\ #2\ } #3 \IDT \Dd V}}
\newcommand{\ma}[1]{\mathring{#1}}
\newcommand{\Wie}{\widehat{=}}
\newcommand{\wie}{\; \; \Wie \; \;}
\newcommand{\ist}{\; \; = \; \;}
\newcommand{\soll}{\; \; := \; \;}
\newcommand{\Soll}{\; \; =: \; \;}
\newcommand{\lgleich}{= \;}
\newcommand{\rgleich}{\; =}
\newcommand{\lungleich}{\not= \;}
\newcommand{\rungleich}{\; \not=}
\newcommand{\HSnot}[1]{\settowidth{\tempwidth}{#1}%
\rlap{\hspace{.5\tempwidth}$\:\backslash$}#1}
%\newcommand{\neqr}{\HSnot =}
\ifdefined\HCode
\def\neqr{\HCode{<mo>=\string&\#x020E5;</mo>}}
\else % LaTeX
\newcommand{\neqr}{\HSnot\!=}
\fi
%
\newcommand{\Ak}{\mbox{,}\!\;}
\newcommand{\AvI}{\,}
\newcommand{\AvFi}{\;}
\newcommand{\AnI}{\ }
\newcommand{\Td}[1][\AnI]{\mbox{:}#1}
\newcommand{\Tk}[1][\AnI]{\mbox{,}#1}
\newcommand{\Tp}[1][\AnI]{\mbox{.}#1}
\newcommand{\Tsk}[1][\AnI]{\mbox{;}#1}
\newcommand{\TdnI}[1][\AnI]{\Td[#1]}
\newcommand{\TknI}[1][\AnI]{\Tk[#1]}
\newcommand{\TpnI}[1][\AnI]{\Tp[#1]}
\newcommand{\TsknI}[1][\AnI]{\Tsk[#1]}
\newcommand{\AknI}{\AvI \Tk \AnI}
\newcommand{\Tfd}{:\AnI}
\newcommand{\Tfk}{,\AnI}
\newcommand{\Tfp}{.\AnI}
\newcommand{\Tfsk}{;\AnI}
\newcommand{\Fd}{\mbox{:}}
\newcommand{\Fk}{\mbox{,}}
\newcommand{\Fp}{\mbox{.}}
\newcommand{\Fsk}{\mbox{;}}
\newcommand{\TDiff}[2]{\ensuremath{\Dd #1/\Dd #2}}
\newcommand{\DPDiff}[2]{\ensuremath{\frac{\Dd^2 #1}{\Dd #2^2}}}
\newcommand{\TpDiff}[2]{\ensuremath{\Pd #1/\Pd #2}}
\newcommand{\TSDiff}[2]{\ensuremath{\Sd #1/\Sd #2}}
\newcommand{\TdpDiff}[2]{\ensuremath{\Pd^2 #1/\Pd #2{}^2}}
\newcommand{\TgpDiff}[3]{\ensuremath{\Pd^2 #1/\Pd #2 \IDT \Pd #3}}
\newcommand{\Diff}[2]{\ensuremath{\frac{\Dd #1}{\Dd #2}}}
\newcommand{\pDiff}[2]{\ensuremath{\frac{\Pd #1}{\Pd #2}}}
\newcommand{\SDiff}[2]{\ensuremath{\frac{\Sd #1}{\Sd #2}}}
\newcommand{\dpDiff}[2]{\ensuremath{\frac{\Pd^2 #1}{\Pd #2^2}}}
\newcommand{\gpDiff}[3]{\ensuremath{\frac{\Pd^2 #1}{\Pd #2 \IDT \Pd #3}}}
\newcommand{\Pd}{\mr{\partial}}
\newcommand{\Sd}{\mr{D}\,}
\newcommand{\Dd}{\mr{d}\,}
\newcommand{\I}{\mr{i}}
\newcommand{\E}{\mbox{e}}
\newcommand{\IL}{\mr{L}}
\newcommand{\IR}{\mr{R}}
\newcommand{\R}{\Bbb{R}}
%\newcommand{\Sp}[1][]{\mr{Sp}^{#1}}
\newcommand{\Sp}[1][]{\mr{tr}^{#1\,}}
\newcommand{\tro}[1]{\ensuremath{\Sp #1}}
%\newcommand{\tr}[1]{\ensuremath{\Sp(#1)}}
\newcommand{\tr}[1]{\ensuremath{\Sp\!(#1)}}
\newcommand{\trn}[2]{\ensuremath{\Sp[#1]}#2}
%\newcommand{\trn}[2]{\ensuremath{\Sp[#1]}\!#2}
\renewcommand{\det}{\mr{det}\:}
\newcommand{\rot}[1][]{\mr{curl}_{#1} \,}
\newcommand{\Div}[1][]{\mr{div}_{#1} \,}
\newcommand{\grad}[1][]{\mr{grad}_{#1} \,}
\newcommand{\Grad}{\ensuremath{^{\circ}}} % T1encoding
\newcommand{\sina}[1][]{\sin^{#1} \alpha}
\newcommand{\sinb}[1][]{\sin^{#1} \beta}
\newcommand{\sinp}[1][]{\sin^{#1} \varphi}
\newcommand{\sint}[1][]{\sin^{#1} \vartheta}
\newcommand{\cosa}[1][]{\cos^{#1} \alpha}
\newcommand{\cosb}[1][]{\cos^{#1} \beta}
\newcommand{\cosp}[1][]{\cos^{#1} \varphi}
\newcommand{\cost}[1][]{\cos^{#1} \vartheta}
\newcommand{\tana}[1][]{\tan^{#1} \alpha}
\newcommand{\tanb}[1][]{\tan^{#1} \beta}
\newcommand{\tanp}[1][]{\tan^{#1} \varphi}
\newcommand{\tant}[1][]{\tan^{#1} \vartheta}
\newcommand{\cota}[1][]{\cot^{#1} \alpha}
\newcommand{\cotb}[1][]{\cot^{#1} \beta}
\newcommand{\cotp}[1][]{\cot^{#1} \varphi}
\newcommand{\cott}[1][]{\cot^{#1} \vartheta}
\newcounter{Stufe}
\newcommand{\Tilde}{\widetilde}
\newcommand{\Hat}{\widehat}
\newcommand{\Tensor}[1]{\addtocounter{Stufe}{-1}%
\ifthenelse{\value{Stufe}=0}%
{\ensuremath{\Ul{#1}}}%
{\ensuremath{\Ul{\Tensor{#1}}}}}
\newcommand{\T}[2][1]{\setcounter{Stufe}{#1}\Tensor{#2}}
%\newcommand{\Matrix}{\addtocounter{Stufe}{-1}%
%\ifthenelse{\value{Stufe}=0}%
%{_{\sim}}%
%{_{\Matrix}}}
%\newcommand{\M}[2][3]{\setcounter{Stufe}{#1}\ensuremath{\rlap{$\Matrix$}#2}}
\ifdefined\HCode
\newcommand{\M}[1]{\ensuremath{\mathop{#1}\limits_{\sim}}}
\else % LaTeX
\newcommand{\Matrix}{\addtocounter{Stufe}{-1}%
\ifthenelse{\value{Stufe}=0}%
{_{\Ds{\sim}}}%
{_{\Matrix}}}
\newcommand{\M}[2][3]{\setcounter{Stufe}{#1}\ensuremath{\rlap{\mbox{\raisebox{1.5pt}{$\Matrix$}}}#2}}
\fi
%
%
\newcommand{\TfB}{\ }
\newcommand{\TfE}{\ }
\newcommand{\Tfb}{}
\newcommand{\Tfe}{}
\newcommand{\Df}[1]{\ensuremath{\Ds #1}}
\newcommand{\Tf}[2][a]{%
\ifthenelse{\not\equal{#1}{e}}{\renewcommand{\Tfb}{\TfB}}{\renewcommand{\Tfb}{}}%
\ifthenelse{\not\equal{#1}{b}}{\renewcommand{\Tfe}{\TfE}}{\renewcommand{\Tfe}{}}%
\Tfb$#2$\Tfe}
\newcommand{\Uaf}[1]{\Af[{\Uf[\Df]}]{#1}}
\newcommand{\Uf}[2][]{${#1{#2}}$}
\newcommand{\Udf}[1]{\Df{{#1}}}
\newcommand{\Utf}[2][a]{\Tf[#1]{{#2}}}
\newcommand{\mc}[1]{\mathscr{#1}}
\newcommand{\mi}[1]{\mathit{#1}}
\newcommand{\mn}[1]{\mathnormal{#1}}
\newcommand{\mr}[1]{\mathrm{#1}}
\newcommand{\ms}[1]{{#1}} % ehemals \m
\newlength{\negAfpre}
\setlength{\negAfpre}{\parskip}
\addtolength{\negAfpre}{\smallskipamount}
\newlength{\negAfpost}
\setlength{\negAfpost}{\parskip}
\addtolength{\negAfpost}{\smallskipamount}
\newcommand{\Afpre}{\par \smallskip}
\newcommand{\Afpost}{\par \smallskip}
%\newcommand{\Af}[2][\Df]{\Afpre #1{#2} \Afpost}
\newcommand{\Af}[2][\Df]{\begin{align*}#1{#2}\end{align*}}

\newcommand{\womit}[2][=]{\stackrel{\mbox{\sS#2}}{#1}}
%\newcommand{\ue}[3][\,]{\rlap{$^{^{^{\Ss#1#2}}}$} #3}
%\newcommand{\un}[2]{\rlap{$_{_{_{_{_{_{\Ss#2}}}}}}$} #1}
\newcommand{\ue}[3][\,]{{\mathop{#3}\limits^{#1#2}}}
\newcommand{\un}[2]{{\mathop{#1}\limits_{#2}}}
%
\newcommand{\ParNo}[1]{\addvspace{\medskipamount}\noindent\textbf{#1}\ }
\newcommand{\ParNoo}[1]{\noindent\textbf{#1}\ }
\newcommand{\tT}{\mr{T}}
\newcommand {\ti}[2]{\renewcommand{\arraystretch}{.75}%
\smash{\begin{array}[t]{@{}>{\Ss}c@{}}#1\\\uparrow \\#2\end{array}}}
\newcommand{\oK}[2]{#1{\Ss<\:\!#2\:\!>}}
\newcommand{\UsW}{\mbox{etc.}}
%\newcommand{\UsW}{\mbox{usw.}}
\newcommand{\usw}[1][\Tk]{\crcr\multicolumn{2}{l}{\UsW #1}}
\newcommand{\USW}[1][\Tk]{\crcr\multicolumn{2}{@{}l}{\UsW #1}}
\newcommand{\Zref}[2]{(\ref{#1})$_{\mbox{\sS#2}}$}
\newcommand{\stimes}[1][\:]{#1\widetilde{\times}#1}
\newcommand{\const}{\mbox{const}}
%\newcommand{\oder}{\mbox{\quad oder\quad}}
\newcommand{\oder}{\mbox{\quad or\quad}}
%\newcommand{\und}{\mbox{\quad und\quad}}
\newcommand{\und}{\mbox{\quad and\quad}}
%\newcommand{\extr}{\mbox{Extremum}}
\newcommand{\extr}{\mbox{extremum}}
\newcommand{\xP}[1][1]{\enlargethispage{#1\baselineskip}}
\newcommand{\cP}[1][1]{\enlargethispage*{#1\baselineskip}}

\newcommand{\Spst}{\normalfont\bfseries --\normalfont\ }
\newenvironment{WdG_itemize}[1][\normalfont\bfseries --]%
{\begin{list}{#1}{\settowidth{\labelwidth}{#1}
               \def\Item{\item\rule{0ex}{\tempwidth}}
               \setlength{\topsep}{0pt}
               \setlength{\partopsep}{0pt}
               \setlength{\tempwidth}{3.6ex}
               \setlength{\parsep}{\parskip}
               \setlength{\partopsep}{0pt}
               \setlength{\itemsep}{0pt}
               \setlength{\leftmargin}{\labelwidth}
               \addtolength{\leftmargin}{\labelsep}
               \addtolength{\mathindent}{-\leftmargin}
} }{\end{list}}

\newcommand{\de}{\color{blue}}
\newcommand{\en}{\color{black}}

%{\er hello}
\usepackage{etoolbox}
\newtoggle{EN}
\toggletrue{EN}
%\togglefalse{EN}
\newtoggle{DE}
%\toggletrue{DE}   % uncomment this to display German
%\togglefalse{DE}

% the fancy do-it-all command
\newcommand{\geen}[2]{\iftoggle{DE}{\de#1}{}\iftoggle{EN}{\en #2}{}}
\endlocaldefs

%\HPROOF\SETGRID
\PROOF
%\CRC

\pubyear{2018}
\firstpage{221}
\lastpage{248}
%\openaccess



\begin{document}

\thisischapter{5}
\chapter{Representation of Tensor Functions}
\label{Kapitel-5}
%\begin{frontmatter}
%\end{frontmatter}


%% BODY

%\begin{mdframed}[style=theorem]
%\end{mdframed}

%\begin{mdframed}[style=equation]
%\end{mdframed}

%\begin{mdframed}[style=section]
%\end{mdframed}

%\begin{problem}
%\end{problem}


\section{\geen{Der Grundgedanke der Darstellungstheorie}
{The Basic Idea of the Representation of Tensor Functions}}
\label{Abschnitt-5.1}
\ParNoo{1.}
\geen{
Bei der Modellierung physikalischer Probleme stellt sich h"aufig die Aufgabe,
eine Funktion zwischen zwei Tensoren zu bestimmen.
Aus dem "ubergeordneten Zusammenhang kann man voraussetzen,
dass eine solche Funktion existiert,
die Funktion selbst ist jedoch unbekannt und
l"asst sich oft auch nur mithilfe von Experimenten ermitteln.
Typische Beispiele f"ur solche Funktionen sind
die Spannungs-Verzerrungs-Bezie"-hung \Tf{\T[2]{T} = \T[2]{f}( \T[2]{D} )}
f"ur einen elastischen Festk"orper,
bei der der (symmetrische) Spannungstensor~\T[2]{T}
von einem (ebenfalls symmetrischen) Verzerrungstensor~\T[2]{D} abh"angt,
oder die Flie"sbedingung \Tf{\sigma = f ( \T[2]{T} )}
in der Plastizit"atstheorie,
durch die die experimentell ermittelte Flie"sspannung $\sigma$
mit einem durch den Spannungstensor \T[2]{T}
beschriebenen dreidimensionalen Spannungszustand in Verbindung
gebracht werden muss.}{
Modeling a physical process often means to find a function
relating two tensors.
From the context we can assume that such a function exists,
but it is not known and it can often be determined only from experiments.
Typical examples of such functions are
the stress--displacement relation
\Tf{\T[2]{T} = \T[2]{f}(\T[2]{D})}
for an elastic solid,
where the (symmetric) stress tensor~\T[2]{T} depends on an (also  symmetric) displacement tensor~\T[2]{D}\TsknI[] or the
yield-stress condition \Tf{\sigma = f (\T[2]{T})}
in plasticity theory, which relates the experimentally determined
yield-stress
$\sigma$
to the three-dimensional stress state described by the stress tensor \T[2]{T}.
}

\geen{
Die Funktionen $f$ oder \T[2]{f} in den genannten Beispielen bezeichnet
man entsprechend der tensoriellen Stufe des Funktionswertes als skalarwertige
oder tensorwertige Tensorfunktionen.
\index{Tensorfunktion!skalarwertige@, skalarwertige}\index{Tensorfunktion!tensorwertige@, tensorwertige}%
\index{skalarwertige Funktion}\index{tensorwertige Funktion}%
Entgegen dem Anschein k"onnen diese Funktionen\Lb nicht beliebige Formen annehmen,
sondern sie sind gewissen Einschr"ankungen unterworfen,
die aus den Transformationseigenschaften des Tensors resultieren:
\index{Tensorfunktion}%
In einem bestimmten kartesischen Koordinatensystem gelte f"ur die Koordinaten
\Tf{ \sigma = f ( T_{ij} )} bzw.
\Tf{ T_{ij} = f_{ij} ( D_{kl} )\Tk[]}
dann muss man bei einem Wechsel des Koordinatensystems beim
Einsetzen der transformierten Koordinaten $\Tilde{T}_{ij}$
in die Funktion $f$ denselben Skalar \Tf{ \sigma = f( \Tilde{T}_{ij} ) }
bzw. beim Einsetzen der transformierten Koordinaten $\Tilde{D}_{kl}$
in die Funktion \T[2]{f} die transformierten Koordinaten
\Tf{ \Tilde{T}_{ij} = f_{ij}( \Tilde{D}_{kl} ) } erhalten.
Wenn man die beteiligten Tensoren als polar voraussetzt,
folgt daraus unter Verwendung der Transformationsgleichungen (\ref{2.17}),
dass f"ur die skalarwertige Funktion $f$ gelten muss}{
The functions $f$ or \T[2]{f} in the examples are called, according to the order of the tensors, scalar-valued or tensor-valued tensor functions.
\index{tensor function!scalar-valued@, scalar-valued}%
\index{tensor function!tensor-valued@, tensor-valued}%
\index{scalar-valued function}%
\index{tensor-valued function}%
Contrary to what one may expect, these functions cannot have
an arbitrary form, because the transformation properties of a
\index{tensor function}tensor impose certain restrictions. For example, if in a given Cartesian coordinate system
\Tf{ \sigma = f ( T_{ij} )} and
\Tf{ T_{ij} = f_{ij} ( D_{kl} ),}
then, under a change of the coordinate system,
substituting the transformed coordinates
$\tilde{T}_{ij}$ into the function $f$ must result in the same scalar \Tf{\sigma = f (\tilde{T}_{ij})\TknI[]}
and similarly, substituting the transformed coordinates
$\tilde{D}_{kl}$ into the function \T[2]{f} must give the transformed coordinates
\Tf{\tilde{T}_{ij} = f_{ij} (\Tilde{D}_{kl})\TpnI[]}
If we assume that the tensors are polar,
then, according to the transformation equations (\ref{2.17}), a~scalar-valued function $f$ must satisfy
}
%
\[%\begin{refequation}
\label{5.1a}
 f( T_{mn} ) = f( \alpha_{im} \: \alpha_{jn} \: T_{ij} ) \Fk
 \tag{a}
\]%\end{refequation}%
%
\geen{
\index{Invarianzbedingung f\"ur Tensorfunktionen}%
\index{Tensorfunktionen!Invarianzbedingung@, Invarianzbedingung f"ur}%
w"ahrend die tensorwertige Funktion \T[2]{f} durch die Bedingung}{
\index{invariance condition for tensor functions}%
\index{tensor functions!invariance condition@, invariance condition for}and a tensor-valued function \T[2]{f} is restricted by the condition
}
%
\[%\begin{refequation}[1]
\label{5.1b}
\alpha_{mi} \: \alpha_{nj}\:  f_{mn}( D_{kl} ) =
f_{ij}( \alpha_{pk} \: \alpha_{ql} \: D_{pq} ) \Fp
\tag{b}
\]%\end{refequation}%
%
%\geen{eingeschr"ankt ist.}{}

\ParNo{2.}
\geen{
Wie man Bedingungen der Art (\ref{5.1a}) oder (\ref{5.1b}) auswertet und zur
Konstruktion von Funktionen zwischen Tensoren nutzt,
ist Gegenstand der Darstellungstheorie. Der Grundgedanke besteht darin,
dass eine skalarwertige Funktion nicht von einzelnen Tensorkoordinaten
abh"angen kann, sondern nur von Kombinationen,
die selbst Skalare und damit invariant gegen"uber einer
Koordinatentransformation sind;
deshalb nennt man die Darstellungstheorie manchmal auch Invariantentheorie.
\index{Darstellungstheorie}\index{Invariantentheorie}%
Wir werden zeigen, dass f"ur einen symmetrischen Tensor wie den
Spannungstensor \T[2]{T} die drei Grundinvarianten \tro{ \T[2]{T} }, \tro{ \T[2]{T}^2 } und
$\tro{ \T[2]{T}^3 }$
einen vollst"andigen Satz von Invarianten bilden,
deshalb kann man die skalarwertige Funktion~$f$ in unserem Beispiel allein als
Funktion der drei Grundinvarianten
(oder eines nach Abschnitt~\ref{Abschnitt-3.15}
dazu "aquivalenten Satzes wie der Eigenwerte oder der Hauptinvarianten)
darstellen:}{
How to evaluate conditions of the type (\ref{5.1a}) or (\ref{5.1b}) and how to use them to construct functions relating  tensors is the subject of a theory called the theory of the  representation of tensor functions.
The basic idea is
that a scalar-valued function cannot depend on single tensor coordinates,
but only on scalar combinations of tensor coordinates,
which are clearly invariant under a coordinate transformation.
This explains why, instead of the theory of the representation of tensor functions, we also speak of the theory of invariants.
\index{representation!of tensor functions}%
\index{tensor functions!representation@, representation of}%
\index{invariant!tensor functions}%
\index{tensor functions! invariant@, invariant}%
We will show that for any symmetric tensor, such as the stress tensor~\T[2]{T}\TknI[] the three basic invariants
\tro{ \T[2]{T} }, \tro{ \T[2]{T}^2\TknI[]} and
$\tro{\T[2]{T}^3}$
form a complete set of invariants,
so we can write the scalar-valued function~$f$ in our example as a function of the three basic invariants
(or, according to Section~\ref{Abschnitt-3.15}, of another equivalent set of invariants, such as the eigenvalues or the main invariants), so we have
}
%
\Af{ \sigma =
f ( \tro{ \T[2]{T} } \Tk \tro{ \T[2]{T}^2 } \Tk \tro{ \T[2]{T}^3 } ) \Tp}

\geen{Die vorstehenden "Uberlegungen lassen sich grunds"atzlich auch auf
tensorwertige Funktionen "ubertragen, wenn man daraus durch
Einf"uhrung eines Hilfstensors skalarwertige Funktionen macht.
In unserem Beispiel wird dann aus
\Tf{ \T[2]{T} = \T[2]{f}( \T[2]{D} )} vor"ubergehend}{
These considerations also apply to
tensor-valued functions, if we make them scalar-valued
by introducing an auxiliary tensor.
In our example, then
\Tf{ \T[2]{T} = \T[2]{f}( \T[2]{D} )} gives temporarily
}
%
\Af{ \T[2]{T} \dsP \T[2]{H} = f( \T[2]{D}\Tk \T[2]{H} ) \Tk}
%
\geen{wobei die Abh"angigkeit vom Hilfstensor \T[2]{H}
so beschaffen sein muss, dass dieser sich am Ende wieder herausk"urzen l"asst.}{
where the auxiliary tensor \T[2]{H} must appear in such a way
that it can be canceled out in the end.
}

\geen{
Bevor wir uns den Einzelheiten zuwenden, m"ussen wir jedoch zuerst kl"aren,
wie viele Tensorinvarianten f"ur eine noch genauer zu definierende
vollst"andige Darstellung erforderlich sind.
In diesem Zusammenhang brauchen wir eine Verallgemeinerung der
Cayley-Hamilton-Gleichung,
da sie in ihrer Grundform nur Potenzen desselben Tensors verkn"upft,
w"ahrend in der Darstellungstheorie auch Produkte verschiedener Tensoren
auftreten k"onnen.
Da in den physikalischen Anwendungen meist polare Tensoren auftreten,
beschr"anken wir uns im Rest des Kapitels auf polare Tensoren
(Skalare und Vektoren als Tensoren nullter bzw. erster Stufe eingeschlossen),
ohne das jedes Mal zu betonen.
Falls wir im Einzelfall auch axiale Tensoren betrachten
oder die Unterscheidung von polaren und axialen Tensoren
f"ur die Argumentation wichtig ist, werden wir ausdr"ucklich darauf hinweisen.}{
Before we turn to the details, we have to clarify how many tensor invariants
are needed  for a (yet to be defined) representation to be complete.
For this we first need to generalize the
Cayley--Hamilton theorem,
which in its basic version relates only powers of the same tensor,
while in the theory of the representation of tensor functions,
products of different tensors often appear as well.
Since the tensors in physical applications are often polar, we restrict ourselves to polar tensors for the rest of this chapter
(this includes scalars and vectors as tensors of order zero and one,
respectively), without mentioning this every time.
In the few cases where we consider axial tensors,
or if the distinction between polar and axial tensors is important for the argument, we will mention this explicitly.
}

\ParNo{3.}
\geen{
Aus Sicht der Physik hat die Darstellungstheorie eine
"ahnliche Bedeutung wie die Dimensionsanalyse.
In der Physik rechnet man mit physikalischen Gr"o"sen,
die als Produkt zwischen einem Zahlenwert und einer Einheit gebildet sind;
eine Gr"o"se selbst ist jedoch unabh"angig von der
gew"ahlten Einheit, d.\,h. wenn man die Einheit wechselt,
"andert sich entsprechend der Zahlenwert. Diese Eigenschaft "ubertr"agt sich
auf Gleichungen zwischen physikalischen Gr"o"sen (man spricht hierbei auch von
dimensioneller Homogenit"at); daraus folgt insbesondere, dass physikalische
Gr"o"sen nicht durch beliebige Funktionen verkn"upft sein k"onnen,
sondern nur durch solche, die die Bedingung der Invarianz gegen einen
Einheitenwechsel erf"ullen.
Diese Invarianz gegen einen Einheitenwechsel hat bei Tensoren
ihr Gegenst"uck in den Beziehungen (\ref{5.1a}) oder (\ref{5.1b}), die
aus der Forderung nach Invarianz gegen einen Wechsel des Koordinatensystems
resultieren.}{
In physics, representation of tensor functions
is as important as dimensional analysis. Physical quantities are the product of a numerical value and a unit,
but the quantity itself is independent of the chosen %system o
unit, i.\,e.\ if we change the %system of
unit,
the numerical value changes correspondingly.
This property carries over to equations between physical quantities, where we say that an equation must be dimensionally homogeneous. Specifically,
it follows that physical quantities cannot be related by
an arbitrary function,
but only by functions which are invariant under a change of units.
This condition of invariance under a change of units has its analog
for tensors in the relations (\ref{5.1a}) and (\ref{5.1b}),
which result from the requirement that an equation must be invariant under a change of the coordinate system.
}

\geen{
In der Dimensionsanalyse wertet man die Invarianzforderung
bei einem Einheitenwechsel dadurch aus, dass man die Beziehungen zwischen
den Gr"o"sen durch Beziehungen zwischen dimensionslosen Kombinationen
dieser Gr"o"sen (also solchen, die keine Einheit ben"otigen) ersetzt,
und gelangt so in vielen F"allen zu einer Beschr"ankung der
zul"assigen Funktionen.
In der Darstellungstheorie hat diese Vorgehensweise ihre Entsprechung
im "Ubergang zu skalaren Kombinationen von Tensorkoordinaten
(d.\,h. Tensorinvarianten),
wodurch man ebenfalls die zul"assigen Funktionen einschr"anken kann.}{
In dimensional analysis we use the condition of invariance under a change
of units to replace relations between quantities by relations between
dimensionless combinations of quantities (which do not need units). In many cases,
this leads to restrictions on  the permissible functions.
Analogously, in the theory of the representation of tensor functions,
we change to scalar combinations of tensor coordinates (i.\,e. tensor invariants), which again leads to
restrictions on the permissible functions.}
\vfill\eject

\section{\geen{Die verallgemeinerte Cayley-Hamilton-Gleichung}{Generalized Cayley--Hamilton Theorem}}
\label{Abschnitt-5.2}

\ParNoo{1.}
\geen{
Nach (\ref{1.20}) ist \Tf{ \delta_{pqrs}^{ijkl} = 0\Tk[]} mit (\ref{1.19}) folgt}{
According to (\ref{1.20}), \Tf{ \delta_{pqrs}^{ijkl} = 0\Tk[]} and then (\ref{1.19}) gives
}
%
\Af{
  \begin{array}|{@{\ }cccc@{\ }}|
  \delta_{ip} &  \delta_{iq} & \delta_{ir} & \delta_{is} \\
  \delta_{jp} &  \delta_{jq} & \delta_{jr} & \delta_{js} \\
  \delta_{kp} &  \delta_{kq} & \delta_{kr} & \delta_{ks} \\
  \delta_{lp} &  \delta_{lq} & \delta_{lr} & \delta_{ls}
 \end{array} = 0 \Tp}
%
\geen{"Uberschiebung mit $a_{pi} \: b_{qj} \: c_{rk}$ ergibt,
wenn man $a_{pi}$ in die erste Zeile, $b_{qj}$ in die zweite Zeile
und $c_{rk}$ in die dritte Zeile multipliziert,}{
Contraction with $a_{pi} \: b_{qj} \: c_{rk}$ gives,
if we multiply the first row by $a_{pi}$, the second row by $b_{qj}$, and the third row by $c_{rk}$,
}
\Af{
  \begin{array}|{@{\ }cccc@{\ }}|
  a_{pp} & a_{pq} & a_{pr} & a_{ps} \\
  b_{qp} & b_{qq} & b_{qr} & b_{qs} \\
  c_{rp} & c_{rq} & c_{rr} & c_{rs} \\
  \delta_{lp} &  \delta_{lq} & \delta_{lr} & \delta_{ls}
 \end{array} = 0 \Tp}
%
\geen{Wir entwickeln diese Determinante nach der letzten Zeile:}{
We expand this determinant along the last row, so we obtain
}
\Af{
\begin{array}{@{\,}r@{\,}l@{\,}}
 - \delta_{lp}
  \begin{array}|{@{\ }ccc@{\ }}|
  a_{pq} & a_{pr} & a_{ps} \\
  b_{qq} & b_{qr} & b_{qs} \\
  c_{rq} & c_{rr} & c_{rs}
 \end{array}
+
&
\delta_{lq}
  \begin{array}|{@{\ }ccc@{\ }}|
  a_{pp} & a_{pr} & a_{ps} \\
  b_{qp} & b_{qr} & b_{qs} \\
  c_{rp} & c_{rr} & c_{rs}
 \end{array}\\
&
{}- \delta_{lr}
  \begin{array}|{@{\ }ccc@{\ }}|
  a_{pp} & a_{pq} & a_{ps} \\
  b_{qp} & b_{qq} & b_{qs} \\
  c_{rp} & c_{rq} & c_{rs} \\
 \end{array}
+ \delta_{ls}
  \begin{array}|{@{\ }ccc@{\ }}|
  a_{pp} & a_{pq} & a_{pr} \\
  b_{qp} & b_{qq} & b_{qr} \\
  c_{rp} & c_{rq} & c_{rr}
 \end{array} = 0 \Tp
\end{array}}
%
\geen{Das Multiplizieren von $\delta_{lp}\TknI$ $\delta_{lq}$ bzw. $\delta_{lr}$
in die erste, zweite bzw. dritte Zeile der ersten drei Determinanten f"uhrt zu}{
Multiplying $\delta_{lp}\TknI$ $\delta_{lq}\TknI$ and $\delta_{lr}$
into the first, second, and third row of the first three determinants,
respectively, gives
}
%
\Af{\begin{array}{*{2}{@{\,}l}}
 -
  \begin{array}|{@{\ }ccc@{\ }}|
  a_{lq} & a_{lr} & a_{ls} \\
  b_{qq} & b_{qr} & b_{qs} \\
  c_{rq} & c_{rr} & c_{rs}
 \end{array}
 +
  \begin{array}|{@{\ }ccc@{\ }}|
  a_{pp} & a_{pr} & a_{ps} \\
  b_{lp} & b_{lr} & b_{ls} \\
  c_{rp} & c_{rr} & c_{rs}
 \end{array}
 -&
  \begin{array}|{@{\ }ccc@{\ }}|
  a_{pp} & a_{pq} & a_{ps} \\
  b_{qp} & b_{qq} & b_{qs} \\
  c_{lp} & c_{lq} & c_{ls} \
 \end{array}\\
&{}+ \delta_{ls}
  \begin{array}|{@{\ }ccc@{\ }}|
  a_{pp} & a_{pq} & a_{pr} \\
  b_{qp} & b_{qq} & b_{qr} \\
  c_{rp} & c_{rq} & c_{rr}
 \end{array} = 0 \Tp
 \end{array}}
%
\geen{Die Entwicklung der einzelnen Determinanten ergibt}{We expand each of the determinants and obtain
}
%
\Af{
 \begin{array}{@{}>{\rule{0ex}{2ex}}l}
 - a_{lq} \: b_{qr} \: c_{rs}
 - a_{lr} \: b_{qs} \: c_{rq}
 - a_{ls} \: b_{qq} \: c_{rr}
 + a_{ls} \: b_{qr} \: c_{rq}
 + a_{lr} \: b_{qq} \: c_{rs}
 + a_{lq} \: b_{qs} \: c_{rr}
\\
 {}+ a_{pp} \: b_{lr} \: c_{rs}
 + a_{pr} \: b_{ls} \: c_{rp}
 + a_{ps} \: b_{lp} \: c_{rr}
 - a_{ps} \: b_{lr} \: c_{rp}
 - a_{pr} \: b_{lp} \: c_{rs}
 - a_{pp} \: b_{ls} \: c_{rr}
\\
 {}- a_{pp} \: b_{qq} \: c_{ls}
 - a_{pq} \: b_{qs} \: c_{lp}
 - a_{ps} \: b_{qp} \: c_{lq}
 + a_{ps} \: b_{qq} \: c_{lp}
 + a_{pq} \: b_{qp} \: c_{ls}
 + a_{pp} \: b_{qs} \: c_{lq}
\\
 {}+ \delta_{ls}
   \left(
      a_{pp} \: b_{qq} \: c_{rr}
    + a_{pq} \: b_{qr} \: c_{rp}
    + a_{pr} \: b_{qp} \: c_{rq}
    - a_{pr} \: b_{qq} \: c_{rp}
    - a_{pq} \: b_{qp} \: c_{rr}
   \right.
\\
\multicolumn{1}{r}{
\rule{0ex}{2ex}
\left.
    {}- a_{pp} \: b_{qr} \: c_{rq}
   \right)
 = 0 \Tp}
 \end{array}}
%
\geen{"Ubersetzt in die symbolische Schreibweise lautet diese Beziehung}{
Translating this expression into symbolic notation gives
}
%
\Af{
 \begin{array}{@{}>{\rule[-2ex]{0ex}{0ex}}l}
 - \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{c}
 - \T[2]{a} \cdot \T[2]{c} \cdot \T[2]{b}
 - \T[2]{a} \; \tro{\T[2]{b}} \; \tro{\T[2]{c}}
 + \T[2]{a} \; \tr{\T[2]{b} \cdot \T[2]{c}}
 + \T[2]{a} \cdot \T[2]{c} \; \tro{\T[2]{b}}
 + \T[2]{a} \cdot \T[2]{b} \; \tro{\T[2]{c}}\\
 {}+ \T[2]{b} \cdot \T[2]{c} \; \tro{\T[2]{a}}
 + \T[2]{b} \; \tr{\T[2]{a} \cdot \T[2]{c}}
 + \T[2]{b} \cdot \T[2]{a} \; \tro{\T[2]{c}}
 - \T[2]{b} \cdot \T[2]{c} \cdot \T[2]{a}
 - \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{c}
 - \T[2]{b} \; \tro{\T[2]{a}} \; \tro{\T[2]{c}}\\
 {}- \T[2]{c} \; \tro{\T[2]{a}} \; \tro{\T[2]{b}}
 - \T[2]{c} \cdot \T[2]{a} \cdot \T[2]{b}
 - \T[2]{c} \cdot \T[2]{b} \cdot \T[2]{a}
 + \T[2]{c} \cdot \T[2]{a} \; \tro{\T[2]{b}}
 + \T[2]{c} \; \tr{\T[2]{a} \cdot \T[2]{b}}
 + \T[2]{c} \cdot \T[2]{b} \; \tro{\T[2]{a}}\\
 {}+ \T[2]{\delta} \left(
     \tro{\T[2]{a}} \; \tro{\T[2]{b}} \; \tro{\T[2]{c}}
   + \tr{\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{c}}
   + \tr{\T[2]{a} \cdot \T[2]{c} \cdot \T[2]{b}}
   - \tr{\T[2]{a} \cdot \T[2]{c}} \, \tro{\T[2]{b}}
   - \tr{\T[2]{a} \cdot \T[2]{b}} \, \tro{\T[2]{c}}
 \right.\\
\multicolumn{1}{r}{  \left. {}
   - \tr{\T[2]{b} \cdot \T[2]{c}} \, \tro{\T[2]{a}}
 \right) = \T[2]{0} \Tp}
 \end{array}}
%
\geen{\index{Cayley-Hamilton-Gleichung!verallgemeinerte@, verallgemeinerte}Ordnet man diese Terme und vertauscht die Vorzeichen,
erh"alt man schlie"slich}{Finally,
\index{Cayley-Hamilton theorem!generalized@, generalized}
\index{generalized!Cayley-Hamilton theorem@ Cayley-Hamilton theorem}%
after sorting these terms and reversing the signs, we obtain
}
%
  \begin{equation}
    \label{cayley_hamilton_verallgemeinert}
\begin{array}{@{}>{\rule[-2ex]{0ex}{0ex}}l}
    \T[2]{a} \cdot \left( \T[2]{b} \cdot \T[2]{c} + \T[2]{c} \cdot \T[2]{b} \right)
  + \T[2]{b} \cdot \left( \T[2]{a} \cdot \T[2]{c} + \T[2]{c} \cdot \T[2]{a} \right)
  + \T[2]{c} \cdot \left( \T[2]{a} \cdot \T[2]{b} + \T[2]{b} \cdot \T[2]{a} \right)\\
{}  - \left( \T[2]{b} \cdot \T[2]{c} + \T[2]{c} \cdot \T[2]{b} \right) \tro{\T[2]{a}}
  -  \left( \T[2]{a} \cdot \T[2]{c} + \T[2]{c} \cdot \T[2]{a} \right) \tro{\T[2]{b}}
  -  \left( \T[2]{a} \cdot \T[2]{b} + \T[2]{b} \cdot \T[2]{a} \right) \tro{\T[2]{c}} \\
{}  + \left[ \tro{\T[2]{b}} \; \tro{\T[2]{c}} - \tr{\T[2]{b} \cdot \T[2]{c}} \right] \T[2]{a}
  + \left[ \tro{\T[2]{a}} \; \tro{\T[2]{c}} - \tr{\T[2]{a} \cdot \T[2]{c}} \right] \T[2]{b}\\
\multicolumn{1}{r}{\rule[-2ex]{0ex}{0ex}
{} + \left[ \tro{\T[2]{a}} \; \tro{\T[2]{b}} - \tr{\T[2]{a} \cdot \T[2]{b}} \right] \T[2]{c}}\\
{} - \left[ \tro{\T[2]{a}} \; \tro{\T[2]{b}} \; \tro{\T[2]{c}}
    + \tr{\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{c}}
    + \tr{\T[2]{c} \cdot \T[2]{b} \cdot \T[2]{a}}       \right.\\
\multicolumn{1}{r}{
   \left. {} - \tr{\T[2]{b} \cdot \T[2]{c}} \; \tro{\T[2]{a}}
   - \tr{\T[2]{a} \cdot \T[2]{c}} \; \tro{\T[2]{b}}
   - \tr{\T[2]{a} \cdot \T[2]{b}} \; \tro{\T[2]{c}}
   \right] \T[2]{\delta}
    =  \T[2]{0} \Fp}
 \end{array}
  \end{equation}

\ParNo{2.}
\geen{
Wenn wir \Tf{ \T[2]{a} = \T[2]{b} = \T[2]{c}} setzen,
vereinfacht sich (\ref{cayley_hamilton_verallgemeinert}) zu}{
If we set \Tf{ \T[2]{a} = \T[2]{b} = \T[2]{c}\Tk[]} then (\ref{cayley_hamilton_verallgemeinert}) simplifies to
}
%
\Af{
   6 \, \T[2]{a}^3 - 6 \, \tro{\T[2]{a}} \; \T[2]{a}^2
 + 3  \left[ \trn{2}{\T[2]{a}} - \tro{\T[2]{a}^2} \right] \T[2]{a}
 - \left[
    \trn{3}{\T[2]{a}} - 3 \, \tro{\T[2]{a}} \; \tro{\T[2]{a}^2} + 2 \, \tro{\T[2]{a}^3}
   \right] \T[2]{\delta} = 0 \Tp}
%
\geen{
\index{Cayley-Hamilton-Gleichung}
Nach Division durch $-6$ und Beachtung von (\ref{3.93}) ist das die
Cayley-Hamil\-ton-Gleichung (\ref{3.88});
wir bezeichnen (\ref{cayley_hamilton_verallgemeinert})
deshalb als verallgemeinerte Cay\-ley-Hamilton-Gleichung.}{
\index{Cayley-Hamilton theorem}%
After dividing by $-6$ and using (\ref{3.93}) we see that this is the Cayley--Hamilton theorem (\ref{3.88}),
so we call (\ref{cayley_hamilton_verallgemeinert})
the generalized Cayley--Hamilton theorem.
}

\ParNo{3.}
\geen{F"ur einige "Uberlegungen in der Darstellungstheorie
kommt es nur auf die erste Zeile in (\ref{cayley_hamilton_verallgemeinert}) an,
deshalb f"uhren wir hierf"ur eine Abk"urzung ein:}{
For the representation of tensor functions, the first row of (\ref{cayley_hamilton_verallgemeinert}) is of particular importance, so we introduce the following symbol:}
\begin{equation}
  \label{zeile_1}
  \T[2]{\Sigma}:=
    \T[2]{a} \cdot \left( \T[2]{b} \cdot \T[2]{c} + \T[2]{c} \cdot \T[2]{b} \right)
  + \T[2]{b} \cdot \left( \T[2]{a} \cdot \T[2]{c} + \T[2]{c} \cdot \T[2]{a} \right)
  + \T[2]{c} \cdot \left( \T[2]{a} \cdot \T[2]{b} + \T[2]{b} \cdot \T[2]{a} \right) \Fp
\end{equation}
\geen{
Aus (\ref{cayley_hamilton_verallgemeinert}) folgt dann durch Aufl"osung nach der ersten Zeile}{
Then we obtain from (\ref{cayley_hamilton_verallgemeinert}), after solving for the first row, i.\,e.
}
\begin{equation}
  \label{Sigma}
    \begin{array}{@{}l@{}c@{}>{\rule[-2ex]{0ex}{0ex}}l}
    \T[2]{\Sigma}
    & {} = {} &
{}    \left( \T[2]{b} \cdot \T[2]{c} + \T[2]{c} \cdot \T[2]{b} \right) \tro{\T[2]{a}}
    + \left( \T[2]{a} \cdot \T[2]{c} + \T[2]{c} \cdot \T[2]{a} \right) \tro{\T[2]{b}}
    + \left( \T[2]{a} \cdot \T[2]{b} + \T[2]{b} \cdot \T[2]{a} \right) \tro{\T[2]{c}}
 \\ & &
{}  - \left[ \tro{\T[2]{b}} \; \tro{\T[2]{c}} - \tr{\T[2]{b} \cdot \T[2]{c}} \right] \T[2]{a}
    - \left[ \tro{\T[2]{a}} \; \tro{\T[2]{c}} - \tr{\T[2]{a} \cdot \T[2]{c}} \right] \T[2]{b}
 \\ & &
\multicolumn{1}{r}{\rule[-2ex]{0ex}{0ex}
{} - \left[ \tro{\T[2]{a}} \; \tro{\T[2]{b}} - \tr{\T[2]{a} \cdot \T[2]{b}} \right] \T[2]{c}}
\\ & &
{} + \left[ \tro{\T[2]{a}} \; \tro{\T[2]{b}} \; \tro{\T[2]{c}}
    + \tr{\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{c}}
    + \tr{\T[2]{c} \cdot \T[2]{b} \cdot \T[2]{a}} \right.
 \\ & &
\multicolumn{1}{r}{
   \left. {} - \tr{\T[2]{b} \cdot \T[2]{c}} \; \tro{\T[2]{a}}
   - \tr{\T[2]{a} \cdot \T[2]{c}} \; \tro{\T[2]{b}}
   - \tr{\T[2]{a} \cdot \T[2]{b}} \; \tro{\T[2]{c}}
   \right] \T[2]{\delta} \Fp}
 \end{array}
\end{equation}



\section{\geen{Invarianten von Vektoren und Tensoren zweiter Stufe}{Invariants of Vectors and Second-Order Tensors}}
\label{Abschnitt-5.3}

\geen{Wir erinnern noch einmal an unsere Definition einer Invariante:
\index{Invariante}%
Eine Invariante ist ein aus Tensorkoordinaten gebildeter Skalar,
der sich (bei polaren Skalaren) bei einem Wechsel des Koordinatensystems nicht
"andert bzw. (bei axialen Skalaren) h"ochstens sein Vorzeichen wechselt.
In "Ubereinstimmung mit unserer Festlegung in Abschnitt~\ref{Abschnitt-5.1}
werden wir in diesem Kapitel jedoch nur polare Skalare
als Invarianten bezeichnen.}{
Let us recall our definition of an invariant.\index{invariants} An invariant is a scalar combination of tensor coordinates which (for polar scalars)
does not change under a change of the  coordinate system, or (for axial scalars) at most its sign changes.
Following our definition from Section~\ref{Abschnitt-5.1}, however, we use the term invariant in this chapter only for polar scalars.
}

\begin{problem} % Aufgabe 1
\label{U5.1}
\mbox{}

\noindent
\geen{
Man zeige mithilfe der Transformationsgleichungen (\ref{2.17})
bzw. (\ref{2.18}), dass \Uf{ \tro{\T[2]{T}} } und \Uf{ \tro{\T[2]{T}^2} }
Invarianten eines (polaren oder axialen) Tensors zweiter Stufe sind.}{
Show, using the transformation equations (\ref{2.17}) or
(\ref{2.18}), that \Uf{ \tro{\T[2]{T}} } and \Uf{ \tro{\T[2]{T}^2} } are invariants of a (polar or axial) second-order tensor.
}
\end{problem}

\geen{In Abschnitt~\ref{Abschnitt-3.15} haben wir mit den Eigenwerten, den
Hauptinvarianten und den Grundinvarianten bereits drei verschiedene S"atze von
je drei Invarianten eines Tensors zweiter Stufe kennengelernt.
Die Elemente jedes dieser drei S"atze sind voneinander unabh"angig,
d.\,h. kein Element eines Satzes kann aus den beiden anderen Elementen
dieses Satzes berechnet werden; aber die drei S"atze sind
nicht unabh"angig voneinander, d.\,h. wenn man die Invarianten eines Satzes kennt,
kann man daraus die Invarianten der anderen S"atze bestimmen.
Wir wissen allerdings nicht, ob die drei Invarianten eines Satzes auch
einen vollst"andigen Satz bilden, d.\,h. ob es noch weitere Invarianten
gibt, die sich daraus nicht berechnen lassen.
Einen vollst"andigen Satz von Invarianten nennt man eine Basis (der Invarianten).}{
In Section~\ref{Abschnitt-3.15}, we saw that the eigenvalues,
the main invariants, and the basic invariants are three different sets of three invariants of a second-order tensor.
The elements of each of these three sets are independent of each other, i.\,e.\ no element of a set can be computed from the other two elements of the same set; but the three sets are
not independent of each other, i.\,e.\ if we know the invariants of one set, then we can compute the invariants of the other sets.
However, it is not clear
if the three invariants of a set form a complete set, i.\,e.\ if further invariants exist, which cannot be computed from these invariants.
A complete set of invariants is called a basis (of invariants).
}

\geen{Am einfachsten erh"alt man Invarianten durch geeignete Verj"ungungen oder
"Uberschiebungen von Tensorkoordinaten, die Grundinvarianten eines
Tensors zweiter Stufe sind ein Beispiel hierf"ur.
Solche Invarianten sind gleichzeitig Polynome aus Tensorkoordinaten,
wir nennen sie polynomische Invarianten.\index{Invariante!polynomische@, polynomische}
In der Darstellungstheorie beschr"ankt man sich meist auf solche
polynomischen Invarianten und f"uhrt daf"ur besondere Bezeichnungen ein:
Wenn eine polynomische Invariante als Polynom anderer polynomischer Invarianten
darstellbar ist, nennt man sie (bez"uglich dieser Invarianten) reduzibel,
andernfalls irreduzibel; \index{irreduzibel}\index{reduzibel}%
\index{Invariante!reduzible@, reduzible}\index{Invariante!irreduzible@, irreduzible}%
ein vollst"andiger Satz irreduzibler Invarianten,
d.\,h. ein Satz, der es erlaubt, alle anderen polynomischen Invarianten als
Polynom dieser irreduziblen Invarianten
auszudr"ucken, hei"st Integrit"atsbasis.\index{Integrit\"atsbasis}
Es ist aber auch m"oglich, dass polynomische Invarianten durch ein Polynom verkn"upft
sind, ohne dass sich daraus eine Invariante \emph{als Polynom} der anderen
gewinnen l"asst, solche Polynome nennt man
Syzygien\footnote{griech. Paar, aus \emph{syn} (zusammen) und \emph{zygon}
(Joch), also eigentlich das Zusammengejochte, z.\,B. in der Astronomie
Oberbegriff f"ur Konjunktion und Opposition zweier beweglicher Sterne,
in der Metrik die Aneinanderreihung zweier gleicher Versf"u"se.}\index{Syzygie},
ein Beispiel ist die Gleichung (\ref{2.45})
zwischen den Skalarprodukten der sechs Vektoren
\T{a}, \T{b}, \T{c}, \T{d}, \T{e} und~\T{f}.}{
The easiest way to compute invariants is from appropriate
contractions of tensor coordinates.
An example are the main invariants of a second-order tensor.
Such invariants are polynomials of tensor coordinates and we call them polynomial invariants.\index{invariants!polynomial@, polynomial}
In the theory of the representation of tensor functions we usually consider only
polynomial invariants and we use the following terms. A polynomial invariant which can be written as a polynomial of other polynomial invariants is called reducible (with respect to these invariants);
otherwise it is called irreducible.\index{irreducible}\index{reducible}%
\index{invariants!reducible@, reducible}
\index{invariants!irreducible@, irreducible}
A complete set of irreducible invariants,
i.\,e.\ a set such that all other polynomial invariants can be written in terms of these irreducible invariants, is called  an integrity basis.\index{integrity basis}
However, it is also possible that polynomial invariants are related by a polynomial and yet none of them can be written \emph{as a polynomial} of the other invariants.
Such polynomials are called syzygies;\footnote{Greek: pair
(from \emph{syn} [together] and \emph{zygon} [yoke]), i.\,e.\  literally, a pair coupled together by a yoke, e.\,g.\ in astronomy a generic term for conjunction and
opposition of two planets, and in poetry the juxtaposition of two
equal metrical feet.}\index{syzygy} an example is equation (\ref{2.45}) for the
scalar products of the six vectors
\T{a}, \T{b}, \T{c}, \T{d}, \T{e}, and~\T{f}.
}

\geen{Die Eigenwerte eines Tensors zweiter Stufe sind ein Beispiel
f"ur nichtpolynomische Invarianten. Sie berechnen sich nach Abschnitt \ref{3.11.2}
aus einer kubischen Gleichung, deren Koeffizienten polynomische Invarianten sind,
lassen sich aber selbst nicht als Polynome von Tensorkoordinaten schreiben.}{
An example of nonpolynomial invariants are the eigenvalues of a
second-order tensor.
We computed them in  Section~\ref{3.11.2} from a cubic equation  whose
coefficients are polynomial invariants,
but an eigenvalue cannot be written as a polynomial of tensor coordinates.
}

\geen{Die polynomischen Invarianten sind eine Untermenge aller Invarianten eines Tensors.
Da zur Bildung reduzibler Invarianten nur Polynome zugelassen sind, kann es trotzdem
vorkommen, dass es mehr irreduzible Invarianten als
unabh"angige\index{Invariante!unabhangige@, unabh"angige} gibt,
m.\,a.\,W. dass eine Integrit"atsbasis mehr Elemente enth"alt als eine Basis.}{
The polynomial invariants are a subset of all the invariants of a tensor.
Since reducible invariants are polynomial combinations of tensor coordinates, it may still happen that there are
more irreducible invariants than
independent invariants\index{invariants!independent@, independent}.
In other words, an integrity basis can contain more elements than a basis.
}

\subsection{\geen{Invarianten von Vektoren}{Invariants of Vectors}}
\label{5.3.1}

\geen{Ein einzelner Vektor \T{u} besitzt nur eine einzige irreduzible Invariante,
n"amlich sein Quadrat $u_i \: u_i\TpnI$}{
A single vector \T{u} has only one irreducible invariant,
i.\,e.\  its square $u_i \: u_i\TpnI$
}

\geen{Aus zwei Vektoren \T{u} und \T{v} kann man insgesamt drei irreduzible
Invarianten bilden:}{
From two vectors \T{u} and \T{v} we can
form a total of three irreducible invariants:}
\begin{itemize}
 \item
 \geen{
  die Quadrate $u_i \: u_i$ und $v_i \: v_i$ der einzelnen Vektoren,}{
  the squares $u_i \: u_i$ and $v_i \: v_i$ of each of the vectors\xch{;}{,}}
 \item
  \geen{das Skalarprodukt $u_i \: v_i\TpnI$}{the scalar product $u_i \: v_i\TpnI$}
\end{itemize}
%
\geen{
\index{Simultaninvariante}\index{Invariante!Simultan-@, Simultan-}
Das Skalarprodukt ist ein Beispiel f"ur eine so genannte Simultaninvariante,
darunter versteht man eine Invariante, die aus Koordinaten verschiedener
Tensoren gebildet ist.}{
\index{simultaneous invariant}\index{invariants!simultaneous@, simultaneous}The scalar product is an example of a so-called simultaneous invariant,
i.\,e.\ an invariant which consists of coordinates of different tensors.
}

\geen{
Mit zunehmender Anzahl der Vektoren steigt die Anzahl der irreduziblen
Invarianten schnell an. Bei drei Vektoren \T{u}, \T{v}, \T{w} gibt es bereits
sieben voneinander unabh"angige skalare Kombinationen:}{
As the number of vectors increases, the number of irreducible invariants quickly increases.
For three vectors \T{u}, \T{v}, \T{w},
there are already seven independent scalar combinations:
}

\begin{itemize}
 \item
 \geen{
  die Quadrate $u_i u_i\TknI v_i v_i\TknI w_i \: w_i$ der einzelnen Vektoren,}{
  the squares $u_i u_i\TknI v_i v_i\TknI w_i \: w_i\TknI[]$ of each of the vectors\xch{;}{,}}
 \item
 \geen{
  die Skalarprodukte $u_i  v_i\TknI u_i w_i\TknI v_i w_i\TknI[]$
  die sich aus jeweils zwei der Vektoren bilden lassen,}{
  the scalar products $u_i v_i\TknI u_i w_i\TknI v_i w_i\TknI[]$
  of each of the vector pairs\xch{;}{,}}
 \item
 \geen{
  das Spatprodukt $\varepsilon_{ijk}  \: u_i  \: v_j  \: w_k$
  aller drei Vektoren.}{
  the triple product $\varepsilon_{ijk}  \: u_i  \: v_j  \: w_k$
  of all three vectors.}
\end{itemize}
\geen{
Das Spatprodukt spielt dabei eine besondere Rolle:
Wenn die Vektoren \T{u}, \T{v}, \T{w} polar sind,
sind auch die ersten sechs Invarianten polare Skalare, das Spatprodukt
ist dagegen wegen des $\varepsilon$-Tensors ein axialer Skalar.
Ein axialer Skalar z"ahlt jedoch nach unserer Verabredung
nicht zu den Invarianten, d.\,h. aus drei (polaren) Vektoren
\T{u}, \T{v}, \T{w} lassen sich insgesamt sechs
irreduzible Invarianten bilden.}{
The triple product plays a particular role. If the vectors \T{u}, \T{v}, \T{w} are polar,
then the first six invariants are also polar scalars,
whereas the triple product is, due to the $\varepsilon$-tensor,
an axial scalar.
However, according to our definition,
an axial scalar is no invariant,
i.\,e.\ from three (polar) vectors
\T{u}, \T{v}, \T{w},
we can form six irreducible invariants.
}

\subsection{\geen{Unabh"angige Invarianten eines Tensors zweiter Stufe}{Independent Invariants of a Second-Order Tensor}}
\label{5.3.2}

\ParNoo{1.}
\geen{
Wir wollen zun"achst die Anzahl
der unabh"angigen Invarianten eines beliebigen Tensors \T[2]{T}
zweiter Stufe bestimmen. Dazu zerlegen wir ihn in seinen symmetrischen Anteil
\T[2]{S} und seinen antimetrischen Anteil \T[2]{A}.
Der antimetrische Anteil \T[2]{A} l"asst sich nach Abschnitt~\ref{Abschnitt-3.3}
durch den zugeh"origen Vektor \T{b} ausdr"ucken, dann gilt:}{
Let us first determine the number of independent invariants of an arbitrary second-order tensor \T[2]{T}.
To this end, we decompose the tensor into its symmetric part
\T[2]{S} and its antimetric part \T[2]{A}.
We can write the antimetric part \T[2]{A}, according to Section~\ref{Abschnitt-3.3}, in terms of its corresponding vector \T{b}, so we have
}
\Af{
 T_{ij} = S_{ij} + A_{ij} = S_{ij} + \varepsilon_{ijk} \: b_{k} \Tp
}
%
\geen{Wenn wir \T[2]{T} als polar voraussetzen, sind \T[2]{S} und \T[2]{A} ebenfalls polar,
und \T{b} ist axial.}{
If we assume that \T[2]{T} is polar,
then \T[2]{S} and \T[2]{A} are also polar and \T{b} is axial.
}

\geen{
Die Zerlegung in einen symmetrischen und einen antimetrischen Anteil ist nach
Abschnitt~\ref{Abschnitt-2.6}~Nr.\,7 unabh"angig vom Koordinatensystem.
Wir k"onnen deshalb auch ein Hauptachsensystem von \T[2]{S}
zur Koordinatendarstellung des vollst"andigen Tensors \T[2]{T} nutzen
und erhalten dann f"ur seine Koordinatenmatrix:}{
The decomposition into a symmetric part and an antimetric part is, according to Section~\ref{Abschnitt-2.6},~No.\,7,
independent of the coordinate system.
So we can also use the principal axis system of \T[2]{S} to represent
the coordinates of the full tensor \T[2]{T}, and
thus we have for its coordinate matrix
}
%
\Af{
  \Tilde{T}_{ij} =
  \begin{array}({@{}ccc@{}})
   \sigma_1 & 0 & 0 \\
   0 & \sigma_2 & 0 \\
   0 & 0 & \sigma_3
  \end{array}
  +
  \begin{array}({@{}ccc@{}})
    \multicolumn{1}{c}{0} & \beta_3 & -\beta_2 \\
   -\beta_3 & \multicolumn{1}{c}{0} &  \beta_1 \\
    \beta_2 & -\beta_1 & \multicolumn{1}{c}{0}
  \end{array} \Tk
}
\vspace{-.5cm}
\begin{equation}
 \label{Zerlegung_symmetrisch_antimetrisch_hauptachsensystem}
  \Tilde{T}_{ij} =
  \begin{array}({@{}rrr@{}})
    \sigma_1 & \beta_3  & -\beta_2 \\
   -\beta_3  & \sigma_2 &  \beta_1 \\
    \beta_2  & -\beta_1 &  \sigma_3
  \end{array} \Fp
\end{equation}
%
\geen{Darin sind die $\sigma_i$ die (nicht notwendigerweise verschiedenen)
Eigenwerte von \T[2]{S} und die $\beta_i$ die Koordinaten von \T{b}
im Hauptachsensystem von \T[2]{S}.
Die Eigenwerte $\sigma_i$ haben wir bereits in Abschnitt~\ref{3.11.2}
als Invarianten kennengelernt,
und die Koordinaten von \T{b} k"onnen wir als Projektionen des
Vektors \T{b} auf die Hauptachsen von \T[2]{S} interpretieren;
damit sind aber auch die $\beta_i$ Invarianten, denn die Richtung der
Hauptachsen von \T[2]{S} und die Richtung von \T{b} sind
unabh"angig vom Koordinatensystem.}{
Here the $\sigma_i$ are the (not necessarily different)
eigenvalues of \T[2]{S} and the $\beta_i$ are the coordinates of \T{b} in the principal axis system of \T[2]{S}.
We already know from Section~\ref{3.11.2}
that the eigenvalues $\sigma_i$ are invariants.
The coordinates of \T{b} can be interpreted as
the projections of the vector \T{b}
onto the principal axes of \T[2]{S};
hence the $\beta_i$ are also invariants,
because the direction of the principal axes of \T[2]{S}
and the direction of \T{b} are independent of the coordinate system.
}

\geen{
Das Koordinatensystem des symmetrischen Anteils \T[2]{S} ist also
ein ausgezeichnetes Koordinatensystem auch des Tensors \T[2]{T}:
Die Koordinatenmatrix von \T[2]{T} ist dann (und nur dann)
bis auf die Hauptdiagonale antimetrisch.}{
Thus the principal axis system of the symmetric part \T[2]{S} is a distinguished coordinate system of the tensor \T[2]{T};
the coordinate matrix of \T[2]{T} is then (and only then)
antimetric, except on the main diagonal.
}

\geen{
Wir kommen also zu dem Ergebnis, dass ein Tensor zweiter Stufe
im allgemeinen Fall sechs unabh"angige Invarianten besitzt; mehr als sechs
unabh"angige Invarianten kann es nicht geben, da der Tensor
durch die Angabe der $\sigma_i$ und $\beta_i$ eindeutig bestimmt ist.
\index{Invariante!unabhangige@, unabh"angige}%
Allerdings sind diese Invarianten keine polynomischen Invarianten,
d.\,h. sie lassen sich nicht als Polynome von Tensorkoordinaten
in einem beliebigen kartesischen Koordinatensystem darstellen.}{
We conclude that, in general, a second-order tensor has six independent invariants; more than six
independent invariants are not possible, because the tensor
is uniquely determined by the $\sigma_i $ and $\beta_i $.
\index{invariants!independent@, independent}%
However, these invariants are not polynomial invariants,
i.\,e.\ they cannot be written as polynomials
of tensor coordinates in an arbitrary Cartesian coordinate system.
}

\ParNo{2.}
\geen{
Wenn der symmetrische Anteil \T[2]{S} mehrfache Eigenwerte besitzt,
verringert sich die Anzahl der unabh"angigen Invarianten.}
{If the symmetric part \T[2]{S} has multiple eigenvalues,
the number of independent invariants is reduced.
}

\geen{
Bei einem doppelten Eigenwert w"ahlen wir die Eigenebene als $x\Ak y$-Ebene
des Hauptachsensystems und die $x$-Achse so, dass \T{b} in der $x\Ak z$-Ebene
liegt. Dann hat der Tensor \T[2]{T} die Koordinatenmatrix}{
For an eigenvalue of multiplicity two, we choose the  $x\Ak y$-plane as the eigenplane of the principal axis system and we put the $x$-axis such that \T{b} lies in the
$x\Ak z$-plane.
Then the tensor \T[2]{T} has the coordinate matrix}
%
\Af{
  \Tilde{T}_{ij} =
  \begin{array}({@{}ccc@{}})
   \sigma_1 & 0 & 0 \\
   0 & \sigma_1 & 0 \\
   0 & 0 & \sigma_3
  \end{array}
  +
  \begin{array}({@{}ccc@{}})
    0 & \beta_3 & 0 \\
   -\beta_3 & 0 &  \beta_1 \\
    0 & -\beta_1 & 0
  \end{array}
  =
  \begin{array}({@{}crc@{}})
    \sigma_1 & \beta_3  &  \multicolumn{1}{c}{0}   \\
   -\beta_3  & \sigma_1 &  \beta_1 \\
        0    & -\beta_1 &  \sigma_3
  \end{array}\Tk}
%
\geen{es gibt also nur vier unabh"angige Invarianten.}{i.\,e.\ only four independent invariants exist.}

\geen{
Im Fall eines dreifachen Eigenwerts ist jedes Koordinatensystem
zugleich Hauptachsensystem von \T[2]{S}.
Wir k"onnen deshalb die $x$-Achse in die Richtung von \T{b} legen
und erhalten f"ur \T[2]{T} die Koordinatenmatrix}{
For an eigenvalue of multiplicity three, every coordinate system is also a principal axis system of \T[2]{S}.
So we can put the $x$-axis in the direction of \T{b} and we get for the
coordinate matrix of \T[2]{T}}
%
\Af{
  \Tilde{T}_{ij} =
  \begin{array}({@{}ccc@{}})
   \sigma & 0 & 0 \\
   0 & \sigma & 0 \\
   0 & 0 & \sigma
  \end{array}
  +
  \begin{array}({@{}ccc@{}})
    0 & 0 & 0 \\
    0 & 0 &  \beta \\
    0 & -\beta & 0
  \end{array}
  =
  \begin{array}({@{}crc@{}})
    \sigma &    0   &     0   \\
        0  & \sigma &  \beta \\
        0  & -\beta &  \sigma
  \end{array} \Tk}
%
\geen{d.\,h. \T[2]{T} besitzt nur zwei unabh"angige Invarianten.}{i.\,e.\ \T[2]{T} has only two independent invariants.}
%\Pb
\goodbreak

\ParNo{3.}
\geen{
Im Spezialfall eines symmetrischen Tensors ist \Tf{\T[2]{A}=\T[2]{0}\Tp[]}
\index{Tensor!symmetrischer@, symmetrischer}\index{symmetrischer (Anteil eines) Tensor(s)}%
Ein symmetrischer Tensor besitzt also maximal drei unabh"angige Invarianten,
n"amlich wenn alle seine Eigenwerte verschieden sind. Bei einem doppelten
Eigenwert gibt es nur zwei, bei einem dreifachen Eigenwert nur eine
unabh"angige Invariante.}{
If the tensor is symmetric, we have
\Tf{\T[2]{A} = \T[2]{0} \Tp[]}
\index{tensor!symmetric@, symmetric}\index{symmetric!tensor@  (part of a) tensor}%
A symmetric tensor has at most three independent invariants, namely if all its eigenvalues are different. If the tensor has an eigenvalue of multiplicity two, it has only two invariants; and if it has an eigenvalue of multiplicity three, only one invariant exists.
}

\geen{
Im Spezialfall eines antimetrischen Tensors ist \Tf{\T[2]{S}=\T[2]{0}\Tp[]}
\index{Tensor!antimetrischer@, antimetrischer}\index{antimetrischer (Anteil eines) Tensor(s)}%
Ein antimetrischer Tensor besitzt deshalb nur eine unabh"angige
Invariante, n"amlich das Quadrat des zugeh"origen Vektors.}{
If the tensor is antimetric, we have \Tf{\T[2]{S}=\T[2]{0} \Tp[]}
\index{tensor!antimetric@, antimetric}
\index{antimetric!(part of a) tensor}%
An antimetric tensor has only one independent
invariant, i.\,e.\ the square of the corresponding vector.
}

\geen{
Als dritten Spezialfall betrachten wir orthogonale Tensoren.
\index{Tensor!orthogonaler@, orthogonaler}\index{orthogonaler!Tensor@ Tensor}%
In einem Koordinatensystem, in dem die $z$-Achse mit der
Dreh- bzw. Drehspiegelungsachse zusammenf"allt,
hat ein orthogonaler Tensor nach (\ref{3.69})
bzw. (\ref{3.70}) die Koordinatenmatrix}{
In addition, we consider orthogonal tensors.
\index{tensor!orthogonal@, orthogonal}\index{orthogonal!tensor@ tensor}%
In a coordinate system in which the $z$-axis is the axis of
rotation or the axis of rotary reflection, an orthogonal tensor has,
according to (\ref{3.69}) or (\ref{3.70}), the coordinate matrix}
%
\Af{
 \Tilde{R}_{ij} =
  \begin{array}({@{}rrr@{}})
  \cost & -\sint & 0 \\
  \sint & \cost & 0 \\
  0 & 0 & \pm 1
 \end{array} \Tp
}
\geen{Das ist zugleich die Darstellung im Hauptachsensystem
des symmetrischen Anteils, und wir erkennen, dass es mit dem
Drehwinkel $\vartheta$ nur eine einzige unabh"angige Invariante gibt.}{
This is a representation of a tensor with respect to the principal axis system of its symmetric part, so we note that with the angle $\vartheta$ only one independent invariant exists.
}

\subsection{\geen{Irreduzible Invarianten von Tensoren zweiter Stufe}{Irreducible Invariants of Second-Order Tensors}}
\label{5.3.3}

\ParNoo{1.}
\geen{
Irreduzible Invarianten sind definitionsgem"a"s
polynomische Invarianten, die durch geeignete Verj"ungungen oder
"Uberschiebungen von Tensorkoordinaten entstehen.
Speziell bei Tensoren zweiter Stufe lassen sich polynomische
Invarianten\index{Invariante!polynomische@, polynomische} auch als Spur einer Folge von Skalarprodukten zwischen diesen
Tensoren ausdr"ucken, deshalb stellen wir f"ur solche Spur-Ausdr"ucke zun"achst
einige Hilfss"atze zusammen, die wir im weiteren Verlauf ben"otigen werden:}{
Irreducible invariants are by definition polynomial invariants,
which are obtained from appropriate contractions of tensor coordinates.
For second-order tensors, we can write the polynomial invariants\index{invariants!polynomial@, polynomial} also
as the trace of a sequence of scalar products between these tensors.
We begin with a few statements, which we need later:\vspace*{2pt}
}

\begin{enumerate}[I.]
%\addtolength{\mathindent}{-\leftmargin}
 \item
 \geen{
  Die Spur einer Folge von Skalarprodukten von Tensoren zweiter Stufe
  "andert sich nicht, wenn man die Reihenfolge der Faktoren
  in den Skalarprodukten zyklisch vertauscht,}{
  The trace of a sequence of scalar products of second-order
  tensors does not change if we cyclically permute the order
  of the factors in the scalar products,
i.\,e.   }
\Af{
\tr{\T[2]{a} \cdot \T[2]{b} \cdot \ldots \cdot \T[2]{c} \cdot \T[2]{d}}
   = a_{ij} \: b_{jk} \, \xch{\,\cdots\,}{\ldots} \, c_{mn} \: d_{ni}
   = b_{jk} \, \xch{\,\cdots\,}{\ldots} \, c_{mn} \: d_{ni} \: a_{ij}
   = \tr{\T[2]{b} \cdot \ldots \cdot \T[2]{c} \cdot \T[2]{d} \cdot \T[2]{a}} \Tk}
%
  \geen{also gilt:}{so we have}
  \begin{equation}
   \label{Spur_zyklisch}
      \tr{\T[2]{a} \cdot \T[2]{b} \cdot \ldots \cdot \T[2]{c} \cdot \T[2]{d}}
    = \tr{\T[2]{b} \cdot \ldots \cdot \T[2]{c} \cdot \T[2]{d} \cdot \T[2]{a}}
    = \xch{\,\cdots\,}{\ldots}
    = \tr{\T[2]{d} \cdot \T[2]{a} \cdot \T[2]{b} \cdot \ldots \cdot \T[2]{c}} \Fp
  \end{equation}

 \item % 2.
 \geen{
  Die Spur einer Folge von Skalarprodukten von Tensoren zweiter Stufe
  "andert sich nicht, wenn man jeden Faktor transponiert und zugleich
  die Reihenfolge vertauscht,}{
  The trace of a sequence of scalar products of second-order
  tensors does not change if we transpose each factor,
  while reversing the order of the factors,
i.\,e.   }
%
\Af{
 \begin{array}{@{}>{\rule{0ex}{3ex}}l}
   \tr{\T[2]{a} \cdot \T[2]{b} \cdot \ldots \cdot \T[2]{c} \cdot \T[2]{d}}
   = a_{ij} \: b_{jk} \, \xch{\,\cdots\,}{\ldots} \, c_{mn} \: d_{ni}\\
   = d_{in}^{\tT} \: c_{nm}^{\tT} \, \xch{\,\cdots\,}{\ldots} \, b_{kj}^{\tT} \: a_{ji}^{\tT}
= \tr{\T[2]{d}^{\tT} \cdot \T[2]{c}^{\tT} \cdot \ldots \cdot \T[2]{b}^{\tT} \cdot \T[2]{a}^{\tT} } \Tk
 \end{array}}
%
  \geen{also gilt:}{so we have}
  \begin{equation}
   \label{Spur_transponiert}
     \tr{\T[2]{a} \cdot \T[2]{b} \cdot \ldots \cdot \T[2]{c} \cdot \T[2]{d}}
   = \tr{\T[2]{d}^{\tT} \cdot \T[2]{c}^{\tT} \cdot \ldots \cdot \T[2]{b}^{\tT} \cdot \T[2]{a}^{\tT} } \Fp
  \end{equation}
%
  \geen{Speziell wenn alle Faktoren gleich sind, folgt daraus}{
  In particular, if all factors are equal, we have
  }
  \begin{equation}
   \label{Spur_Potenz_transponiert}
     \tro{\T[2]{a}^n}
   = \tro{(\T[2]{a}^{\tT} )^n}
   = \tro{(\T[2]{a}^n)^{\tT}} \Fk
  \end{equation}
%
  \geen{wobei $n$ eine nat"urliche Zahl ist.}{where $n$ is a natural number.}

 \item % 3.
 \geen{Die Spur eines Skalarprodukts aus einem symmetrischen Tensor \Tf{\T[2]{s} = \T[2]{s}^{\tT}}
  und einem antimetrischen Tensor \Tf{\T[2]{a} = -\T[2]{a}^{\tT}} ist null.}{The trace of a scalar product of a symmetric tensor
  \Tf{\T[2]{s} = \T[2]{s}^{\tT}}
   and an antimetric tensor \Tf{\T[2]{a} =-\T[2]{a}^{\tT}} is zero.
   }

  \geen{Zun"achst gilt}{Since}
%
\[%\begin{refequation}%[1]
\label{5.3a}%
   ( \T[2]{s} \cdot \T[2]{a} )^{\tT}
   \womit{(\mbox{\ref{2.35}})}
   \T[2]{a}^{\tT} \cdot \T[2]{s}^{\tT} = -\T[2]{a} \cdot \T[2]{s}
\tag{a}
\]%\end{refequation}%
%
\geen{und weiterhin}{and also}
\Af{ \tr{ \T[2]{s} \cdot \T[2]{a} }
   \womit{(\ref{Spur_Potenz_transponiert})}
   \tro{ ( \T[2]{s} \cdot \T[2]{a} )^{\tT} }
   \womit{(\ref{5.3a})}
   -\tr{ \T[2]{a} \cdot \T[2]{s} }
   \womit{(\ref{Spur_zyklisch})}
   -\tr{ \T[2]{s} \cdot \T[2]{a} } \Tk}
%
  \geen{was}{we obtain}
  \begin{equation}
   \label{Spur_symmetrisch_antimetrisch}
   \tr{ \T[2]{s} \cdot \T[2]{a} } = 0 \Fp
  \end{equation}
% \geen{bedeutet.}{}
\end{enumerate}

\ParNoo{2.}
\geen{
Wenn man die irreduziblen Invarianten von Tensoren zweiter Stufe als
Spur einer Folge von Skalarprodukten ausdr"ucken will, besteht die zentrale Frage
darin, wie viele solcher Invarianten eine Integrit"atsbasis bilden.
Wir k"onnen diese Frage hier nicht allgemein beantworten, sondern beschr"anken
uns auf den Sonderfall, dass die Faktoren in den Skalarprodukten nur von zwei
verschiedenen Tensoren \T[2]{a} und \T[2]{b} gebildet werden.
Bei der Untersuchung gehen wir systematisch vor und erh"ohen
schrittweise die Anzahl der Faktoren, die in den Skalarprodukten auftreten;
\index{Invariante!Grad@, Grad einer}die Anzahl der Faktoren bezeichnen wir dabei auch als Grad der Invariante.}{
In order to write the irreducible invariants of a second-order tensor as the trace of a sequence of scalar products, the main question is how many of these invariants form an integrity basis.
Answering this question here in all generality would be beyond the scope of this book.
We restrict ourselves to the case that the factors
in the scalar product depend only on
two different tensors \T[2]{a} and \T[2]{b}.
We will follow a systematical approach and increase the number of the factors
in the scalar product step-by-step;
\index{invariant!degree@, degree of an} the number of these  factors is also called the degree of the invariant.
}

\geen{Bei nur einem Faktor gibt es lediglich zwei M"oglichkeiten, auf die beschriebene Art
Invarianten zu bilden, n"amlich die Spur der beiden Tensoren selbst:}{
With only one factor, there are only two ways to form invariants in the described manner, namely
the trace of each of the two tensors themselves, i.\,e.}
%
\begin{equation}
 \label{invarianten_ersten_grades}
  I_{11} := \tro{ \T[2]{a} } \Fk
  \qquad \qquad
  I_{12} := \tro{ \T[2]{b} } \Fp
 \end{equation}
%
\geen{Skalarprodukte aus zwei Faktoren lassen sich auf vier verschiedene Arten bilden:
$\T[2]{a}^2 \Tk[]$ $\T[2]{b}^2 \Tk$ $\T[2]{a} \cdot \T[2]{b} \Tk$
$\T[2]{b} \cdot \T[2]{a} \Tsk[]$
wegen der zyklischen Vertauschbarkeit (\ref{Spur_zyklisch}) ergeben sich
daraus aber nur drei Invarianten zweiten Grades:}{
Scalar products of two factors can be formed in four different ways:
$\T[2]{a}^2 \Tk[]$ $\T[2]{b}^2 \Tk$ $\T[2]{a} \cdot \T[2]{b} \Tk$
$\T[2]{b} \cdot \T[2]{a} \TsknI[]$
after taking cyclical permutations (\ref{Spur_zyklisch}) into account, only three invariants of degree two remain:
}
%
\begin{equation}
 \label{invarianten_zweiten_grades}
  I_{21} := \tro{ \T[2]{a}^2 } \Fk
 \qquad \qquad  I_{22} := \tro{ \T[2]{b}^2 } \Fk
 \qquad \qquad  I_{23} := \tr{ \T[2]{a} \cdot \T[2]{b} } \Fp
 \end{equation}
%
\geen{F"ur Skalarprodukte aus drei Faktoren gibt es insgesamt acht M"oglichkeiten:
$\T[2]{a}^3 \Tk[]$
$\T[2]{b}^3 \Tk[]$
$\T[2]{a}^2 \cdot \T[2]{b} \Tk[]$
$\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \Tk[]$
$\T[2]{b} \cdot \T[2]{a}^2 \Tk[]$
$\T[2]{b}^2 \cdot \T[2]{a} \Tk[]$
$\T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \Tk[]$
$\T[2]{a} \cdot \T[2]{b}^2  \Tsk[]$
bei der Spurbildung bleiben dabei nach Ber"ucksichtigung
der zyklischen Vertauschbarkeit (\ref{Spur_zyklisch})
vier Invarianten dritten Grades "ubrig:}{
From three factors, there are altogether eight possible scalar products:
$\T[2]{a}^3 \Tk[]$
$\T[2]{b}^3 \Tk[]$
$\T[2]{a}^2 \cdot \T[2]{b} \TknI[]$
$\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \Tk[]$
$\T[2]{b} \cdot \T[2]{a}^2 \Tk[]$
$\T[2]{b}^2 \cdot \T[2]{a} \Tk[]$
$\T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \Tk[]$
$\T[2]{a} \cdot \T[2]{b}^2  \Tsk[]$
after computing the traces and taking cyclical permutations according to (\ref{Spur_zyklisch}) into account,
only four invariants of degree three remain:
}
%
\begin{equation}
 \label{invarianten_dritten_grades}
 \begin{array}{@{}>{\Ds}l@{\qquad\qquad }>{\Ds}l}
  I_{31} := \tro{ \T[2]{a}^3 } \Fk
  &
  I_{32} := \tro{ \T[2]{b}^3 } \Fk %\rule[-4ex]{0ex}{0ex}
  \\
  I_{33} := \tr{ \T[2]{a}^2 \cdot \T[2]{b} } \Fk
  &
  I_{34} := \tr{ \T[2]{a} \cdot \T[2]{b}^2 } \Fp \rule{0ex}{3ex}
 \end{array}
\end{equation}
%
\geen{Die bisher betrachteten Invarianten ersten, zweiten und dritten Grades
sind alle irreduzibel, weil es keine M"oglichkeit gibt, eine von ihnen
durch eine andere auszudr"ucken. Wenn man jedoch auf Invarianten vierten
Grades "ubergeht, gibt es zum ersten Mal eine grunds"atzliche Einschr"ankung,
denn Invarianten wie $\tr{\T[2]{a}^3 \cdot \T[2]{b}}$ oder
$\tr{\T[2]{b}^3 \cdot \T[2]{a}}$ sind reduzibel.
Um das zu erkennen, l"osen wir die Cayley-Hamilton-Gleichung
(\ref{3.88}) nach $\T[2]{a}^3$ auf und multiplizieren von rechts skalar mit
$\T[2]{b}\Td$}{
The invariants of degree one, two, and three,
which we have considered so far, are all irreducible,
because none can be written in terms of the others.
However, for invariants of degree four,
a fundamental restriction appears,
since invariants such as $\tr{\T[2]{a}^3 \cdot \T[2]{b}}$ and
$\tr{\T[2]{b}^3 \cdot \T[2]{a}}$ are reducible.
To see this, we solve the Cayley--Hamilton theorem
(\ref{3.88}) for $\T[2]{a}^3$ and scalar multiply it
from the right by $\T[2]{b}$, so we have
}
%
\Af{
 \T[2]{a}^3 \cdot \T[2]{b}
 =
 A'' \, \T[2]{a}^2 \cdot \T[2]{b} - A' \, \T[2]{a} \cdot \T[2]{b} + A \, \T[2]{b} \Tp
}
%
\geen{Durch Bildung der Spur folgt dann}{Computing the trace gives}
%
\Af{
 \tr{\T[2]{a}^3 \cdot \T[2]{b}}
 =
 A'' \, \tr{\T[2]{a}^2 \cdot \T[2]{b}} - A' \, \tr{\T[2]{a} \cdot \T[2]{b}} + A \, \tro{\T[2]{b}} \Tk
}
%
\geen{d.\,h. $\tr{ \T[2]{a}^3 \cdot \T[2]{b} }$ l"asst sich durch
Invarianten h"ochstens dritten Grades ausdr"ucken,
da $A''\Tk A'$ und $A$ gem"a"s (\ref{3.94})
ebenfalls Funktionen von $\tro \T[2]{a}\Tk[]$ $\tro \T[2]{a}^2$ und $\tro \T[2]{a}^3$
sind. Dieselbe Aussage erh"alt man f"ur $\tr{ \T[2]{b}^3 \cdot \T[2]{a} }\Tk[]$
wenn in der obigen Herleitung $\T[2]{a}$ und $\T[2]{b}$ vertauscht werden.}{i.\,e.\
$\tr{ \T[2]{a}^3 \cdot \T[2]{b} }$ can be written in terms of invariants of degree less than or equal to three,
since $A''\Tk A'$, and $A$ are, according to (\ref{3.94}),
also functions of $\tro \T[2]{a}\Tk[]$ $\tro \T[2]{a}^2\Tk[]$
and $\tro \T[2]{a}^3$.
The same is true for $\tr{ \T[2]{b}^3 \cdot \T[2]{a} }\Tk[]$
because $\T[2]{a}$ and $\T[2]{b}$ can be interchanged in the above derivation.
}


\geen{
Die vorstehenden "Uberlegungen lassen sich auf Invarianten der Form
$\tr{ \T[2]{c} \cdot \T[2]{a}^3 \cdot \T[2]{d}}$ oder
$\tr{ \T[2]{c} \cdot \T[2]{b}^3 \cdot \T[2]{d}}$ "ubertragen,
wobei $\T[2]{c}$ und $\T[2]{d}$ beliebige Tensoren zweiter Stufe sind,
insbesondere auch wieder Skalarprodukte aus den Faktoren
$\T[2]{a}$ und $\T[2]{b}\Tp[]$
Solche Invarianten k"onnen mithilfe der Cayley-Hamilton-Gleichung
(\ref{3.88}) auf Invarianten niedrigeren Grades zur"uckgef"uhrt werden,
oder anders formuliert: Invarianten, die einen Faktor in dritter (oder h"oherer)
Potenz enthalten, sind reduzibel.
Wir brauchen deshalb im Folgenden nur noch Skalarprodukte zu untersuchen,
die aus den Elementen $\T[2]{a}^2\Tk[]$ $\T[2]{b}^2\Tk[]$ $\T[2]{a} \Tk[]$ $\T[2]{b}$
aufgebaut sind.}{
We can extend these considerations to invariants of the form
$\tr{ \T[2]{c} \cdot \T[2]{a}^3 \cdot \T[2]{d}}$ and \Lb
$\tr{ \T[2]{c} \cdot \T[2]{b}^3 \cdot \T[2]{d}}$,
where  $\T[2]{c}$ and $\T[2]{d}$ are arbitrary second-order tensors;
in particular they can be scalar products of the factors
$\T[2]{a}$ and $\T[2]{b}\Tp[]$
Such invariants can be reduced, using the Cayley--Hamilton theorem
(\ref{3.88}), to invariants of a smaller degree.
In other words,
invariants with a term of power three (or higher) are reducible.
Hence we only need to investigate sequences of scalar products
with the elements $\T[2]{a}^2\Tk$ $\T[2]{b}^2\Tk$ $\T[2]{a} \Tk$ $\T[2]{b}$.
}

\geen{
F"ur Skalarprodukte mit mindestens vier Faktoren k"onnen wir
aus der verallgemeinerten Cayley-Hamilton-Gleichung eine weitere Beziehung
herleiten, die uns helfen wird, die Suche nach den irreduziblen Invarianten
einzuschr"anken.
Hierzu setzen wir in (\ref{cayley_hamilton_verallgemeinert})
\Tf{ \T[2]{a} = \T[2]{b} = \T[2]{n} } und multiplizieren von rechts skalar mit
einem beliebigen Tensor $\T[2]{d}\Tp[]$
F"ur die erste Zeile gem"a"s (\ref{zeile_1}) erhalten wir zun"achst:}{
For scalar products with at least four factors, we can derive another relation,
using the generalized Cayley--Hamilton theorem,
 which will narrow down the search for irreducible invariants.
For this we set in (\ref{cayley_hamilton_verallgemeinert}) \Tf{ \T[2]{a} = \T[2]{b} = \T[2]{n} } and scalar multiply
from the right by
an arbitrary tensor $\T[2]{d}\Tp[]$
For the first row we get with (\ref{zeile_1})
}
%
\Af{
 \begin{array}{@{}>{\Ds}l@{}>{\Ds}c@{}>{\Ds\rule[-2ex]{0ex}{0ex}}l}
 \T[2]{\Sigma} \cdot \T[2]{d}
 &{} = &
   \left[
    \T[2]{n} \cdot \left( \T[2]{n} \cdot \T[2]{c} + \T[2]{c} \cdot \T[2]{n} \right)
  + \T[2]{n} \cdot \left( \T[2]{n} \cdot \T[2]{c} + \T[2]{c} \cdot \T[2]{n} \right)
  + \T[2]{c} \cdot \left( \T[2]{n} \cdot \T[2]{n} + \T[2]{n} \cdot \T[2]{n} \right)
   \right] \cdot \T[2]{d}
 \\
 &{} = & \,
 2 \left[
   \T[2]{n} \cdot \T[2]{c} \cdot \T[2]{n} + \T[2]{n}^2 \cdot \T[2]{c} + \T[2]{c} \cdot \T[2]{n}^2
   \right] \cdot \T[2]{d}
 =
 2 \left[
   \T[2]{n} \cdot \T[2]{c} \cdot \T[2]{n} \cdot \T[2]{d}
 + \T[2]{n}^2 \cdot \T[2]{c} \cdot \T[2]{d} + \T[2]{c} \cdot \T[2]{n}^2 \cdot \T[2]{d}
   \right] \Tp
   \rule{0ex}{3ex}
 \end{array}
}
%
\geen{Nach Bildung der Spur und Ber"ucksichtigung der zyklischen Vertauschbarkeit
entsteht daraus:}{
Computing the trace, taking cyclic permutations
into account, yields
}
%
\Af{
\tr{ \T[2]{\Sigma} \cdot \T[2]{d} }
=
2 \left[ \tr{ \T[2]{n} \cdot \T[2]{c} \cdot \T[2]{n} \cdot \T[2]{d} }
       + \tr{ \T[2]{n}^2 \cdot \T[2]{c} \cdot \T[2]{d} }
       + \tr{ \T[2]{n}^2 \cdot \T[2]{d} \cdot \T[2]{c} }
  \right] \Tk
%}
%%
%\Af{
\\
\tr{ \T[2]{n} \cdot \T[2]{c} \cdot \T[2]{n} \cdot \T[2]{d} }
=
- \left(  \tr{ \T[2]{n}^2 \cdot \T[2]{c} \cdot \T[2]{d} }
        + \tr{ \T[2]{n}^2 \cdot \T[2]{d} \cdot \T[2]{c} }
  \right)
+ \frac{1}{2} \: \tr{ \T[2]{\Sigma} \cdot \T[2]{d} } \Tp
}
%
\geen{
$\tr{ \T[2]{\Sigma} \cdot \T[2]{d}}$ l"asst sich wegen (\ref{Sigma})
durch Invarianten ausdr"ucken, deren Grad um mindestens eins niedriger ist als
der Grad von $\tr{ \T[2]{n} \cdot \T[2]{c} \cdot \T[2]{n} \cdot \T[2]{d} }\Tk$
$\tr{ \T[2]{n}^2 \cdot \T[2]{c} \cdot \T[2]{d} }$ und
$\tr{ \T[2]{n}^2 \cdot \T[2]{d} \cdot \T[2]{c} }\Tp$
In der Darstellungstheorie sagt man daf"ur auch, dass
$\tr{ \T[2]{n} \cdot \T[2]{c} \cdot \T[2]{n} \cdot \T[2]{d} }$
und
$- \left(  \tr{ \T[2]{n}^2 \cdot \T[2]{c} \cdot \T[2]{d} }
        + \tr{ \T[2]{n}^2 \cdot \T[2]{d} \cdot \T[2]{c} }
  \right)
$
"aquivalent sind und schreibt}{Using (\ref{Sigma}),
we can write $\tr{ \T[2]{\Sigma} \cdot \T[2]{d}}$
in terms of invariants of at least one degree less than
the degree of
$\tr{ \T[2]{n} \cdot \T[2]{c} \cdot \T[2]{n} \cdot \T[2]{d} }\Tk$
$\tr{ \T[2]{n}^2 \cdot \T[2]{c} \cdot \T[2]{d} }\Tk[]$ and
$\tr{ \T[2]{n}^2 \cdot \T[2]{d} \cdot \T[2]{c} }\Tp$
In the theory of the representation of tensor functions we also say that
$\tr{ \T[2]{n} \cdot \T[2]{c} \cdot \T[2]{n} \cdot \T[2]{d} }$
and
$- \left(  \tr{ \T[2]{n}^2 \cdot \T[2]{c} \cdot \T[2]{d} }
        + \tr{ \T[2]{n}^2 \cdot \T[2]{d} \cdot \T[2]{c} }
  \right)
$
are equivalent and we write
}
%
\begin{equation}
\label{aequivalenz_invarianten}
\tr{ \T[2]{n} \cdot \T[2]{c} \cdot \T[2]{n} \cdot \T[2]{d} }
\equiv
- \left(  \tr{ \T[2]{n}^2 \cdot \T[2]{c} \cdot \T[2]{d} }
        + \tr{ \T[2]{n}^2 \cdot \T[2]{d} \cdot \T[2]{c} }
  \right) \Fp
\end{equation}
%
\geen{"Aquivalente Invarianten\index{Invarianten!aquivalente@, "aquivalente}\index{aquivalente@"aquivalente!Invarianten@ Invarianten}
haben denselben Grad und unterscheiden sich nur durch (reduzible) Invarianten niedrigeren Grades,
insbesondere kann eine irreduzible Invariante in einer Integrit"atsbasis
durch eine "aquivalente Invariante ersetzt werden.
Falls eine Rechnung zu dem Ergebnis f"uhrt, dass eine
Invariante "aquivalent zu null ist, dann ist diese Invariante reduzibel.
Die besondere Bedeutung der "Aquivalenzbeziehung (\ref{aequivalenz_invarianten})
liegt darin, dass sich Invarianten mit zwei gleichen, aber getrennt voneinander stehenden Faktoren
"aquivalent durch die Summe von zwei anderen Invarianten ausdr"ucken lassen,
in denen dieser Faktor als Quadrat erscheint.}{
Equivalent invariants\index{invariants!equivalent@, equivalent}
\index{equivalent@equivalent!invariant@ invariants}
have the same degree and differ only in their (reducible) invariants of lower degrees;
in particular, we can replace an irreducible invariant in an integrity basis by an equivalent invariant.
If a computation shows that an invariant is equivalent to zero, then this invariant is reducible.
The important implication of the equivalence relation
(\ref{aequivalenz_invarianten})
is that invariants with two factors which are equal but appear separated from each other can be written as the sum of two other invariants in which this factor appears squared.
}

\geen{Nach diesen Vorbereitungen k"onnen wir uns
bei der Suche nach den irreduziblen Invarianten vierten Grades
auf folgende Skalarprodukte beschr"anken:
$\T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a} \Tk[]$ \Lb
$\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a}^2 \Tk$
$\T[2]{b}^2 \cdot \T[2]{a} \cdot \T[2]{b} \Tk$
$\T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2 \Tk$
$\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \Tk$
$\T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \Tk$
$\T[2]{a} \cdot \T[2]{b}^2 \cdot \T[2]{a} \Tk$
$\T[2]{b} \cdot \T[2]{a}^2 \cdot \T[2]{b} \Tk[]$ \Lb
$\T[2]{a}^2 \cdot \T[2]{b}^2 \Tk$
$\T[2]{b}^2 \cdot \T[2]{a}^2 \Tp$
Nach Bildung der Spur folgt wegen der zyklischen Vertauschbarkeit
\Tf{
\tr{\T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a}}
= \tr{\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a}^2}
= \tr{\T[2]{a}^3 \cdot \T[2]{b}}
}
und
\Tf{
\tr{\T[2]{b}^2 \cdot \T[2]{a} \cdot \T[2]{b}}
= \tr{\T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2}
= \tr{\T[2]{b}^3 \cdot \T[2]{a}} \Tk[]
}
diese Invarianten sind also reduzibel.
Aus dem gleichen Grund ist
\Tf{
\tr{\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}} =
\tr{\T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a}}
}
und
\Tf{
\tr{\T[2]{a}^2 \cdot \T[2]{b}^2}
= \tr{\T[2]{b}^2 \cdot \T[2]{a}^2}
= \tr{\T[2]{a} \cdot \T[2]{b}^2 \cdot \T[2]{a}}
= \tr{\T[2]{b} \cdot \T[2]{a}^2 \cdot \T[2]{b}}
\Tk[]
}
es bleiben daher nur noch zwei Invarianten "ubrig,
die wir auf ihre Irreduzibilit"at pr"ufen m"ussen, n"amlich
$\tr{\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}}$ und
$\tr{\T[2]{a}^2 \cdot \T[2]{b}^2}\Tp[]$
Durch Setzen von
\Tf{ \T[2]{n} = \T[2]{a} \Tk \T[2]{c} = \T[2]{d} = \T[2]{b}}
folgt aus (\ref{aequivalenz_invarianten})}{
With these preparations we can now reduce our search for
fourth-order irreducible invariants to the following scalar products:
$\T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a} \Tk[]$
$\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a}^2 \Tk$
$\T[2]{b}^2 \cdot \T[2]{a} \cdot \T[2]{b} \Tk$
$\T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2 \Tk$
$\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \Tk$
$\T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \Tk$
$\T[2]{a} \cdot \T[2]{b}^2 \cdot \T[2]{a} \Tk$
$\T[2]{b} \cdot \T[2]{a}^2 \cdot \T[2]{b} \Tk[]$
$\T[2]{a}^2 \cdot \T[2]{b}^2 \Tk$
$\T[2]{b}^2 \cdot \T[2]{a}^2 \Tp$
After computing the trace and using cyclic permutation we have
\Tf{
\tr{\T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a}}
= \tr{\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a}^2}
= \tr{\T[2]{a}^3 \cdot \T[2]{b}}
}
and \Lb
\Tf{
\tr{\T[2]{b}^2 \cdot \T[2]{a} \cdot \T[2]{b}}
= \tr{\T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2}
= \tr{\T[2]{b}^3 \cdot \T[2]{a}} \Tk[]
}
so these invariants are reducible.
With the same reasoning we have
\Tf{
\tr{\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}} =
\tr{\T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a}}
}
and
\Tf{
\tr{\T[2]{a}^2 \cdot \T[2]{b}^2}
= \tr{\T[2]{b}^2 \cdot \T[2]{a}^2} \Lb
= \tr{\T[2]{a} \cdot \T[2]{b}^2 \cdot \T[2]{a}}
= \tr{\T[2]{b} \cdot \T[2]{a}^2 \cdot \T[2]{b}}
\Tk[]
}
so only two invariants remain,  i.\,e.\
$\tr{\T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}}$ and
$\tr{\T[2]{a}^2 \cdot \T[2]{b}^2}\Tk[]$
and we have to check if they are irreducible.
Setting in (\ref{aequivalenz_invarianten})
\Tf{ \T[2]{n} = \T[2]{a} \Tk \T[2]{c} = \T[2]{d} = \T[2]{b}}
we obtain
}
%
\Af{
\tr{ \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} }
\equiv
- 2 \: \tr{ \T[2]{a}^2 \cdot \T[2]{b}^2  } \Tk
}
\geen{d.\,h. beide Invarianten sind "aquivalent.
Es gibt also nur eine einzige irreduzible Invariante vierten Grades,
wir w"ahlen }{i.\,e.\ both invariants are equivalent.
Hence only one irreducible invariant of degree four exists
and we choose
}
%
\begin{equation}
 \label{invarianten_vierten_grades}
 I_{41} := \tr{\T[2]{a}^2 \cdot \T[2]{b}^2 } \Fp
\end{equation}
%
%
\geen{Bei der Untersuchung von Skalarprodukten mit f"unf Faktoren ber"ucksichtigen
wir von vornherein die zyklische Vertauschbarkeit, dann gibt es lediglich
zwei M"oglichkeiten, Invarianten f"unften Grades zu bilden, die gleichzeitig
aus den Elementen
$\T[2]{a}^2\Tk[]$ $\T[2]{b}^2\Tk[]$ $\T[2]{a} \Tk[]$ $\T[2]{b}$
zusammengesetzt sind:
$ \tr{ \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2 }$
und
$ \tr{ \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a}^2}\Tp[]$
Aus (\ref{aequivalenz_invarianten}) folgt}{
When investigating scalar products with five factors,
we consider cyclic
permutations from the outset and then we see that
there are only two ways of computing invariants of degree five,
which are composed of the elements
$\T[2]{a}^2\Tk[]$ $\T[2]{b}^2\Tk[]$ $\T[2]{a} \Tk[]$ $\T[2]{b}\TknI[]$  namely
$\tr{ \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2}$
and
$ \tr{ \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a}^2}\Tp[]$
From (\ref{aequivalenz_invarianten}) it follows that
}
%
\Af{ \tr{ \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2}
\equiv - 2 \: \tr{ \T[2]{a}^2 \cdot \T[2]{b}^3} \Tk%}
%
%\Af{
%
\\
\tr{ \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a}^2}
\equiv - 2 \: \tr{ \T[2]{b}^2 \cdot \T[2]{a}^3}\Tsk}
\geen{wegen des Auftretens von $\T[2]{a}^3$ und $\T[2]{b}^3$
bedeutet das jedoch, dass beide Invarianten reduzibel sind,
m.\,a.\,W. es gibt "uberhaupt keine irreduziblen Invarianten
f"unften Grades.}{
however, because of $\T[2]{a}^3$ and $\T[2]{b}^3$ both invariants are reducible.
In other words, no irreducible invariants of degree five exist.
}

\geen{Auf der Suche nach den irreduziblen Invarianten sechsten Grades stellen wir
zun"achst alle Invarianten zusammen, die sich unter Ber"ucksichtigung der
zyklischen Vertauschbarkeit aus den Elementen
$\T[2]{a}^2\Tk[]$ $\T[2]{b}^2\Tk[]$ $\T[2]{a} \Tk[]$ $\T[2]{b}$
bilden lassen:
$\tr{ \T[2]{a} \cdot \T[2]{b}^2 \cdot \T[2]{a} \cdot \T[2]{b}^2} \Tk$
$\tr{ \T[2]{b} \cdot \T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a}^2} \Tk$
$\tr{ \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}} \Tk$
$\tr{ \T[2]{a}^2 \cdot \T[2]{b}^2 \cdot \T[2]{a} \cdot \T[2]{b}} \Tk$
$\tr{ \T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2} \Tsk$
anschlie"send untersuchen wir sie mithilfe von (\ref{aequivalenz_invarianten})
auf ihre Irreduzibilit"at.
F"ur die ersten beiden Invarianten folgt}{
In order to find the irreducible invariants of degree six, which can be formed from the elements
$\T[2]{a}^2\Tk[]$ $\T[2]{b}^2\Tk[]$ $\T[2]{a} \Tk[]$ $\T[2]{b}\Tk$ we start, after taking cyclic permutations into account,
from the invariants
$\tr{ \T[2]{a} \cdot \T[2]{b}^2 \cdot \T[2]{a} \cdot \T[2]{b}^2} \Tk$
$\tr{ \T[2]{b} \cdot \T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a}^2} \Tk$
$\tr{ \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}} \Tk$
$\tr{ \T[2]{a}^2 \cdot \T[2]{b}^2 \cdot \T[2]{a} \cdot \T[2]{b}} \Tk$
$\tr{ \T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2} \Tp$
We then investigate, using (\ref{aequivalenz_invarianten}),
which of them are irreducible.\vadjust{\vfill\eject}
For the first two invariants we have
}
\Af{
\tr{ \T[2]{a} \cdot \T[2]{b}^2 \cdot \T[2]{a} \cdot \T[2]{b}^2} \equiv
- 2 \: \tr{ \T[2]{a}^2 \cdot \T[2]{b}^4} \Tk
%}
%\Af{
\\
\tr{ \T[2]{b} \cdot \T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a}^2} \equiv
- 2 \: \tr{ \T[2]{b}^2 \cdot \T[2]{a}^4} \Tsk
}
\geen{diese Invarianten sind also wegen des Auftretens von $\T[2]{a}^4$ und $\T[2]{b}^4$
reduzibel.
F"ur die dritte Invariante ergibt sich}{
but because of $\T[2]{a}^4$ and $\T[2]{b}^4$ these invariants are reducible. For the third invariant we have
}
\Af{
\tr{ \T[2]{a} \cdot (\T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b} ) \cdot \T[2]{a} \cdot \T[2]{b}} \equiv
- \tr{ \T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2}
- \tr{ \T[2]{a}^2 \cdot \T[2]{b}^2 \cdot \T[2]{a} \cdot \T[2]{b}} \Tk
}
\geen{sie ist also "aquivalent zur (negativen) Summe der letzten beiden Invarianten.
F"ur die letzten beiden Invarianten erh"alt man}{
i.\,e.\ the third invariant is equivalent to the (negative) sum of the last two invariants.
For the last two invariants we obtain
}
\Af{
\tr{ \T[2]{a}^2 \cdot \T[2]{b}^2 \cdot \T[2]{a} \cdot \T[2]{b}}
=
\tr{ \T[2]{a} \cdot( \T[2]{a} \cdot \T[2]{b}^2) \cdot \T[2]{a} \cdot \T[2]{b}} \equiv
- \underbrace{\tr{ \T[2]{a}^3 \cdot \T[2]{b}^3}}_{\Ds \equiv 0}
- \tr{ \T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2} \Tk
}
\geen{sie sind also zueinander "aquivalent und lassen sich nur als Summe,
aber nicht einzeln auf Invarianten niedrigeren Grades zur"uckf"uhren.
Im Ergebnis k"onnen wir daher eine von ihnen als irreduzibel betrachten, wir w"ahlen}{
i.\,e.\  they are equivalent and can only be reduced as a sum, but not individually, to invariants of lower degree.
So we can regard one of them as irreducible and we choose\looseness=-1}
%
\begin{equation}
 \label{invarianten_sechsten_grades}
 I_{61} := \tr{\T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2 } \Fp
\end{equation}
%
\geen{Invarianten siebten und h"oheren Grades braucht man "uberraschenderweise nicht mehr
im Einzelnen zu untersuchen, da sie stets reduzibel sind.
Ursache hierf"ur ist zum einen die Tatsache, dass in irreduziblen Invarianten alle
Faktoren nur einfach oder als Quadrat auftreten d"urfen,
zum anderen die "Aquivalenzbeziehung (\ref{aequivalenz_invarianten}),
nach der sich Invarianten mit einem doppelt vorkommenden Faktor
durch Invarianten mit quadratischen Faktoren ersetzen lassen.
Aus den insgesamt zur Verf"ugung stehenden Elementen
$\T[2]{a}^2\Tk[]$ $\T[2]{b}^2\Tk[]$ $\T[2]{a} \Tk[]$ $\T[2]{b}$
lassen sich ohne Wiederholung h"ochstens Invarianten vom Grad sechs bilden,
bei h"oherem Grad muss mindestens eines der Elemente doppelt vorkommen.
Ist das doppelt vorkommende Element $\T[2]{a}$ oder $\T[2]{b}\Tk[]$
k"onnen wir die betreffende Invariante
wegen (\ref{aequivalenz_invarianten}) durch
"aquivalente Invarianten mit $\T[2]{a}^2$ oder $\T[2]{b}^2$
ersetzen; die Elemente $\T[2]{a}^2$ oder $\T[2]{b}^2$
sind aber ebenfalls schon vorhanden, dann f"uhrt eine
erneute Anwendung von (\ref{aequivalenz_invarianten})
auf Invarianten, die $\T[2]{a}^4$ oder $\T[2]{b}^4$
enthalten und somit reduzibel sind.
Ist das doppelt vorkommende Element $\T[2]{a}^2$ oder $\T[2]{b}^2\Tk$
reicht bereits eine einmalige Anwendung von (\ref{aequivalenz_invarianten})
aus, um die betreffende Invariante auf Invarianten niedrigeren Grades
zur"uckzuf"uhren.}{
It turns out that we do not have to look further for invariants of
degree seven or higher, because they will always be reducible.
This follows from two facts.
First, a factor can appear in irreducible invariants only as itself or squared. Second,
the equivalence relation (\ref{aequivalenz_invarianten})
states that invariants appearing twice
can be replaced by invariants with quadratic factors.
From the elements
$\T[2]{a}^2\Tk[]$ $\T[2]{b}^2\Tk[]$ $\T[2]{a} \Tk[]$ $\T[2]{b}$ we can form, without repetition, at most invariants of degree six, because for higher degrees at least one of the elements appears twice.
If the element appearing twice is $\T[2]{a}$ or $\T[2]{b}\Tk[]$ we can replace the invariant under consideration, using (\ref{aequivalenz_invarianten}), with equivalent invariants with $\T[2]{a}^2$ or $\T[2]{b}^2$; however, the elements $\T[2]{a}^2$ and $\T[2]{b}^2$ already appear, so that applying (\ref{aequivalenz_invarianten}) again leads to invariants with $\T[2]{a}^4$ or $\T[2]{b}^4$, which are reducible.
If the element appearing twice is $\T[2]{a}^2$ or $\T[2]{b}^2\Tk$
then applying (\ref{aequivalenz_invarianten}) once is already sufficient to reduce the invariant under consideration to  invariants of lower degree.
}


\ParNo{3.}
\geen{Wir fassen zum Abschluss noch einmal die Ergebnisse unserer "Uberlegungen zusammen:}{We summarize the results of our investigations.
}

\geen{Wir haben Invarianten als Spur einer Folge von Skalarprodukten zwischen
Tensoren zweiter Stufe ausgedr"uckt und uns bei der Suche nach
irreduziblen Invarianten auf den Sonderfall beschr"ankt, dass die Faktoren
in den Skalarprodukten nur von zwei verschiedenen Tensoren $\T[2]{a}$ und $\T[2]{b}$
gebildet werden.
Durch Ausnutzung der Cayley-Hamilton-Gleichung (\ref{3.88})
und ihrer Verallgemeinerung (\ref{cayley_hamilton_verallgemeinert})
gelang es uns zu zeigen, dass Invarianten mit mehr als sechs Faktoren
stets reduzibel sind; au"serdem konnten wir in
(\ref{invarianten_ersten_grades}), (\ref{invarianten_zweiten_grades})
(\ref{invarianten_dritten_grades}), (\ref{invarianten_vierten_grades})
und (\ref{invarianten_sechsten_grades})
insgesamt elf irreduzible Invarianten identifizieren
(von denen einige Simultaninvarianten sind, da sie aus den Koordinaten
verschiedener Tensoren gebildet werden):}{
We computed invariants as the trace of a sequence of scalar products of second-order tensors, and we restricted our search for invariants to the case
that the factors in the sequence of scalar products are two different tensors $\T[2]{a}$ and $\T[2]{b}$.
Using the Cayley--Hamilton theorem (\ref{3.88})
and its generalization (\ref{cayley_hamilton_verallgemeinert}),
we could show that invariants with more than six factors
are always reducible. Finally, we were able to find with
(\ref{invarianten_ersten_grades}), (\ref{invarianten_zweiten_grades}),
(\ref{invarianten_dritten_grades}), (\ref{invarianten_vierten_grades}),
and (\ref{invarianten_sechsten_grades})
a total of 11 irreducible invariants
(some of which are simultaneous invariants, since they are
built from the coordinates of different tensors):\looseness=1}
%
\begin{equation}
 \label{irreduzible_invarianten_a_b}
 \begin{array}{@{}>{\Ds}l@{\qquad}>{\Ds}l@{\qquad}>{\Ds}l@{\qquad}>{\Ds\rule{0ex}{3ex}}l}
  I_{11} = \tro{ \T[2]{a} } \Fk
  &
  I_{12} = \tro{ \T[2]{b} } \Fk
  \\
  I_{21} = \tro{ \T[2]{a}^2 } \Fk
  &
  I_{22} = \tro{ \T[2]{b}^2 } \Fk
  &
  I_{23} = \tr{ \T[2]{a} \cdot \T[2]{b} } \Fk
  &
  \\
  I_{31} = \tro{ \T[2]{a}^3 } \Fk
  &
  I_{32} = \tro{ \T[2]{b}^3 } \Fk %\rule[-4ex]{0ex}{0ex}
  &
  I_{33} = \tr{ \T[2]{a}^2 \cdot \T[2]{b} } \Fk
  &
  I_{34} = \tr{ \T[2]{a} \cdot \T[2]{b}^2 } \Fk
  \\
  \multicolumn{4}{@{}>{\Ds\rule{0ex}{3ex}}l}{
  I_{41} = \tr{\T[2]{a}^2 \cdot \T[2]{b}^2 } \Fk }
  \\
  \multicolumn{4}{@{}>{\Ds\rule{0ex}{3ex}}l}{
  I_{61} = \tr{\T[2]{a}^2 \cdot \T[2]{b} \cdot \T[2]{a} \cdot \T[2]{b}^2 } \Fp }
 \end{array}
\end{equation}
%
\geen{Wir wissen allerdings noch nicht, ob diese irreduziblen Invarianten
auch einen vollst"andigen Satz bilden; dieser Frage gehen wir bei der Betrachtung
einiger Beispiele nach.}{
It remains to answer the question
if these irreducible invariants form a complete set.
We will do this by means of examples.
}

\ParNo{4.}
\geen{
Im ersten Beispiel untersuchen wir einen einzelnen Tensor $\T[2]{T}$
und setzen in (\ref{irreduzible_invarianten_a_b})
\Tf{ \T[2]{a} = \T[2]{T} \Tk \T[2]{b} = \T[2]{T}^\tT \Tp[]}
Da sich die Spur bei der Transposition nicht "andert und
nach (\ref{Spur_Potenz_transponiert}) Transposition und Potenzierung
bei der Spurbildung vertauschbar sind, erkennt man sofort, dass einige der Invarianten
in (\ref{irreduzible_invarianten_a_b}) zusammenfallen:}{
As a first example,
we consider a single tensor $\T[2]{T}$ and set in (\ref{irreduzible_invarianten_a_b})
\Tf{ \T[2]{a} = \T[2]{T} \Tk\Lb \T[2]{b} = \T[2]{T}^\tT \Tp[]}
Since the trace does not change if we transpose its argument and since,
according to (\ref{Spur_Potenz_transponiert}),
transposition and exponentiation are interchangeable within a trace,
we see immediately that some of the invariants
in (\ref{irreduzible_invarianten_a_b}) are the same. We have
}
%
\Af{
I_{11} = I_{12} = \tro{\T[2]{T}} \Tk\quad
I_{21} = I_{22} = \tro{\T[2]{T}^2} \Tk\quad
I_{31} = I_{32} = \tro{\T[2]{T}^3} \Tk
}
%
%\Pb
\geen{au"serdem ergibt eine n"ahere Untersuchung von $I_{33}$ und $I_{34}$}{and further investigation of $I_{33}$ and $I_{34}$ shows that
}
%
\Af{
I_{34} = \tr{\T[2]{T} \cdot ( \T[2]{T}^\tT)^2 }
\womit{(\ref{Spur_transponiert})}
\tr{ \T[2]{T}^2 \cdot \T[2]{T}^\tT } = I_{33} \TpnI
}
%
\geen{Ein einzelner Tensor zweiter Stufe hat also im allgemeinen Fall
sieben irreduzible Invarianten:}
{Thus a single second-order tensor
has, in general, seven irreducible invariants:}
%
\begin{equation}
 \label{irreduzible_invarianten_T}
 \begin{array}{@{}>{\Ds}l!{:=}>{\Ds\rule{0ex}{3ex}}l!{=}>{\Ds\rule{0ex}{3ex}}l}
  I_1 & T_{ii} & \tro{ \T[2]{T} } \Fk
  \\
  I_2 &  T_{ij} \: T_{ji} & \tro{ \T[2]{T}^2 } \Fk
  \\
  I_3 & T_{ij} \: T_{ij}  & \tr{ \T[2]{T} \cdot \T[2]{T}^\tT } \Fk
  \\
  I_4 & T_{ij} \: T_{jk} \: T_{ki} & \tro{ \T[2]{T}^3 } \Fk
  \\
  I_5 & T_{ij} \: T_{jk} \: T_{ik} &  \tr{ \T[2]{T}^2 \cdot \T[2]{T}^\tT } \Fk
  \\
  I_6 & T_{ij} \: T_{jk} \: T_{lk} \: T_{il} &
        \tr{\T[2]{T}^2 \cdot ( \T[2]{T}^\tT)^2 } \Fk
  \\
  I_7 & T_{ij} \: T_{jk} \: T_{lk} \: T_{lm} \: T_{nm} \: T_{in} &
        \tr{\T[2]{T}^2 \cdot \T[2]{T}^\tT  \cdot \T[2]{T} \cdot ( \T[2]{T}^\tT)^2 } \Fp
 \end{array}
\end{equation}
%
\geen{Diese Invarianten bilden tats"achlich eine Integrit"atsbasis. Der Grund hierf"ur liegt darin,
dass wir neben $\T[2]{T}$ auch $\T[2]{T}^\tT$ in unsere "Uberlegungen einbezogen haben,
denn mit $\T[2]{T}$ allein lassen sich nicht alle Invarianten
durch Spur-Ausdr"ucke darstellen. Das erkennt man beispielsweise
am Vergleich von $I_2$ und $I_3\TdnI[]$
In der Koordinatenschreibweise gilt hierf"ur
\Tf{ I_2 = T_{ij} \: T_{ji} }
und
\Tf{ I_3 = T_{ij} \: T_{ij} \TsknI[]}
beides sind Skalare, die durch "Uberschiebung von
Tensorkoordinaten gebildet werden,
aber $I_3$ l"asst sich ohne den transponierten Tensor nicht
als Spur-Ausdruck darstellen.\footnote{Aus diesem Grund ist
(\ref{irreduzible_invarianten_a_b})
kein vollst"andiger Satz von irreduziblen Invarianten f"ur
die beiden Tensoren $\T[2]{a}$ und $\T[2]{b}\Tsk[]$
zur Gewinnung einer Integrit"atsbasis h"atten wir auch die
transponierten Tensoren $\T[2]{a}^\tT$ und $\T[2]{b}^\tT\Tk[]$
d.\,h. insgesamt vier unterschiedliche Tensoren
betrachten m"ussen.
}}{
These invariants in fact form an integrity basis.
Both $\T[2]{T}$ and $\T[2]{T}^\tT$ are needed and
it is not possible to write all invariants in terms of traces
using only $\T[2]{T}$.
We can see this, for example, if we compare
$I_2$ and $I_3$.
In index notation we have
\Tf{ I_2 = T_{ij} \: T_{ji} }
and
\Tf{ I_3 = T_{ij} \: T_{ij} \TsknI[]}
both are scalars obtained by contracting tensor coordinates,
but without the transposed tensor,
we cannot write $I_3$ as a trace.\footnote{This explains why
(\ref{irreduzible_invarianten_a_b}) is
not a complete set of irreducible invariants of
the tensors $\T[2]{a}$ and $\T[2]{b}\Tsk[]$\Lb
to obtain an integrity basis, we have to include also the
transposed tensors $\T[2]{a}^\tT$ and $\T[2]{b}^\tT\Tk[]$
i.\,e.\ we have to investigate four different tensors.}
}

\geen{Beim Vergleich mit Abschnitt \ref{5.3.2} stellen wir fest,
dass ein Tensor zweiter Stufe im allgemeinen Fall sechs unabh"angige,
aber sieben irreduzible Invarianten besitzt.
Die irreduziblen Invarianten lassen sich aber nat"urlich alle durch die
unabh"angigen Invarianten aus Abschnitt \ref{5.3.2} Nr.\,1
ausdr"ucken, wenn man die Spur-Ausdr"ucke in (\ref{irreduzible_invarianten_T})
im Hauptachsensystem des symmetrischen Anteils von $\T[2]{T}$ auswertet.}{If we compare our results with Section \ref{5.3.2},
we see that, in general, a second-order tensor has six independent invariants,
but seven irreducible invariants.
We can clearly write all irreducible invariants
in terms of the independent invariants from Section \ref{5.3.2},~No.\,1,
if we write the traces in
(\ref{irreduzible_invarianten_T}) with respect to the principal axis system of the symmetric part of $\T[2]{T}$.
}

\geen{F"ur symmetrische Tensoren gilt \Tf{ \T[2]{T}^{\tT} = \T[2]{T}\TpnI[]}%
\index{Tensor!symmetrischer@, symmetrischer}\index{symmetrischer (Anteil eines) Tensor(s)}
Damit ist \Tf{I_2 = I_3} und \Tf{I_4 = I_5\TknI[]}
w"ahrend \Tf{I_6 = \tro{\T[2]{T}^4}} und \Tf{I_7 = \tro{\T[2]{T}^6}} sich
mithilfe der Cayley-Hamilton-Gleichung (\ref{3.89})
auf die verbleibenden Invarianten zur"uckf"uhren lassen.
Von den irreduziblen Invarianten in (\ref{irreduzible_invarianten_T})
bleiben also nur die drei Grundinvarianten
\Tf{I_1 = \tro{\T[2]{T}}\Tk[]} \Tf{I_2 = \tro{\T[2]{T}^2}\Tk[]}
\Tf{I_4 = \tro{\T[2]{T}^3}} "ubrig.}{
Symmetric tensors obey \Tf{ \T[2]{T}^{\tT} = \T[2]{T}\TpnI[]}%
\index{tensor!symmetric@, symmetric}\index{symmetric!tensor@  (part of a) tensor}
Then \Tf{I_2 = I_3} and \Tf{I_4 = I_5\TknI[]}
and we can reduce \Tf{I_6 = \tro{\T[2]{T}^4}} and \Tf{I_7 = \tro{\T[2]{T}^6}\TknI[]}
using the Cayley--Hamilton theorem (\ref{3.89}), to the remaining invariants.
So, from the irreducible invariants in (\ref{irreduzible_invarianten_T}),
only the three basic invariants
\Tf{I_1 = \tro{\T[2]{T}}\Tk[]} \Tf{I_2 = \tro{\T[2]{T}^2}\Tk[]}
\Tf{I_4 = \tro{\T[2]{T}^3}} remain.
}

\geen{F"ur antimetrische Tensoren gilt \Tf{ \T[2]{T}^{\tT} = -\T[2]{T}\Tk[]}
damit ist \Tf{I_1 = 0\Tp[]}
\index{Tensor!antimetrischer@, antimetrischer}\index{antimetrischer (Anteil eines) Tensor(s)}%
$\T[2]{T}^2$ ist wegen
\Tf{ T_{ij} \: T_{jk} = (-T_{ji}) \, (-T_{kj}) = T_{kj} \: T_{ji}}
symmetrisch, $I_2$ verschwindet also nicht, aber es gilt \Tf{I_3 = - I_2\TpnI[]}
$\T[2]{T}^3$ ist wegen
\Tf{ T_{ij} \: T_{jk} \: T_{kl} = (-T_{ji}) \, (-T_{kj}) \, (-T_{lk})
= - T_{lk} \: T_{kj} \: T_{ji}} wieder antimetrisch, d.\,h. es ist \Tf{I_4 = 0}
und damit zugleich auch \Tf{I_5 = - I_4 = 0\Tp[]}
Weiterhin folgt
\Tf{I_6 = \tro{\T[2]{T}^4}} und \Tf{I_7 = -\tro{\T[2]{T}^6}\Tk[]}
deshalb k"onnen auch $I_6$ und $I_7$
mithilfe der Cayley-Hamilton-Gleichung (\ref{3.89})
auf die einzige verbleibende Invariante
\Tf{ I_2 = \tro{\T[2]{T}^2}} zur"uckgef"uhrt werden.}
{
Antimetric tensors satisfy
\Tf{ \T[2]{T}^{\tT} = -\T[2]{T};}
hence \Tf{I_1 = 0\Tp[]}
\index{tensor!antimetric@, antimetric}\index{antimetric!(part of a) tensor}%
We know $\T[2]{T}^2$ is symmetric because
\Tf{ T_{ij} \: T_{jk} = (-T_{ji}) \, (-T_{kj}) = T_{kj} \: T_{ji}\TknI[]} so $I_2$ is nonzero, but we have \Tf{I_3 = - I_2\TpnI[]}\Lb
Here $\T[2]{T}^3$ is again antimetric because
\Tf{ T_{ij} \: T_{jk} \: T_{kl} = (-T_{ji}) \, (-T_{kj}) \, (-T_{lk})
= - T_{lk} \: T_{kj} \: T_{ji}\TknI[]}
so we have  \Tf{I_4 = 0}
and thus also \Tf{I_5 = - I_4 = 0\Tp[]}
It further follows that
\Tf{I_6 = \tro{\T[2]{T}^4}} and \Tf{I_7 = -\tro{\T[2]{T}^6}\Tk[]}
so the Cayley--Hamilton theorem (\ref{3.89}) helps us
reduce $I_6$ and $I_7$ to the only remaining invariant
\Tf{ I_2 = \tro{\T[2]{T}^2}}.
}

\geen{
F"ur orthogonale Tensoren gilt \Tf{ \T[2]{T}^{\tT} = \T[2]{T}^{-1}\Tk[]}
\index{Tensor!orthogonaler@, orthogonaler}\index{orthogonaler!Tensor@ Tensor}%
dann folgt f"ur alle orthogonalen Tensoren
\Tf{ I_3 = I_6 = I_7 = 3 \Tk[]} d.\,h. $I_3\Tk$ $I_6$ und $I_7$
enthalten keine Informationen
"uber einen speziellen orthogonalen Tensor und z"ahlen
deshalb nicht zu den Invarianten.
Weiterhin folgt \Tf{I_5 = I_1\TknI[]}
damit bleiben zun"achst die drei Grundinvarianten
\Tf{I_1 = \tro{\T[2]{T}}\Tk[]} \Tf{ I_2 = \tro{\T[2]{T}^2}\Tk[]}
\Tf{I_4 = \tro{\T[2]{T}^3} }
"ubrig. Ein orthogonaler Tensor hat nach Abschnitt \ref{3.13.2}
au"serdem die Determinante $\pm 1$,
und der Kotensor stimmt nach (\ref{3.14}) bis auf das Vorzeichen
mit dem Tensor "uberein. F"ur die Hauptinvarianten gilt also
nach (\ref{3.41}) bis (\ref{3.43})
\Tf{ A^{\prime\prime} = \tro{\T[2]{T}} \Tk[]}
\Tf{ A^\prime = \pm \tro{\T[2]{T}} \Tk[]} \Tf{ A = \pm 1 \Tsk}
dann folgt aus (\ref{3.95})
\Tf{ \tro{ \T[2]{T}^2 } = \trn{2}{ \T[2]{T} } \mp 2 \: \tro{ \T[2]{T} } \Tk[] }
\Tf{ \tro{ \T[2]{T}^3 } = \trn{3}{ \T[2]{T} } \mp 3 \: \trn{2}{ \T[2]{T} } \pm 3 \Tk[]}
d.\,h. ein orthogonaler Tensor hat nur eine einzige irreduzible
Invariante \Tf{ I_1 = \tr{ \T[2]{T} } \Tp}}{
For orthogonal tensors we have \Tf{ \T[2]{T}^{\tT} = \T[2]{T}^{-1}.}
\index{tensor!orthogonal@, orthogonal}\index{orthogonal!tensor@ tensor}%
Then %all orthogonal tensors have
\Tf{ I_3 = I_6 = I_7 = 3 \Tp[]}
In other words, $I_3\Tk$ $I_6\Tk$ and $I_7$
do not contain any information about a particular orthogonal tensor and thus do not count as invariants.
It further follows that \Tf{I_5 = I_1\TknI[]}
so we are left with the three basic invariants
\Tf{I_1 = \tro{\T[2]{T}}\Tk[]} \Tf{ I_2 = \tro{\T[2]{T}^2}\Tk[]}
\Tf{I_4 = \tro{\T[2]{T}^3} \Tp[]}
The determinant of an orthogonal tensor is, according to Section~\ref{3.13.2}, equal to $\pm 1$, and the cotensor is, according to (\ref{3.14}), equal to the tensor itself, up to the sign.
Thus, we have for the main invariants,
according to (\ref{3.41})--(\ref{3.43}),
\Tf{ A^{\prime\prime} = \tro{\T[2]{T}} \Tk[]}
\Tf{ A^\prime = \pm \tro{\T[2]{T}} \Tk[]}  \Tf{ A = \pm 1 \Tsk[]}
then it follows from (\ref{3.95}) that
\Tf{ \tro{ \T[2]{T}^2 } = \trn{2}{ \T[2]{T} } \mp 2 \: \tro{ \T[2]{T} } \Tk[] }
\Tf{ \tro{ \T[2]{T}^3 } = \trn{3}{ \T[2]{T} } \mp 3 \: \trn{2}{ \T[2]{T} } \pm 3 \Tk[]}
so an orthogonal tensor has only one irreducible invariant \Tf{ I_1 = \tr{ \T[2]{T} } \Tp}
}

\ParNo{5.}
\geen{Im n"achsten Beispiel betrachten wir den auch f"ur die physikalische
Anwendung wichtigen Fall zweier symmetrischer Tensoren $\T[2]{U}$ und $\T[2]{V}\Tp[]$
Da es hierbei keinen Unterschied zwischen Tensoren und transponierten Tensoren gibt,
k"onnen wir aus (\ref{irreduzible_invarianten_a_b}) mit Sicherheit eine
Integrit"atsbasis gewinnen.
Wir setzen in (\ref{irreduzible_invarianten_a_b})
\Tf{\T[2]{a} = \T[2]{U}\Tk[]} \Tf{\T[2]{b} = \T[2]{V}}
und "ubernehmen die ersten zehn Invarianten,
nur die Invariante sechsten Grades geh"ort nicht zur Integrit"atsbasis,
da sie sich als reduzibel herausstellt.
Einerseits folgt aus der Symmetrie unter Beachtung von zyklischer Vertauschung
und Transposition (\ref{Spur_zyklisch}) bis (\ref{Spur_Potenz_transponiert})}{
As our next example we consider the case of two symmetric tensors $\T[2]{U}$ and $\T[2]{V}\Tk[]$
which is also important for physical applications.
Now we do not need to distinguish between the tensors and their transposed tensors, so we certainly can obtain an integrity basis from (\ref{irreduzible_invarianten_a_b}).
We set \Tf{\T[2]{a} = \T[2]{U}\Tk[]} \Tf{\T[2]{b} = \T[2]{V}}
in (\ref{irreduzible_invarianten_a_b})
and keep the first 10 invariants.
Only the invariant of degree six does not belong to the integrity basis because it turns out to be reducible.
On the one hand, from the symmetry of the tensors and by taking  cyclic permutations and transposition (\ref{Spur_zyklisch})--(\ref{Spur_Potenz_transponiert}) into account, it follows that
}
%
\Af{
 \tr{\T[2]{U}^2 \cdot \T[2]{V} \cdot \T[2]{U} \cdot \T[2]{V}^2 }
 =
 \tr{ (\T[2]{V}^2)^\tT \cdot \T[2]{U}^\tT \cdot \T[2]{V}^\tT \cdot (\T[2]{U}^2)^\tT }
 =
\tr{ \T[2]{U}^2 \cdot \T[2]{V}^2 \cdot \T[2]{U} \cdot \T[2]{V} } \Tk
}
\geen{andererseits liefert (\ref{aequivalenz_invarianten})}{and on the other hand, from (\ref{aequivalenz_invarianten}), we get}
\Af{
 \tr{\T[2]{U}^2 \cdot \T[2]{V} \cdot \T[2]{U} \cdot \T[2]{V}^2 }
 =
 \tr{\T[2]{U} \cdot (\T[2]{U} \cdot  \T[2]{V}) \cdot \T[2]{U} \cdot \T[2]{V}^2 }
 \equiv
 - \underbrace{\tr{\T[2]{U}^3 \cdot \T[2]{V}^3 }}_{\Ds \equiv 0}
 - \tr{\T[2]{U}^2 \cdot \T[2]{V}^2 \cdot  \T[2]{U} \cdot \T[2]{V} } \Tp
}
\geen{Der Vergleich der beiden Beziehungen ergibt}{
The comparison of these two relations yields}
\Af{
 \tr{\T[2]{U}^2 \cdot \T[2]{V} \cdot \T[2]{U} \cdot \T[2]{V}^2 }
 \equiv
 -\tr{\T[2]{U}^2 \cdot \T[2]{V} \cdot \T[2]{U} \cdot \T[2]{V}^2 }\Tk
}
\geen{was nur m"oglich ist, wenn}{which is only possible if}
\Tf{ \tr{\T[2]{U}^2 \cdot \T[2]{V} \cdot \T[2]{U} \cdot \T[2]{V}^2 } \equiv 0,}
%
\geen{und damit reduzibel ist.}{and thus it is reducible.}

\geen{Wir erhalten also f"ur zwei symmetrische Tensoren \T[2]{U} und \T[2]{V}
eine Integrit"atsbasis,
die insgesamt zehn irreduzible Invarianten umfasst:}{
So we find that the integrity basis of two symmetric tensors \T[2]{U} and \T[2]{V} consists of ten irreducible invariants:
}
%

\begin{itemize}
 \item
 \geen{zun"achst die Grundinvarianten}{the basic invariants}

  \noindent\tro{\T[2]{U}}\Tk\tro{\T[2]{U}^2}\Tk\tro{\T[2]{U}^3}
%
  \geen{und}{and}
%
  \tro{\T[2]{V}}\Tk\tro{\T[2]{V}^2}\Tk\tro{\T[2]{V}^3}
%
  \geen{der einzelnen Tensoren,}{of each of the tensors and}

 \item
  \geen{au"serdem die Simultaninvarianten}{the simultaneous invariants}

  \noindent\tr{\T[2]{U} \cdot \T[2]{V}}\Tk\tr{\T[2]{U}^2 \cdot \T[2]{V}}\Tk
  \tr{\T[2]{U} \cdot \T[2]{V}^2}\Tk\tr{\T[2]{U}^2 \cdot \T[2]{V}^2}\Tp
\end{itemize}

\begin{problem}
\label{U5.3}
\mbox{}

\noindent
\geen{Man bestimme alle irreduziblen Invarianten, die sich aus zwei antimetrischen Tensoren
\Uf{\T[2]{A}} und \Uf{\T[2]{B}} bilden lassen, und
vergleiche das Ergebnis mit den
Invarianten zweier Vektoren aus Abschnitt~\ref{5.3.1}.}{
Find all irreducible invariants which can be computed from  two antimetric tensors \Uf{\T[2]{A}} and \Uf{\T[2]{B}},
and compare the result with the
invariants of two vectors from Section~\ref{5.3.1}.
}

\geen{L"osungshinweis: Zum Nachweis der Reduzibilit"at von
\Uf{ \tr{ \T[2]{A}^2  \cdot \T[2]{B}^2 } } stelle man die
antimetrischen Tensoren \Uf{\T[2]{A}} und \Uf{\T[2]{B}} vor"ubergehend
durch die zugeh"origen Vektoren dar.}{Hint:
To show that
\Uf{ \tr{ \T[2]{A}^2  \cdot \T[2]{B}^2 } } is reducible,
represent the two antimetric tensors \Uf{\T[2]{A}} and \Uf{\T[2]{B}} temporarily by their corresponding vectors.
}
\end{problem}

\ParNoo{6.}
\geen{
Im letzten Beispiel untersuchen wir die Invarianten,
die sich aus einem symmetrischen Tensor $\T[2]{S}$ und einem
antimetrischen Tensor $\T[2]{A}$ bilden lassen.
Auch in diesem Fall k"onnen wir aus
(\ref{irreduzible_invarianten_a_b})
eine Integrit"atsbasis ableiten,
da sich Tensoren und transponierte Tensoren h"ochstens um das
Vorzeichen unterscheiden.
Wenn wir in (\ref{irreduzible_invarianten_a_b})
\Tf{ \T[2]{a} = \T[2]{S} \Tk \T[2]{b} = \T[2]{A}}
setzen, sind einige Invarianten null, weil neben der Spur eines antimetrischen Tensors
und der Spur seiner ebenfalls antimetrischen dritten Potenz
gem"a"s (\ref{Spur_symmetrisch_antimetrisch}) auch
die Spur eines Skalarprodukts aus einem symmetrischen und einem antimetrischen Tensor
verschwindet. Im Einzelnen gilt deshalb
\Tf{ I_{12} = I_{23} = I_{32} = I_{33} = 0 \Tp}
Anders als im zuvor betrachteten Fall zweier symmetrischer Tensoren ist die Invariante
sechsten Grades nicht reduzibel.
Unter Ausnutzung von zyklischer Vertauschung
und Transposition (\ref{Spur_zyklisch}) bis
(\ref{irreduzible_invarianten_a_b})
folgt zun"achst}{
As a last example,
we investigate the invariants of a symmetric tensor $\T[2]{S}$ and an antimetric tensor $\T[2]{A}$.
Also for this case we can obtain an integrity basis
from (\ref{irreduzible_invarianten_a_b}),
since the tensors and their transposed tensors differ at most by a sign.
If we set \Lb \Tf{ \T[2]{a} = \T[2]{S} \Tk \T[2]{b} = \T[2]{A}} in (\ref{irreduzible_invarianten_a_b}), some invariants are zero,
%partly because the trace of an antimetric tensor is zero and the trace of its (also antimetric) third power is also zero, partly
because not only the trace of an antimetric tensor and its (also antimetric) third power is zero but also, according to
(\ref{Spur_symmetrisch_antimetrisch}),
the trace of the scalar product of a symmetric tensor and an antimetric tensor
is zero. Thus, we have
\Tf{ I_{12} = I_{23} = I_{32} = I_{33} = 0 \Tp}
Contrary to the case of two symmetric tensors, here the invariant of degree six is not reducible.
Using cyclic permutations and transposition (\ref{Spur_zyklisch})--(\ref{Spur_Potenz_transponiert}), we initially have
}
%
\Af{
 \tr{\T[2]{S}^2 \cdot \T[2]{A} \cdot \T[2]{S} \cdot \T[2]{A}^2 }
 =
 \tr{ (\T[2]{A}^2)^\tT \cdot \T[2]{S}^\tT \cdot \T[2]{A}^\tT \cdot (\T[2]{S}^2)^\tT }
 =
 - \tr{ \T[2]{A}^2 \cdot \T[2]{S} \cdot \T[2]{A} \cdot \T[2]{S}^2 } \Tk
}
%
\geen{au"serdem ergibt (\ref{aequivalenz_invarianten})}{and from (\ref{aequivalenz_invarianten}) we further obtain that}
\Af{
 \tr{\T[2]{S}^2 \cdot \T[2]{A} \cdot \T[2]{S} \cdot \T[2]{A}^2 }
 =
 \tr{\T[2]{S} \cdot (\T[2]{S} \cdot  \T[2]{A}) \cdot \T[2]{S} \cdot \T[2]{A}^2 }
 \equiv
 - \underbrace{\tr{\T[2]{S}^3 \cdot \T[2]{A}^3 }}_{\Ds = 0}
 - \tr{\T[2]{S}^2 \cdot \T[2]{A}^2 \cdot  \T[2]{S} \cdot \T[2]{A} } \Tp
}
\geen{Der Vergleich der beiden Beziehungen resultiert dann in der trivialen Aussage}{Comparing these two equations leads to the trivial statement
\Tf{
 \tr{\T[2]{S}^2 \cdot \T[2]{A} \cdot \T[2]{S} \cdot \T[2]{A}^2 }
\Lb \equiv
 \tr{\T[2]{S}^2 \cdot \T[2]{A} \cdot \T[2]{S} \cdot \T[2]{A}^2 }\Tk
}
i.\,e.\ we obtain no additional information about this invariant.}
%\geen{d.\,h. es entsteht keine zus"atzliche Information "uber diese Invariante.}{}
%\Pb

\geen{Wir erhalten damit f"ur einen symmetrischen Tensor
$\T[2]{S}$ und einen antimetrischen Tensor $\T[2]{A}$
eine Integrit"atsbasis, die insgesamt sieben irreduzible Invarianten umfasst:}{
We thus obtain for the integrity basis of a symmetric tensor
$\T[2]{S}$ and an antimetric tensor $\T[2]{A}$
a total of seven irreducible invariants:}
%
\begin{itemize}
 \item
  \geen{zun"achst die Grundinvarianten}{the basic invariants}

  \noindent\tro{\T[2]{S}}\Tk\tro{\T[2]{S}^2}\Tk\tro{\T[2]{S}^3}
%
  \geen{und}{and}
%
  \tro{\T[2]{A}^2}
%
  \geen{der einzelnen Tensoren,}{of each of the tensors,}

 \item
  \geen{au"serdem die Simultaninvarianten}{and also the simultaneous invariants}

  \noindent\tr{ \T[2]{S} \cdot \T[2]{A}^2}\Tk \tr{ \T[2]{S}^2 \cdot \T[2]{A}^2}\Tk
  \tr{ \T[2]{S}^2 \cdot \T[2]{A} \cdot \T[2]{S} \cdot \T[2]{A}^2 }\Tp
\end{itemize}\vfill\eject\vspace*{-18pt}

\begin{problem} % Aufgabe 5.4
\label{U5.4}
\mbox{}

\noindent
\geen{Man bestimme alle irreduziblen Invarianten, die sich aus einem polaren symmetrischen Tensor
\Uf{\T[2]{S}} und einem  Vektor \Uf{\T{u}} bilden lassen,
und vergleiche das Ergebnis mit den Invarianten eines symmetrischen
und eines antimetrischen Tensors. Man unterscheide au"serdem die F"alle,
in denen \Uf{\T{u}} polar oder axial ist.}{
Find all irreducible invariants
which can be formed from a polar symmetric tensor
\Uf{\T[2]{S}} and a vector \Uf{\T{u}},
and compare the result with the invariants of a symmetric tensor and an antimetric tensor.
Also, distinguish the cases
where \Uf{\T{u}} is polar or axial.\looseness=0}
\end{problem}
\vspace*{-12pt}

%\Pb
\geen{\subsection{Zusammenfassung}}{
\subsection{Summary}}
\label{5.3.4}

\geen{Wir fassen die Ergebnisse des Abschnitts~\ref{Abschnitt-5.3} noch einmal in
Tabellenform zusammen. Dabei steht \T[2]{T} f"ur einen beliebigen Tensor,
\T[2]{R} f"ur einen orthogonalen Tensor;
\T[2]{S}, \T[2]{U}, \T[2]{V} bezeichnen symmetrische Tensoren,
\T[2]{A}, \T[2]{B} antimetrische Tensoren und \T{u}, \T{v}, \T{w} Vektoren.
Alle Vektoren und Tensoren sind polar.}{
We finally summarize the results of Section~\ref{Abschnitt-5.3} in a table.
Here \T[2]{T} denotes an arbitrary tensor,
\T[2]{R} is an orthogonal tensor,
\T[2]{S}, \T[2]{U}, \T[2]{V} are symmetric tensors,
\T[2]{A}, \T[2]{B} are antimetric tensors,
and \T{u}, \T{v}, \T{w} are vectors.
All vectors and tensors are polar.\vspace*{-6pt}}
\begin{table}[h]
\begin{tabular}{ll}%\hline
%Argumente & Integrit"atsbasis
Arguments & Integrity basis
\\ \midrule\starttabularbody
\T{u} & $\T{u} \cdot \T{u}$ \rule[-2.1ex]{0ex}{0ex}\\
\T{u}, \T{v}  & $\T{u} \cdot \T{u}\Tk \ \T{v} \cdot \T{v}\Tk \
                          \T{u} \cdot \T{v}$ \rule[-2.1ex]{0ex}{0ex}\\
\T{u}, \T{v}, \T{w}  & $\T{u} \cdot \T{u}\Tk \
                                       \T{v} \cdot \T{v}\Tk \
                                       \T{w} \cdot \T{w}\Tk \
                                       \T{u} \cdot \T{v}\Tk \
                                       \T{u} \cdot \T{w}\Tk \
                                       \T{v} \cdot \T{w}$ \rule[-2.1ex]{0ex}{0ex}\\
\T[2]{T} & \tro{\T[2]{T}}\Tk \ \tro{\T[2]{T}^2}\Tk \ \tro{\T[2]{T}^3}\Tk \ \rule[-1.5ex]{0ex}{0ex}
\tr{\T[2]{T} \cdot \T[2]{T}^{\tT} }\Tk \ \tr{\T[2]{T}^2 \cdot \T[2]{T}^{\tT} }\Tk \ \\
          & \tr{\T[2]{T}^2 \cdot (\T[2]{T}^{\tT})^2}\Tk \
            \tr{\T[2]{T}^2 \cdot \T[2]{T}^\tT  \cdot \T[2]{T} \cdot ( \T[2]{T}^\tT )^2  }\rule[-2.1ex]{0ex}{0ex}
\\
\T[2]{S} & \tro{\T[2]{S}}\Tk \ \tro{\T[2]{S}^2}\Tk \ \tro{\T[2]{S}^3}
\rule[-2.1ex]{0ex}{0ex}\\
\T[2]{A} & \tro{\T[2]{A}^2}
\rule[-2.1ex]{0ex}{0ex}\\
\T[2]{R} & \tro{\T[2]{R}}
\rule[-2.1ex]{0ex}{0ex}\\\rule[-1.5ex]{0ex}{0ex}%
\T[2]{U}, \T[2]{V}  & \tro{\T[2]{U}}\Tk \ \tro{\T[2]{U}^2}\Tk \ \tro{\T[2]{U}^3}\Tk \
                          \tro{\T[2]{V}}\Tk \ \tro{\T[2]{V}^2}\Tk \ \tro{\T[2]{V}^3}\Tk\\
 &                      \tr{\T[2]{U} \cdot \T[2]{V}}\Tk \
                                           \tr{\T[2]{U}^2 \cdot \T[2]{V}}\Tk \
                                           \tr{\T[2]{U} \cdot \T[2]{V}^2}\Tk \
                                           \tr{\T[2]{U}^2 \cdot \T[2]{V}^2}
\rule[-2.1ex]{0ex}{0ex}\\
\T[2]{A}, \T[2]{B}  & \tro{\T[2]{A}^2}\Tk \ \tro{\T[2]{B}^2}\Tk \
                            \tr{\T[2]{A} \cdot \T[2]{B}}
\rule[-2.1ex]{0ex}{0ex}\\
\T[2]{S}, \T[2]{A}& \tro{\T[2]{S}}\Tk \ \tro{\T[2]{S}^2}\Tk \ \tro{\T[2]{S}^3}\Tk \
                          \tro{\T[2]{A}^2}\Tk \ \tr{\T[2]{S} \cdot \T[2]{A}^2}\Tk \
\rule[-1.5ex]{0ex}{0ex}\\
                        & \tr{\T[2]{S}^2 \cdot \T[2]{A}^2}\Tk \
                          \tr{\T[2]{S}^2 \cdot \T[2]{A} \cdot \T[2]{S} \cdot \T[2]{A}^2}
\rule[-2.1ex]{0ex}{0ex}\\
\T[2]{S}, \T{u} & \tro{\T[2]{S}}\Tk \ \tro{\T[2]{S}^2}\Tk \ \tro{\T[2]{S}^3}\Tk \
                          $\T{u} \cdot \T{u}\Tk \
                           \T{u} \cdot \T[2]{S} \cdot \T{u}\Tk \
                           \T{u} \cdot \T[2]{S}^2 \cdot \T{u}$  \\
\end{tabular}
\end{table}
\vspace*{-24pt}

\section{\geen{Isotrope Tensorfunktionen}{Isotropic Tensor Functions}}
\label{Abschnitt-5.4}
\subsection{\geen{Invarianzbedingungen}{Invariance Conditions}}
\label{5.4.1}

\geen{\index{Invarianzbedingung f\"ur Tensorfunktionen|(}%
\index{Tensorfunktionen!Invarianzbedingung@, Invarianzbedingung f"ur|(}%
Tensoren k"onnen untereinander nicht durch beliebige Funktionen verkn"upft
werden, da beim "Ubergang auf ein anderes kartesisches Koordinatensystem
auch der Funktionswert das entsprechende Transformationsgesetz f"ur
Tensorkoordinaten erf"ullen muss.
Wir betrachten eine Menge von polaren Vektoren $\T{v}\Tk \ldots\Tk\T{w}$
und polaren Tensoren zweiter Stufe $\T[2]{M}\Tk\ldots\Tk\T[2]{N}$
als Argumente von Tensorfunktionen $\mathscr{F}$ verschiedener tensorieller Stufe.
\index{Tensorfunktion}%
Bei einem Wechsel des kartesischen Koordinatensystems gelten f"ur die
Koordinaten der Argumente nach (\ref{2.17}) die Transformationsgleichungen}{
\index{invariance condition for tensor functions|(}%
\index{tensor functions!invariance condition@, invariance condition for|(}%
Tensors cannot be related by arbitrary functions,
because the function value must satisfy the corresponding
transformation law for tensor coordinates
under a change to another Cartesian coordinate system.
Let polar vectors $\T{v}\Tk \ldots\Tk\T{w}$ and
polar second-order tensors $\T[2]{M}\Tk\ldots\Tk\T[2]{N}$ be
arguments of tensor functions $\mathscr{F}$ of
various orders.\index{tensor function}
Under a change of the Cartesian coordinate system we have for the coordinates of the
arguments, according to (\ref{2.17}),  the transformation equations
}
%
\Af{\begin{array}{@{}>{\rule[-2ex]{0ex}{0ex}}l}
 \Tilde{v}_i = \alpha_{pi} \: v_{p} \TknI \ldots \Tk
 \Tilde{w}_j = \alpha_{qj} \: w_{q} \TknI \\
 \Tilde{M}_{kl} = \alpha_{pk} \: \alpha_{ql} \: M_{pq} \TknI \ldots \Tk
 \Tilde{N}_{mn} = \alpha_{pm} \: \alpha_{qn} \: N_{pq} \TpnI
\end{array}}
%
\geen{Je nach der tensoriellen Stufe erh"alt man dann f"ur die Funktion $\mathscr{F}$
verschiedene Bedingungen:}{
Depending on the order of the tensors, we obtain different conditions for the function~$\mathscr{F}$:
}

\begin{itemize}
 \item
  \geen{Ein polarer Skalar
  \Tf{ s = f( \T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N} )}
  darf sich beim Wechsel des Koordinatensystems nicht "andern,}{
   A polar scalar
  \Tf{ s = f( \T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N} )}
   must remain unchanged under a transformation of the coordinate system,}
%
\Af{
   f( v_i\TknI \ldots \Tk w_j \TknI M_{kl} \TknI \ldots \Tk N_{mn} ) =
   f( \Tilde{v}_i \TknI \ldots \Tk \Tilde{w}_j \TknI
        \Tilde{M}_{kl} \TknI \ldots \Tk \Tilde{N}_{mn} ) \Tk}
%
  \geen{deshalb gilt f"ur die Funktion $f$:}
{and then it follows for the function $f$ that}
  \begin{equation}
   \label{skalarfunktion}
\begin{array}{@{}l}
f( v_i \TknI \ldots \Tk w_j\TknI M_{kl} \TknI \ldots \Tk N_{mn} ) \hspace{6ex}\\
\multicolumn{1}{r}{ =f( \alpha_{pi}\: v_{p} \TknI \ldots \Tk \alpha_{qj}\: w_{q} \TknI
        \alpha_{pk} \: \alpha_{ql} \: M_{pq} \TknI \ldots \Tk
 \alpha_{pm} \: \alpha_{qn} \: N_{pq}
    ) \Fp}
\end{array}
  \end{equation}

 \item
  \geen{Bei einem polaren Vektor
  \Tf{ \T{u} = \T{f}( \T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk
\T[2]{N} )}
  m"ussen beim Einsetzen der transformierten Koordinaten
  $\Tilde{v}_i\TknI\ldots\Tk\Tilde{w}_j\TknI$
  $\Tilde{M}_{kl}\TknI\ldots\Tk\Tilde{N}_{mn}$
  die transformierten Koordinaten}{
  For a polar vector \Tf{ \T{u} = \T{f}( \T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk
\T[2]{N} )\Tk[]} substituting the transformed coordinates
 $\Tilde{v}_i\TknI\ldots\Tk\Tilde{w}_j\TknI$
  $\Tilde{M}_{kl}\TknI\ldots\Tk\Tilde{N}_{mn}$
  must give the transformed vector coordinates
  }
%
\Af{   \Tilde{u}_r = \alpha_{ur} \: u_u =
   f_r( \Tilde{v}_i \TknI \ldots \Tk \Tilde{w}_j \TknI
          \Tilde{M}_{kl} \TknI \ldots \Tk \Tilde{N}_{mn} )\Fp}
  \geen{entstehen. In den urspr"unglichen Koordinaten gilt}
   {In the original coordinates, we have}
%
\Af{   u_u = f_u( v_i \TknI \ldots \Tk w_j \TknI M_{kl} \TknI \ldots \Tk N_{mn} ) \Tk}
  \geen{also folgt f"ur die Funktion \T{f}:}{
  so it follows for the function \T{f} that}
  \begin{equation}
   \label{vektorfunktion}
\begin{array}{@{}l}
\alpha_{ur} \: f_u( v_i \TknI \ldots \Tk w_j \TknI M_{kl} \TknI \ldots \Tk N_{mn} )\\
\multicolumn{1}{r}{ = f_r( \alpha_{pi}\: v_{p} \TknI \ldots \Tk \alpha_{qj}\: w_{q} \TknI
\alpha_{pk} \: \alpha_{ql} \: M_{pq} \TknI \ldots \Tk  \alpha_{pm} \: \alpha_{qn} \: N_{pq}) \Fp}
\end{array}
  \end{equation}

 \item
  \geen{Bei einem polaren Tensor
  \Tf{ \T[2]{T} = \T[2]{f}( \T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N} )}
  zweiter Stufe m"ussen sich entsprechend beim Einsetzen der transformierten
Koordinaten
  $\Tilde{v}_i\Tk\ldots\Tk\Tilde{w}_j\TknI$
  $\Tilde{M}_{kl}\Tk\ldots\Tk\Tilde{N}_{mn}$
  die transformierten Koordinaten}{
For a polar second-order tensor
  \Tf{ \T[2]{T} = \T[2]{f}( \T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N} )\TknI[]}
   substituting the transformed coordinates
  $\Tilde{v}_i\Tk\ldots\Tk\Tilde{w}_j\TknI$
  $\Tilde{M}_{kl}\Tk\ldots\Tk\Tilde{N}_{mn}$
  must give the transformed tensor coordinates}
%
\Af{\Tilde{T}_{rs} = \alpha_{ur} \: \alpha_{vs} \: T_{uv} =
   f_{rs}( \Tilde{v}_i \TknI \ldots \Tk \Tilde{w}_j \TknI
          \Tilde{M}_{kl} \TknI \ldots \Tk \Tilde{N}_{mn} )\Fp}
  \geen{ergeben. Mit}{With}
%
\Af{   T_{uv} = f_{uv}( v_i \TknI \ldots \Tk w_j \TknI M_{kl} \TknI \ldots\Tk N_{mn} ) \Tk  }
  \geen{folgt dann f"ur die Funktion \T[2]{f}:}{we then obtain  for the function \T[2]{f}}
  \begin{equation}
   \label{tensorfunktion}
\begin{array}{@{}l}
\alpha_{ur} \: \alpha_{vs} \: f_{uv}( v_i \TknI \ldots \Tk w_j \TknI M_{kl} \TknI \ldots \Tk N_{mn} )  \\
\multicolumn{1}{r}{ =f_{rs} \, ( \alpha_{pi} \: v_{p} \TknI \ldots \Tk \alpha_{qj}\: w_{q} \TknI
\alpha_{pk} \: \alpha_{ql} \: M_{pq} \TknI \ldots \Tk  \alpha_{pm} \: \alpha_{qn} \: N_{pq}
   ) \Fp}
\end{array}
  \end{equation}
\end{itemize}
%
\geen{\index{Tensorfunktion!isotrope@, isotrope}\index{isotrope Tensorfunktion}
Falls die Transformationskoeffizienten $\alpha_{ij}$ eine beliebige orthogonale
Matrix sein k"onnen (man sagt dann auch, dass sie alle orthogonalen
Transformationen umfassen), spricht man bei (\ref{skalarfunktion}),
(\ref{vektorfunktion}) und (\ref{tensorfunktion})
von isotropen Tensorfunktionen.}{
\index{tensor function!isotropic@, isotropic}%
\index{isotropic!tensor function@ tensor function}%
If the transformation coefficients $\alpha_{ij}$ form an arbitrary orthogonal matrix
(we also say that they encompass
all orthogonal transformations), we call (\ref{skalarfunktion}),
(\ref{vektorfunktion}) and (\ref{tensorfunktion}) isotropic tensor functions.
}

\geen{Die Funktionen
(\ref{skalarfunktion}), (\ref{vektorfunktion}) und (\ref{tensorfunktion})
k"onnen grunds"atzlich auch noch von polaren Skalaren abh"angen;
da sich hieraus keine Einschr"ankungen f"ur die Funktionen ergeben,
haben wir sie nicht in die Liste der Argumente aufgenommen.}{
The functions (\ref{skalarfunktion}),
(\ref{vektorfunktion}), and (\ref{tensorfunktion})
can in general further depend on polar scalars; since this does not impose any restrictions on the functions,
we did not include scalars in the list of arguments.
}

\geen{\index{Invarianzbedingung f\"ur Tensorfunktionen|)}%
\index{Tensorfunktionen!Invarianzbedingung@, Invarianzbedingung f"ur|)}%
Wir haben die Invarianzbedingungen hier nur f"ur polare Tensoren formuliert,
sie lassen sich jedoch mithilfe der Transformationsgleichungen (\ref{2.18})
leicht auf axiale Tensoren "ubertragen.}{
\index{invariance condition for tensor functions|)}%
\index{tensor functions!invariance condition@, invariance condition for|)}%
We derived the invariance conditions here only for polar tensors, but they can be easily transferred to axial tensors by means of the transformation equations (\ref{2.18}).
}

\subsection{\geen{Skalarwertige Funktionen}{Scalar-Valued Functions}}
\label{5.4.2}

\geen{\index{Tensorfunktion!skalarwertige@, skalarwertige|(}%
\index{skalarwertige Funktion|(}%
Um die Invarianzbedingung (\ref{skalarfunktion}) zu erf"ullen, darf ein Skalar
nicht von einzelnen Tensorkoordinaten abh"angen, weil diese sich in der Regel
beim Wechsel des Koordinatensystems "andern, sondern nur von solchen
Kombinationen, die selbst Invarianten und damit ebenfalls Skalare sind.
Wenn sich aus den Koordinaten von
$\T{v}\Tk\ldots\Tk\T{w}\Tk\T[2]{M}\Tk\ldots\Tk\T[2]{N}$
eine Integrit"atsbasis mit $P$ irreduziblen Invarianten $I_1\TknI\ldots\Tk I_P$
bilden l"asst, folgt daraus f"ur die skalarwertige Funktion~$f$:}{
\index{tensor function!scalar-valued@, scalar-valued|(}%
\index{scalar-valued function|(}%
In order to satisfy the invariance condition (\ref{skalarfunktion}),
a scalar cannot depend on individual tensor coordinates,
because, in general, coordinates change under a transformation of the coordinate system,
so a scalar can only depend on combinations of coordinates
which are invariants and thus also scalars.
If it is possible to form an integrity basis with $P$
irreducible invariants $I_1\TknI\ldots\Tk I_P$
from the coordinates $\T{v}\Tk\ldots\Tk\T{w}\Tk\T[2]{M}\Tk\ldots\Tk\T[2]{N}$,
then the scalar-valued function~$f$ satisfies
}
%
\begin{equation}
 s = f( \T{v} \Tk  \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N} )
   = f( I_1 \TknI I_2 \TknI \ldots \Tk I_P) \Fp
\end{equation}
%
\geen{\index{Tensorfunktion!skalarwertige@, skalarwertige|)}
\index{skalarwertige Funktion|)}
Weitere Informationen "uber die Funktion $f$ lassen sich mithilfe der
Darstellungstheorie nicht gewinnen, in Zusammenhang mit einem physikalischen
Problem ist man daher auf Experimente angewiesen.
Die Art und die Anzahl $P$ der Invarianten $I_1\TknI\ldots\Tk I_P$ h"angen vom
jeweils betrachteten Einzelfall ab und m"ussen nach den Regeln des
Abschnitts~\ref{Abschnitt-5.3} bestimmt werden.}{
\index{tensor function!scalar-valued@, scalar-valued|)}%
\index{scalar-valued function|)}%
The theory of the representation of tensor functions does not provide any more information about the function $f$, so
for a particular physical process one has to rely on experiments.
The type and the number $P$ of the invariants $I_1\TknI\ldots\Tk I_P$ depend on the particular
case and must be determined according to the rules from
Section~\ref{Abschnitt-5.3}.
}

\subsection{\geen{Vektorwertige Funktionen}{Vector-Valued Functions}}
\label{5.4.3}

\ParNoo{1.}
\geen{\index{Tensorfunktion!vektorwertige@, vektorwertige|(}%
\index{vektorwertige Funktion|(}
Aus einem Vektor l"asst sich durch skalare Multiplikation mit einem anderen
Vektor ein Skalar erzeugen. Wenn man daher eine vektorwertige Funktion~\T{f}
mit einem beliebigen Hilfsvektor~\T{h}
skalar multipliziert und den Hilfsvektor in die Liste der Argumente aufnimmt,
kann man die Suche nach Darstellung einer vektorwertigen Funktion auf
das Problem der Darstellung einer skalarwertigen Funktion zur"uckf"uhren:}{
\index{tensor function!vector-valued@, vector-valued|(}%
\index{vector-valued function|(}%
We can obtain a scalar from a vector by means of the scalar product of the vector and another vector.
This suggests that, with the help of the scalar product of the
vector-valued function~\T{f} and
an arbitrary auxiliary vector~\T{h}
and by adding the auxiliary vector to the argument list,
we can reduce the problem of finding a representation
of a vector-valued function to the problem
of finding a representation of a scalar-valued function:
}
%
\Af{
\T{u} \cdot \T{h}
= \T{f}( \T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N} ) \cdot \T{h}
= f( \T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N} \Tk
       \T{h} )\Tp}
%
\geen{Nach Abschnitt~\ref{5.4.2} ist $f$ dann eine Funktion der $P$ irreduziblen
Invarianten $I_1\TknI\ldots\Tk I_P\TknI$ die sich aus
$\T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N}$
bilden lassen, au"serdem kommen noch die Simultaninvarianten unter Beteiligung
von \T{h} hinzu. Da \T{h} jedoch nur ein Hilfsvektor ist, der am Ende
in der vektorwertigen Funktion \T{f} wieder herausfallen muss,
brauchen wir von der zweiten Gruppe nur diejenigen Simultaninvarianten
zu ber"ucksichtigen, die linear in \T{h} sind.
Solche Simultaninvarianten haben die Form
$\T{J}\,_{i} \cdot \T{h}$, wobei die $\T{J}\,_{i}$ ein im Einzelfall
zu bestimmender Satz von $Q$ Vektoren sind, die sich aus $\T{v} \Tk \ldots
\Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N}$ bilden lassen.
Die Vektoren $\T{J}\,_{i}$ bezeichnet man auch als Generatoren der
Darstellung,\index{Generator} ein vollst"andiger Satz von Generatoren hei"st
Funktionsbasis.\index{Funktionsbasis}
Wenn wir die Ausdr"ucke $\T{J}\,_{i} \cdot \T{h}$
superponieren, erhalten wir zun"achst f"ur $\T{u} \cdot \T{h}$
die Darstellung}{
Then $f$ is, according to Section~\ref{5.4.2}, a function of the $P$ irreducible invariants
$I_1\TknI\ldots\Tk I_P\TknI$ which can be formed from the
$\T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N}$
and the simultaneous invariants with a vector \T{h}.
However, since \T{h} is only an auxiliary vector,
which must cancel out from the vector-valued function \T{f} at the end,
we need only those simultaneous invariants which are linear in \T{h}.
These simultaneous invariants have the form $\T{J}\,_{i} \cdot \T{h}$,
where $\T{J}\,_{i}$ is a set of $Q$ vectors, which are computed from the $\T{v} \Tk \ldots
\Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N}$ and which have to be  determined for each case individually.
The vectors $\T{J}\,_{i}$ are also called the generators of the
representation\index{generator} and
a complete set of generators is called a function basis.\index{function basis}
We start by writing $\T{u} \cdot \T{h}$ as a linear combination of the  $\T{J}\,_{i} \cdot \T{h}$, i.\,e.
}
%
\[%\begin{refequation}%[1]
\label{5.4a}%
 \T{u} \cdot \T{h} =
 k_1 \: \T{J}\,_{1} \cdot \T{h} + \xch{\,\cdots\,}{\ldots} + k_Q \: \T{J}\,_{Q} \cdot \T{h} \Tk
\tag{a}
\]%\end{refequation}%
%
\geen{Die Koeffizienten $k_1\TknI\ldots\Tk k_Q$ sind hierbei Skalare, die noch von den
Invarianten $I_1\TknI\ldots\Tk I_P$ der Integrit"atsbasis f"ur
$\T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N}$
abh"angen k"onnen, es gilt also}{
where the coefficients $k_1\TknI\ldots\Tk k_Q$ are scalars which can still depend on the invariants
$I_1\TknI\ldots\Tk I_P$ of the integrity basis for
$\T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N}$, i.\,e.\  we have
}
%
\Af{
 k_i = k_i(  I_1 \TknI \ldots \Tk I_P ) \Tp}
%
\geen{Da jeder Term in (\ref{5.4a}) ein Skalarprodukt mit dem Hilfsvektor \T{h} enth"alt,
k"onnen wir \T{h} am Ende wieder herausk"urzen
und gelangen so zu einer Darstellung f"ur die urspr"unglich betrachtete
vektorwertige Funktion \T{f}, die aufgrund ihrer Konstruktion
automatisch die Invarianzbedingung (\ref{vektorfunktion}) erf"ullt:}{
Since each term in (\ref{5.4a}) is a scalar product with the auxiliary vector \T{h}, we can cancel \T{h} out, and thus we obtain a representation of the original vector-valued function~\T{f}\TknI[]
which inherently satisfies the invariance condition (\ref{vektorfunktion}) due to its construction. We have
}
%
\begin{equation}
 \T{u} = k_1 \: \T{J}\,_{1} + \xch{\,\cdots\,}{\ldots} + k_Q \: \T{J}\,_{Q} \Fp
\end{equation}
%
\geen{Wie man die Generatoren $\T{J}\,_{i}$ in dieser Darstellung im Einzelfall
bestimmt, erl"autern wir an zwei Beispielen.}{
We show by means of two examples
how to determine the generators $\T {J}\,_{i}$ of this representation for a particular case.
}

\ParNo{2.}
\geen{
Im ersten Beispiel suchen wir die Darstellung eines Vektors \T{u},
der nur von einem anderen Vektor \T{v} abh"angt:}{
In the first example, we seek a representation of a vector \T{u}
%\era{,}
which depends only on another vector \T{v},
}
%
\Af{
 \T{u} = \T{f}( \T{v} ) \Tp}
%
\geen{Durch skalare Multiplikation mit einem Hilfsvektor \T{h} entsteht daraus}{
Scalar multiplication with an auxiliary vector \T{h} gives
}
%
\Af{
 \T{u} \cdot \T{h} = f( \T{v}\Tk \T{h} ) \Tp}
%
\geen{Nach Abschnitt~\ref{5.3.1} besitzt der Vektor \T{v} mit seinem Quadrat
$\T{v} \cdot \T{v}$ nur eine einzige irreduzible Invariante,
und aus den Vektoren \T{v} und \T{h} l"asst sich mit dem Skalarprodukt
$\T{v} \cdot \T{h}$ ebenfalls nur eine einzige irreduzible Simultaninvariante
bilden, die zugleich linear in \T{h} ist.
Die Darstellung f"ur den Vektor \T{u} besitzt also nur einen einzigen Generator,
n"amlich den Vektor \T{v} selbst, und lautet:}{
According to Section~\ref{5.3.1}, the vector \T{v} has
only one irreducible invariant, i.\,e.\  its square $\T{v} \cdot \T{v}$\TknI[]
and from the vectors \T{v} and \T{h} we can form
also only one irreducible simultaneous invariant,
and this is linear in~\T{h}\TknI[]
namely the scalar product $\T{v} \cdot \T{h}$.
So the representation of the vector \T{u} has only one generator, namely the vector \T{v} itself,
and we have
}
%
\Af{
 \T{u} = k( \T{v} \cdot \T{v} ) \: \T{v} \Tp}
%
\geen{Die Funktion $k( \T{v} \cdot \T{v} )$ l"asst sich mithilfe der
Darstellungstheorie nicht genauer bestimmen und muss beispielsweise bei einem
physikalischen Problem durch Experimente ermittelt werden.}{
The function
$k( \T{v} \cdot \T{v} )$ cannot be determined further
from the theory of the representation of tensor functions.
For example, for a physical process,
the missing information must be obtained from experiments.
}

\ParNo{3.}
\geen{\index{symmetrischer (Anteil eines) Tensor(s)}\index{Tensor!symmetrischer@, symmetrischer}Im zweiten Beispiel erweitern wir die Funktion \T{f} aus Nr.\,2 um die
Abh"angigkeit von einem symmetrischen Tensor \T[2]{S}, wir suchen also nach
einer Darstellung f"ur}{
\index{symmetric!tensor@ (part of a) tensor}%
\index{tensor!symmetric@, symmetric}%
In a second example,
we extend the function \T{f} from No.\,2 and include a symmetric tensor \T[2]{S},
so we seek a representation for
}
%
\Af{
 \T{u} = \T{f}( \T{v} \Tk \T[2]{S} ) }
%
\geen{bzw. nach skalarer Multiplikation mit einem Hilfsvektor \T{h}:}{
or, after scalar multiplication by an auxiliary vector \T{h},}
%
\Af{
 \T{u} \cdot \T{h} = f( \T{v} \Tk \T[2]{S} \Tk \T{h} ) \Tp}
%
\geen{Wie in Nr.\,2 gibt es das Skalarprodukt $\T{v} \cdot \T{h}$
als in \T{h} lineare Simultaninvariante.
Au"serdem k"onnen wir weitere lineare Simultaninvarianten bilden,
indem wir \T[2]{S} von links und rechts skalar mit \T{v} bzw. \T{h}
multiplizieren; da \T[2]{S} symmetrisch ist, kommt es dabei nicht auf die
Reihenfolge an. Wenn wir auf gleiche Weise auch die ganzzahligen Potenzen von
\T[2]{S} behandeln, erhalten wir zun"achst die Invarianten
$\T{v} \cdot \T[2]{S} \cdot \T{h}\Tk\T{v} \cdot \T[2]{S}^2 \cdot \T{h}$,
$\T{v} \cdot \T[2]{S}^3 \cdot \T{h}$ usw.
Allerdings l"asst sich $\T{v} \cdot \T{h}$ auch als
$\T{v} \cdot \T[2]{\delta} \cdot \T{h}$ schreiben,
dann erkennen wir, dass $\T{v} \cdot \T[2]{S}^3 \cdot \T{h}$
(und entsprechend jeder Ausdruck mit h"oheren Potenzen von \T[2]{S})
reduzibel ist, weil sich $\T[2]{S}^3$ mithilfe der
Cayley-Hamilton-Gleichung (\ref{3.88})
durch $\T[2]{S}^2$, \T[2]{S} und \T[2]{\delta} ausdr"ucken l"asst.
Es gibt also drei Generatoren f"ur die Darstellung des Vektors \T{u}:}{
As in No.\,2, the scalar product $\T{v}\cdot\T{h}$ is a simultaneous invariant which is linear in~\T{h}\TpnI[]
In addition, other
linear simultaneous invariants can be formed with the help
of the scalar product of \T[2]{S} and \T{v} on the left and \T{h} on the right;
since \T[2]{S} is symmetric, the order does not matter.
Doing the same with the integer powers of \T[2]{S} yields  initially the invariants
$\T{v} \cdot \T[2]{S} \cdot \T{h}\Tk\T{v} \cdot \T[2]{S}^2 \cdot \T{h}$\TknI[]
$\T{v} \cdot \T[2]{S}^3 \cdot \T{h}$\Tk[] etc.
Since $\T{v} \cdot \T{h}$ can also be written
as $\T{v} \cdot \T[2]{\delta} \cdot \T{h}$\TknI[] we see that
$\T{v} \cdot \T[2]{S}^3 \cdot \T{h}$
(and correspondingly any expression with higher powers of~\T[2]{S}) is reducible,
because we can write  $\T[2]{S}^3$, using the Cayley--Hamilton theorem (\ref{3.88}),
in terms of $\T[2]{S}^2$\Tk \T[2]{S}\TknI[] and \T[2]{\delta}\TpnI[]
Hence there are three generators for the representation
of the vector \T{u}, i.\,e.}
%
\Af{
 \T{u} = k_1 \: \T{v} + k_2 \: \T{v} \cdot \T[2]{S} + k_3 \: \T{v} \cdot \T[2]{S}^2 \Tp}
%
\geen{Die Koeffizienten $k_1\TknI k_2\TknI k_3$ sind skalarwertige Funktionen
der Invarianten von \T{v} und \T[2]{S}. Da wir nur polare Vektoren und Tensoren
betrachten, folgt aus dem Ergebnis von Aufgabe~\ref{U5.4}}{
The coefficients $k_1\TknI k_2\TknI k_3$ are scalar-valued functions of the invariants of \T{v} and \T[2]{S}.
Since here we consider only polar vectors and tensors, it follows from the result to Problem~\ref{U5.4} that
}
\Af{
 k_i = f( \tro{\T[2]{S}} \Tk \tro{\T[2]{S}^2} \Tk \tro{\T[2]{S}^3} \Tk
            \T{v} \cdot \T{v} \Tk
            \T{v} \cdot \T[2]{S} \cdot \T{v} \Tk \T{v} \cdot \T[2]{S}^2 \cdot \T{v} ) \Tp}

\begin{problem}
\label{U5.5}
\mbox{}

\noindent
\geen{\index{Tensorfunktion!vektorwertige@, vektorwertige|)}
\index{vektorwertige Funktion|)}
Man bestimme die Darstellung eines Vektors \Uf{\T{u}},
der von einem polaren Tensor \Uf{\T[2]{T}} zweiter Stufe abh"angt,
f"ur folgende F"alle:}{
\index{tensor function!vector-valued@, vector-valued|)}%
\index{vector-valued function|)}%
Find the representation of a vector \Uf{\T{u}}
which depends on a polar tensor \Uf{\T[2]{T}}
for the following cases:}

\begin{itemize}
 \item
 \geen{\Uf{\T[2]{T}} ist symmetrisch oder antimetrisch,}{\Uf{\T[2]{T}} is
 symmetric or antimetric\xch{;}{,}}
 \item
  \geen{\Uf{\T{u}} ist polar oder axial.}{\Uf{\T{u}} is polar or axial.}
\end{itemize}
\end{problem}\vspace*{-12pt}

\subsection{\geen{Tensorwertige Funktionen}{Tensor-Valued Functions}}
\label{5.4.4}

\ParNoo{1.}
\geen{\index{Tensorfunktion!tensorwertige@, tensorwertige|(}
\index{tensorwertige Funktion|(}%
Die "Uberlegungen aus Abschnitt~\ref{5.4.3} lassen sich leicht von
vektorwertigen auf tensorwertige Funktionen "ubertragen, indem man einen
beliebigen Hilfstensor \T[2]{H} einf"uhrt und doppelt skalar multipliziert;
durch diese Vorgehensweise ist sichergestellt, dass das Ergebnis
am Ende wieder die Invarianzbedingung (\ref{tensorfunktion})
f"ur tensorwertige Funktionen erf"ullt.  Aus}{
\index{tensor function!tensor-valued@, tensor-valued|(}%
\index{tensor-valued function|(}%
It is easy to generalize our work from Section~\ref{5.4.3}
for vector-valued functions to tensor-valued functions;
we simply introduce an auxiliary tensor \T[2]{H} and use the double scalar product;
this again ensures that the result inherently satisfies the invariance condition
(\ref{tensorfunktion}) for tensor-valued functions.
Then, from
}
%
\Af{
\T[2]{T} = \T[2]{f}( \T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N} )}
%
\geen{wird dadurch vor"ubergehend}{we first get}
%
\Af{
\T[2]{T} \dsP \T[2]{H} =
f( \T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N} \Tk
\T[2]{H} ) \Tp}
%
\geen{Die Generatoren $\T[2]{J}\,_{i}$ sind jetzt Tensoren zweiter Stufe, da die
Simultaninvarianten mit dem Hilfstensor
die lineare Form $\T[2]{J}\,_{i} \dsP \T[2]{H}$
haben m"ussen, damit \T[2]{H} am Ende wieder herausgek"urzt werden kann.
Durch Superposition aller $Q$~Simultaninvarianten erhalten wir dann
f"ur $\T[2]{T} \dsP \T[2]{H}$ die Darstellung}{
The generators $\T[2]{J}\,_{i}$ are now second-order tensors,
because in order for \T[2]{H} to cancel out at the end, the simultaneous invariants with the auxiliary tensor must have the linear form
$\T[2]{J}\,_{i} \dsP \T[2]{H}$.
Then we can represent
$\T[2]{T} \dsP \T[2]{H}$ as the linear combination of all $Q$~simultaneous invariants, i.\,e.\ we have
}
%
\Af{ \T[2]{T} \dsP \T[2]{H} =
 k_1 \: \T[2]{J}\,_{1} \dsP \T[2]{H} \, + \xch{\,\cdots\,}{\ldots} +
 k_Q \: \T[2]{J}\,_{Q} \dsP \T[2]{H}\Fk  }
%
\geen{bzw. nach K"urzen von \T[2]{H} f"ur die urspr"ungliche tensorwertige Funktion \T[2]{f}:}{
and, after canceling \T[2]{H} out, we obtain for the original tensor-valued function \T[2]{f}}
\begin{equation}
 \T[2]{T} =
 k_1 \: \T[2]{J}\,_{1} + \xch{\,\cdots\,}{\ldots} + k_Q \: \T[2]{J}\,_{Q} \Fp
\end{equation}
%
\geen{Die Koeffizienten $k_1\TknI \ldots\Tk k_Q$ sind wie in Abschnitt~\ref{5.4.3}
Skalare, die noch von den Invarianten $I_1\TknI \ldots\Tk I_P$ einer
Integrit"atsbasis f"ur
$\T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N}$
abh"angen k"onnen:}{
As in Section~\ref{5.4.3}, the coefficients $k_1\TknI \ldots\Tk k_Q$
are scalars which can depend
on the invariants $I_1\TknI \ldots\Tk I_P$ of an integrity basis for
$\T{v} \Tk \ldots \Tk \T{w} \Tk \T[2]{M} \Tk \ldots \Tk \T[2]{N}$, i.\,e.}
\Af{
 k_i = k_i(  I_1 \TknI \ldots \Tk I_P ) \Tp}
%
\geen{Die Art und die Anzahl $Q$ der Generatoren
$\T[2]{J}\,_{1}\Tk \ldots\Tk \T[2]{J}\,_{Q}$
lassen sich nur im konkreten Einzelfall bestimmen;
wie, das erl"autern wir wieder an zwei Beispielen.}{
The type and number $Q$ of the generators $\T[2]{J}\,_{1}\Tk \ldots\Tk \T[2]{J}\,_{Q}$ can
only be determined for each particular case;
we will again explain this with two examples.
}

\ParNo{2.}
\geen{\index{symmetrischer (Anteil eines) Tensor(s)}\index{Tensor!symmetrischer@, symmetrischer}
Wir untersuchen zun"achst einen Tensor \T[2]{T} zweiter Stufe, der nur
von einem symmetrischen Tensor \T[2]{S} zweiter Stufe abh"angt,
wir suchen also eine Darstellung f"ur}{
\index{symmetric!tensor@ (part of a) tensor}%
\index{tensor!symmetric@, symmetric}%
We first consider a second-order tensor \T[2]{T}
which depends only on a symmetric second-order tensor \T[2]{S}\TknI[]
so we seek a representation for
}
%
\Af{\T[2]{T} = \T[2]{f}( \T[2]{S} ) \Tp}
%
\geen{Durch doppelte Skalarmultiplikation mit einem Hilfstensor \T[2]{H}
entsteht daraus}{
The double scalar product
with an auxiliary tensor \T[2]{H} gives
}
%
\Af{\T[2]{T} \dsP \T[2]{H} = f( \T[2]{S} \Tk \T[2]{H}  ) \Tp}
%
\geen{Da $\T[2]{S}$ symmetrisch ist und wir nur die in $\T[2]{H}$ linearen Invarianten
ben"otigen, k"onnen wir von (\ref{irreduzible_invarianten_a_b}) ausgehen
und darin \Tf{ \T[2]{a} = \T[2]{S} } und \Tf{ \T[2]{b} = \T[2]{H} } setzen.
Wir erhalten so die drei Grundinvarianten
$\tro{\T[2]{S} }\Tk[]$ $\tro{\T[2]{S}^2 }\Tk[]$ $\tro{\T[2]{S}^3 }$
des symmetrischen Tensors $\T[2]{S}$ und als in $\T[2]{H}$
lineare Invarianten unter Ausnutzung der Symmetrie von $\T[2]{S}$}{
Since $\T[2]{S}$ is symmetric and because we only need the invariants which are linear in~$\T[2]{H}$\TknI[]
we can start from (\ref{irreduzible_invarianten_a_b}) and set there \Tf{ \T[2]{a} = \T[2]{S} } and \Tf{ \T[2]{b} = \T[2]{H} \TpnI[]}
From this we obtain the three basic invariants $\tro{\T[2]{S} }\TknI[]$ $\tro{\T[2]{S}^2 }\Tk$ $\tro{\T[2]{S}^3 }$
of the symmetric tensor $\T[2]{S}$ and, using the symmetry of $\T[2]{S}$\TknI[] the invariants
which are linear in $\T[2]{H},$
}
\Af{
 \begin{array}{@{}l}
 \tro{\T[2]{H}} = H_{ii} =
  \delta_{ij} \: H_{ij} =
  \T[2]{\delta} \dsP \T[2]{H}\rule[-2ex]{0ex}{0ex} \Tk
 \\
 \tr{\T[2]{S} \cdot \T[2]{H} } =
  S_{ij} \: H_{ji} = S_{ij} \: H_{ij} =
  \T[2]{S} \dsP \T[2]{H}\rule[-2ex]{0ex}{0ex} \Tk
 \\
 \tr{\T[2]{S}^2 \cdot \T[2]{H} } =
  S_{ij} \: S_{jk} \: H_{ki} =
  S_{kj} \: S_{ji} \: H_{ki} =
  \T[2]{S}^2 \dsP \T[2]{H} \Tp
 \end{array}
}
\geen{Es gibt also nur die drei Generatoren $\T[2]{\delta}\Tk \T[2]{S}\Tk \T[2]{S}^2$,
damit lautet Darstellung f"ur den Tensor \T[2]{T}:}{
Hence we have three generators $\T[2]{\delta}\Tk \T[2]{S}\Tk \T[2]{S}^2$, and the representation of the tensor \T[2]{T}~is}
\Af{ \T[2]{T} = k_1 \: \T[2]{\delta} + k_2 \: \T[2]{S} + k_3 \: \T[2]{S}^2 \Tk}
%
\geen{Die Koeffizienten $k_1\TknI k_2\TknI k_3$ sind hierbei skalarwertige Funktionen
der drei Grundinvarianten von \T[2]{S}:}{
where the coefficients $k_1\TknI k_2\TknI k_3$ are scalar-valued functions
of the three basic invariants of \T[2]{S}, i.\,e.}
%
\Af{ k_i = f( \tro{\T[2]{S}} \Tk \tro{\T[2]{S}^2} \Tk \tro{\T[2]{S}^3} ) \Tp}
%
\geen{Da der Tensor \T[2]{S} als symmetrisch vorausgesetzt wurde, liefert die
Darstellungstheorie unmittelbar das Ergebnis, dass auch der Tensor \T[2]{T}
symmetrisch sein muss.}{
Since we assumed that the tensor \T[2]{S} is symmetric,
we immediately obtain from the theory of the representation of
tensor functions that the tensor \T[2]{T} must also be symmetric.
}

\ParNo{3.}
\geen{\index{symmetrischer (Anteil eines) Tensor(s)}\index{Tensor!symmetrischer@, symmetrischer}
Im zweiten Beispiel nehmen wir an, dass der Tensor \T[2]{T} nicht nur
von einem symmetrischen Tensor \T[2]{S}, sondern auch noch von einem
Vektor \T{v} abh"angt, d.\,h. wir suchen nach einer Darstellung f"ur}{
\index{symmetric!tensor@ (part of a) tensor}%
\index{tensor!symmetric@, symmetric}%
As a second example, we consider a tensor \T[2]{T}
which depends on a symmetric tensor \T[2]{S}
and also on a vector \T{v}, i.\,e.\ we are looking for a representation for
}
%
\Af{  \T[2]{T} =  \T[2]{f}( \T[2]{S} \Tk \T{v} ) \Tp}
%
\geen{Nach doppelter skalarer Multiplikation mit dem Hilfstensor \T[2]{H} wird daraus}{
The double scalar product with the auxiliary tensor \T[2]{H} gives
}
%
\Af{  \T[2]{T} \dsP \T[2]{H} =  f( \T[2]{S} \Tk \T{v} \Tk \T[2]{H} ) \TpnI[]}
%
\geen{Die Invarianten von \T[2]{S} und \T{v} k"onnen wir aus
Abschnitt~\ref{5.4.3}~Nr.\,3 "ubernehmen, dann bleibt nur noch die Bestimmung
der in \T[2]{H} linearen Simultaninvarianten "ubrig.
Wie in Nr.\,2 finden wir zun"achst}{
We can keep the invariants of \T[2]{S} and \T{v} from Section~\ref{5.4.3},~No.\,3,
so we only need to compute the simultaneous invariants which are linear in \T[2]{H}\TpnI[]
As in No.\,2 we initially find
}
%
\Af{
 \T[2]{\delta} \dsP \T[2]{H} \Tk
 \T[2]{S} \dsP \T[2]{H} \Tk
 \T[2]{S}^2 \dsP \T[2]{H} \TpnI[]}
%
\geen{Mit dem Vektor \T{v} allein k"onnen wir eine weitere Simultaninvariante
bilden:}
{Another simultaneous invariant can be formed with the vector \T{v}\,:}
%
\Af{ \T{v} \, \T{v} \dsP \T[2]{H} \Tp}
%
\geen{Zur Bestimmung der Simultaninvarianten, die sowohl \T[2]{S}  als auch \T{v}
enthalten, gehen wir von $\T{v} \, \T{v} \dsP \T[2]{H}$ aus
und f"ugen an $\T{v} \, \T{v}$ von links oder rechts Skalarprodukte mit
\T[2]{S} oder $\T[2]{S}^2$ an; h"ohere Potenzen von \T[2]{S} brauchen wir
wegen der Cayley-Hamilton-Gleichung (\ref{3.89})
nicht zu ber"ucksichtigen. Auf diese Weise ergibt sich:}{
In order to form the simultaneous invariants with  both \T[2]{S} and \T{v}\TknI[]
we start from $\T{v} \, \T{v} \dsP \T[2]{H}$ and form scalar products with $\T{v} \, \T{v}$ and
\T[2]{S} or $\T[2]{S}^2$ on the right or on the left;
we can neglect higher powers of \T[2]{S}\TknI[] because of the Cayley--Hamilton theorem (\ref{3.89}).
This gives
}
%
\Af{
 \begin{array}{@{}>{\rule[-2ex]{0ex}{0ex}}l}
 ( \T[2]{S} \cdot \T{v} \, \T{v} ) \dsP \T[2]{H} \Tk
 ( \T{v} \, \T{v} \cdot \T[2]{S} ) \dsP \T[2]{H} \Tk
 ( \T[2]{S}^2 \cdot \T{v} \, \T{v} ) \dsP \T[2]{H} \Tk
 ( \T{v} \, \T{v} \cdot \T[2]{S}^2 ) \dsP \T[2]{H} \TknI[]\\
 ( \T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S} ) \dsP \T[2]{H} \Tk
 ( \T[2]{S}^2 \cdot \T{v} \, \T{v} \cdot \T[2]{S} ) \dsP \T[2]{H} \Tk
 ( \T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S}^2 ) \dsP \T[2]{H} \Tk
 ( \T[2]{S}^2 \cdot \T{v} \, \T{v} \cdot \T[2]{S}^2 ) \dsP \T[2]{H} \TpnI[]
 \end{array}}
%
\geen{Diese Simultanvarianten m"ussen wir noch hinsichtlich ihrer Unabh"angigkeit "uberpr"ufen:
$( \T[2]{S} \cdot \T{v} \, \T{v} ) \dsP \T[2]{H}$ und
$( \T{v} \, \T{v} \cdot \T[2]{S} ) \dsP \T[2]{H}$ sind offenkundig irreduzibel.
Die Skalarprodukte $\T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S}$,
$\T[2]{S}^2 \cdot \T{v} \, \T{v}$ und $\T{v} \, \T{v} \cdot \T[2]{S}^2$
sind dagegen "uber die verallgemeinerte Cayley-Hamilton-Gleichung
(\ref{cayley_hamilton_verallgemeinert})
verkn"upft, wenn wir dort beispielsweise
\Tf{\T[2]{a} = \T[2]{c} = \T[2]{S}} und \Tf{\T[2]{b} = \T{v} \,\T{v}}
setzen.  Deshalb sind von den drei Invarianten
$( \T[2]{S}^2 \cdot \T{v} \, \T{v} ) \dsP \T[2]{H} $,
$( \T{v} \, \T{v} \cdot \T[2]{S}^2 ) \dsP \T[2]{H} $ und
$( \T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S} ) \dsP \T[2]{H}$
nur zwei irreduzibel, wir w"ahlen f"ur die Funktionsbasis
$\T[2]{S}^2 \cdot \T{v} \, \T{v}$ und $\T{v} \, \T{v} \cdot \T[2]{S}^2$.
Die verbleibenden Invarianten
$( \T[2]{S}^2 \cdot \T{v} \, \T{v} \cdot \T[2]{S} ) \dsP \T[2]{H}$,
$( \T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S}^2 ) \dsP \T[2]{H}$  und
$( \T[2]{S}^2 \cdot \T{v} \, \T{v} \cdot \T[2]{S}^2 ) \dsP \T[2]{H}$
sind reduzibel, weil sich die Skalarprodukte
$\T[2]{S}^2 \cdot \T{v} \, \T{v} \cdot \T[2]{S}$,
$\T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S}^2$ und
$\T[2]{S}^2 \cdot \T{v} \, \T{v} \cdot \T[2]{S}^2$
mithilfe der verallgemeinerten Cayley-Hamilton-Gleichung
(\ref{cayley_hamilton_verallgemeinert}) durch
$\T[2]{\delta}\Tk \T[2]{S}\Tk \T[2]{S}^2\Tk \T{v}\, \T{v}$\TknI[]
$\T[2]{S} \cdot \T{v}\,\T{v}\Tk \T{v}\,\T{v} \cdot \T[2]{S}$\TknI[]
$\T[2]{S}^2 \cdot \T{v}\,\T{v}\Tk \T{v}\,\T{v} \cdot \T[2]{S}^2$
ausdr"ucken lassen.}{
It remains to check
if these simultaneous invariants are irreducible. Clearly, \Lb
$( \T[2]{S} \cdot \T{v} \, \T{v} ) \dsP \T[2]{H}$ and
$( \T{v} \, \T{v} \cdot \T[2]{S} ) \dsP \T[2]{H}$ are irreducible.
However, the scalar products $\T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S}$\TknI[]
$\T[2]{S}^2 \cdot \T{v} \, \T{v}$\TknI[] and $\T{v} \, \T{v} \cdot \T[2]{S}^2$
are linked via the generalized Cayley--Hamilton theorem
(\ref{cayley_hamilton_verallgemeinert}), for example, if we  set
\Tf{\T[2]{a} = \T[2]{c} = \T[2]{S}} and \Tf{\T[2]{b} = \T{v} \,\T{v}}.
Thus, from the three invariants
$( \T[2]{S}^2 \cdot \T{v} \, \T{v} ) \dsP \T[2]{H} $,
$( \T{v} \, \T{v} \cdot \T[2]{S}^2 ) \dsP \T[2]{H} $, and
$( \T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S} ) \dsP \T[2]{H}$
only two are irreducible, and we choose
$\T[2]{S}^2 \cdot \T{v} \, \T{v}$ and $\T{v} \, \T{v} \cdot \T[2]{S}^2$ for the function basis.
The remaining invariants \Lb
$( \T[2]{S}^2 \cdot \T{v} \, \T{v} \cdot \T[2]{S} ) \dsP \T[2]{H}$\TknI[]
$( \T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S}^2 ) \dsP \T[2]{H}$\TknI[] and
$( \T[2]{S}^2 \cdot \T{v} \, \T{v} \cdot \T[2]{S}^2 ) \dsP \T[2]{H}$
are reducible, since, according to\break the generalized Cayley--Hamilton theorem
(\ref{cayley_hamilton_verallgemeinert}), the scalar products
$\T[2]{S}^2 \cdot \T{v} \, \T{v} \cdot \T[2]{S}$,
$\T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S}^2$, and
$\T[2]{S}^2 \cdot \T{v} \, \T{v} \cdot \T[2]{S}^2$
can be written in terms of
$\T[2]{\delta}\Tk \T[2]{S}\Tk \T[2]{S}^2\Tk \T{v}\, \T{v}$\TknI[]
$\T[2]{S} \cdot \T{v}\,\T{v}\Tk \T{v}\,\T{v} \cdot \T[2]{S}$\TknI[]
$\T[2]{S}^2 \cdot \T{v}\,\T{v}\Tk \T{v}\,\T{v} \cdot \T[2]{S}^2$.
}

\geen{Es gibt also insgesamt acht Generatoren f"ur die Funktion \T[2]{f}, sodass die
Darstellung f"ur den Tensor \T[2]{T} lautet:}{
Hence the function \T[2]{f} has eight generators,
and we can represent the tensor \T[2]{T} as}
%
\Af{
 \T[2]{T} = k_1 \: \T[2]{\delta} + k_2 \: \T[2]{S} + k_3 \: \T[2]{S}^2
         + k_4 \: \T{v} \, \T{v}
         + k_5 \: \T[2]{S} \cdot \T{v} \, \T{v}
         + k_6 \: \T{v} \, \T{v} \cdot \T[2]{S}
         + k_7 \: \T[2]{S}^2 \cdot \T{v} \, \T{v}
         + k_8 \: \T{v} \, \T{v} \cdot \T[2]{S}^2 \Tp}
%
\geen{Die Koeffizienten $k_1\TknI \ldots\Tk k_8$ sind dabei wie in
Abschnitt~\ref{5.4.3} Nr.\,3 skalarwertige Funktionen
der Invarianten von \T[2]{S} und \T{v}:}{
The coefficients $k_1\TknI \ldots\Tk k_8$ are, as in Section~\ref{5.4.3}, No.\,3, scalar-valued functions
of the invariants of \T[2]{S} and \T{v}\,, i.\,e.
}
%
\Af{ k_i = f( \tro{\T[2]{S}} \Tk \tro{\T[2]{S}^2} \Tk \tro{\T[2]{S}^3} \Tk
            \T{v} \cdot \T{v} \Tk
            \T{v} \cdot \T[2]{S} \cdot \T{v} \Tk \T{v} \cdot \T[2]{S}^2 \cdot \T{v} ) \TpnI[]}
%
\geen{Anders als in Nr.\,2 folgt aus der Symmetrie von \T[2]{S} nicht mehr
zwangsl"aufig die Symmetrie von \T[2]{T}, das ist nur der Fall,
wenn zus"atzlich \Tf{k_5 = k_6} und \Tf{k_7 = k_8} gilt.
Wenn wir dagegen wissen, dass \T[2]{T} symmetrisch ist, l"asst sich
die Darstellung f"ur \T[2]{T} auch in der Form}{
In contrast to No.\,2,
here we cannot conclude from the symmetry of \T[2]{S}
that \T[2]{T} is also symmetric.
This is only true if \Tf{k_5 = k_6} and \Tf{k_7 = k_8\TpnI[]}
But if \T[2]{T} is symmetric,
then we can represent \T[2]{T} also in the form
}
%
\Af{ \T[2]{T} = k^\ast_1 \: \T[2]{\delta} + k^\ast_2 \: \T[2]{S} + k^\ast_3 \: \T[2]{S}^2
         + k^\ast_4 \: \T{v} \, \T{v}
         + k^\ast_5 \,
           \left(  \T[2]{S} \cdot \T{v} \, \T{v}
                 + \T{v} \, \T{v} \cdot \T[2]{S} \right)
         + k^\ast_6 \: \T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S}\Tp}
%
\geen{\index{Tensorfunktion!tensorwertige@, tensorwertige|)}%
\index{tensorwertige Funktion|)}%
angeben. $\T[2]{S}^2 \cdot \T{v} \, \T{v}$ und $\T{v} \, \T{v} \cdot \T[2]{S}^2$
k"onnen bei symmetrischem \T[2]{T} nur als Summe eingehen,
und mithilfe der verallgemeinerten Cayley-Hamilton-Gleichung
(\ref{cayley_hamilton_verallgemeinert})
l"asst sich diese Summe durch den Generator
$\T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S}$
ersetzen, der von vornherein symmetrisch ist.
Die Koeffizienten $k^\ast_1\TknI \ldots\Tk k^\ast_6$ sind dabei wie zuvor
skalarwertige Funktionen der Invarianten von \T[2]{S} und \T{v}.}{
\index{tensor function!tensor-valued@, tensor-valued|)}%
\index{tensor-valued function|)}%
If \T[2]{T} is symmetric, then $\T[2]{S}^2 \cdot \T{v} \, \T{v}$ and $\T{v} \, \T{v} \cdot \T[2]{S}^2$
can only appear as a sum, and according to the generalized Cayley--Hamilton theorem (\ref{cayley_hamilton_verallgemeinert}),
we can replace this sum by the generator $\T[2]{S} \cdot \T{v} \, \T{v} \cdot \T[2]{S}$\TknI[]
which is symmetric from the outset.
The coefficients $k^\ast_1\TknI \ldots\Tk k^\ast_6$ are again scalar-valued functions of the invariants of \T[2]{S} and \T{v}.
}

\begin{problem}
\label{U5.6}
\mbox{}

\noindent
\geen{Man bestimme die Darstellung eines polaren Tensors \Uf{\T[2]{T}}
zweiter Stufe, der von einem polaren oder axialen Vektor~\Uf{\T{v}} abh"angt.}{
Find the representation of a polar second-order tensor \Uf{\T[2]{T}}
which depends on a polar vector or on an axial vector~\Uf{\T{v}}.
}
\end{problem}\vspace*{-12pt}

\subsection{\geen{Zusammenfassung}{Summary}}
\label{5.4.5}
\geen{\index{Tensorfunktion!vektorwertige@, vektorwertige}%
\index{Tensorfunktion!tensorwertige@, tensorwertige}%
\index{vektorwertige Funktion}%
\index{tensorwertige Funktion}%
Wir fassen die Ergebnisse des Abschnitts~\ref{Abschnitt-5.4} noch einmal in
Tabellenform zusammen. Dabei bezeichnet \T[2]{S} einen polaren symmetrischen
Tensor, \T[2]{A} einen polaren antimetrischen Tensor, \T{v} einen polaren
Vektor und \T{u} einen axialen Vektor.}{
\index{tensor function!vector-valued@, vector-valued}%
\index{tensor function!tensor-valued@, tensor-valued}%
\index{vector-valued function}%
\index{tensor-valued function}%
We summarize the results of Section~\ref{Abschnitt-5.4} in a table.
Here \T[2]{S} denotes a polar symmetric tensor, \T[2]{A}  a polar antimetric tensor,
\T{v} a polar vector, and \T{u} an axial vector.}

\begin{table}[h]
%\renewcommand{\arraystretch}{1.38}
\begin{tabular}{lll}%{@{}>{$}l<{$}>{$}l<{$}>{$}l<{$}}
\text{Argument} & \text{Function basis} &
\\ \midrule\starttabularbody
& \text{vector-valued functions} & \\
& \text{polar} & \text{axial}
\\ \hline
\T{v} & \T{v} &
\\
\T{u} & & \T{u}
\\
\T[2]{S} & \multicolumn{2}{c}{--}
\\
\T[2]{A} &  &  \T[3]{\epsilon} \dsP \T[2]{A} \rule[-2ex]{0ex}{0ex}
\\ \rule[-1.5ex]{0ex}{0ex}
$\T[2]{S}\Tk \T{v} $  & $\T{v}\Tk \T[2]{S} \cdot \T{v} \Tk \T[2]{S}^2 \cdot \T{v}$  &
\\ \hline
& \text{tensor-valued functions}& \\
& \text{polar} & \text{axial}
\\ \hline
\T{v} & $\T[2]{\delta}\Tk \T{v} \, \T{v}$ &  $\T[3]{\epsilon} \cdot \T{v}  $
\\
\T{u} & $\T[2]{\delta}\Tk \T{u} \, \T{u}\Tk \T[3]{\epsilon} \cdot \T{u}$ &
\\
\T[2]{S} & $\T[2]{\delta}\Tk \T[2]{S}\Tk \T[2]{S}^2 $&
\\
\T[2]{S}\Tk  \T{v} & $\T[2]{\delta}\Tk \T[2]{S}\Tk \T[2]{S}^2\Tk
                         \T{v} \, \T{v}\Tk
                         \T[2]{S} \cdot \T{v} \, \T{v}\Tk
                         \T{v} \, \T{v} \cdot \T[2]{S}\Tk
                         \T[2]{S}^2 \cdot \T{v} \, \T{v}\Tk
                         \T{v} \, \T{v} \cdot \T[2]{S}^2$ &   \\
\end{tabular}
\end{table}
\vfill\break
\section{\geen{Ber"ucksichtigung von Anisotropien}{Considering Anisotropy}}
\label{Abschnitt-5.5}

\ParNoo{1.}
\geen{\index{Anisotropie|(}%
Wir haben eine Tensorfunktion im letzten Abschnitt isotrop genannt,
wenn die Transformationskoeffizienten in den Invarianzbedingungen
(\ref{skalarfunktion}), (\ref{vektorfunktion}) und (\ref{tensorfunktion})
alle orthogonalen Transformationen umfassen.
Diese Festlegung ist jedoch nicht erforderlich; man kann genauso gut auch die
Menge der zul"assigen orthogonalen Transformationen
einschr"anken und beispielsweise nur Drehungen um eine feste Achse betrachten.
Solche "Uberlegungen sind wichtig in der Physik,
wenn man die Materialeigenschaften eines K"orpers genauer beschreiben will;
denn viele K"orper wie Kristalle oder moderne Verbundwerkstoffe
zeichnen sich durch eine Richtungsabh"angigkeit aus, d.\,h. sie reagieren bei
einer Drehung je nach Richtung der Drehachse unterschiedlich.
Es gibt dann sehr h"aufig Drehungen um bestimmte Achsen
und Winkel, bei denen die Reaktion des K"orpers gleich bleibt.
Solche Drehungen kann man dazu nutzen, um K"orper zu klassifizieren;
man spricht dann davon, dass der K"orper eine bestimmte Symmetrie besitzt
oder zu einer bestimmten Symmetriegruppe geh"ort.
\index{Symmetriegruppe}%
Mathematisch ist eine solche Symmetriegruppe
durch die Menge der orthogonalen Transformationen definiert,
bei denen sich das Verhalten des K"orpers nicht "andert.}{
\index{anisotropy|(}%
In the previous section, we called a tensor function isotropic
%\era{,}
if the transformation coefficients
in the invariance conditions (\ref{skalarfunktion}), (\ref{vektorfunktion}) and (\ref{tensorfunktion})
include all orthogonal transformations.
We could also consider only a subset of certain  permissible orthogonal transformations, e.\,g.\ only rotations about a fixed axis.
Such considerations are important in physics and material science, if the problem is to describe the properties of a material in more detail;
many materials, such as crystals and composite materials,
are characterized by a directional dependency, i.\,e.\
they behave differently under rotations,
depending on the direction of the axis of rotation.
In such cases,
often certain rotations about distinguished axes and angles of rotation exist,
where the behavior of these materials remains the same.
These rotations can be used to classify a material;
we also say that the material possesses
a certain symmetry or belongs to a certain symmetry group.
\index{symmetry group}%
Mathematically, such a symmetry group is defined as the set
of orthogonal transformations
under which the behavior of the material remains unchanged.
}

\ParNo{2.}
\geen{Die Invarianzbedingungen aus Abschnitt~\ref{5.4.1} lassen sich auch dann
auswerten, wenn nicht mehr alle orthogonalen Transformationen zugelassen sind.
Wir wollen auf die Einzelheiten nicht n"aher eingehen, grunds"atzlich gilt
jedoch, dass die Anzahl der Invarianten steigt, wenn man die Menge der
zul"assigen Transformationen einschr"ankt.  Ein Beispiel ist die Beschr"ankung
auf eigentlich orthogonale Transformationen, man spricht dann auch von
hemitropen Invarianten und hemitropen Tensorfunktionen.
\index{hemitrope Tensorfunktion}%
\index{Tensorfunktion!hemitrope@, hemitrope}%
Sie lassen sich auf "ahnliche Weise wie in den Abschnitten~\ref{Abschnitt-5.3}
und \ref{Abschnitt-5.4} ermitteln, nur muss man dann stets auch die
Simultaninvarianten mit dem $\varepsilon$-Tensor ber"ucksichtigen,
da bei eigentlich orthogonalen Transformationen die Unterscheidung von
polaren und axialen Tensoren "uberfl"ussig ist.
Ein anderes Beispiel sind Drehungen, die nur um eine bestimmte Achse erfolgen.
Wenn wir diese Achse als $z$-Achse eines kartesischen Koordinatensystems
w"ahlen, hat die Matrix der Transformationskoeffizienten nach
(\ref{3.69}) und Abschnitt~{3.13.4} die Form}{
The invariance conditions from Section~\ref{5.4.1} can also be used
%\era{,}
if only a subset of all orthogonal transformations is allowed.
Without further elaboration,
we only mention here that, in general, the number of the invariants
increases if the permissible transformations are restricted.
An example is the restriction to only proper orthogonal transformations.
Then we also speak of hemitropic invariants and hemitropic
tensor functions.
\index{hemitropic tensor function}%
\index{tensor function!hemitropic@, hemitropic}%
They are formed similarly as in
Sections~\ref{Abschnitt-5.3} and~\ref{Abschnitt-5.4},
but now we also have to take
the simultaneous invariants with the $\varepsilon$-tensor into account,
because for proper orthogonal transformations,
we do not need to distinguish between polar and axial tensors.
Another example are rotations only about a certain axis.
If we choose this axis as the $z$-axis of a Cartesian coordinate system,
then the matrix of the transformation coefficients has, according to (\ref{3.69}) and with
Section~\ref{3.13.4}, the form}
%
\Af{
 \alpha_{ij} =
 \left( \begin{array}{@{}rrr@{}}
    \cosp & -\sinp & 0 \\
    \sinp &  \cosp & 0 \\
    0 & 0 & 1
 \end{array} \right) \Tp}
%
\geen{Aus den Transformationsgleichungen (\ref{2.17})
folgt dann, dass die Koordinate $u_3$ eines Vektors und die Koordinate $T_{33}$
eines Tensors zweiter Stufe bei der Transformation unver"andert
bleiben und somit zu den Invarianten gez"ahlt werden m"ussen.}{
Then it follows from the transformation equations (\ref{2.17}) that the coordinate $u_3$ of a vector
and the coordinate $T_{33}$ of a second-order tensor remain unchanged under the transformation
and thus they have to be counted as invariants.
}

\ParNo{3.}
\geen{Alle Tensoren, die gegen"uber den Transformationen einer bestimmten
Symmetriegruppe invariant sind, bilden eine Anisotropieklasse.
Zur Erl"auterung betrachten wir drei Beispiele
in Zusammenhang mit Tensoren zweiter Stufe.}{
All tensors
which are invariant under the transformations of a certain symmetry group
form an anisotropy class.
We explain this by means of three examples with second-order tensors.
}

\geen{Die Anisotropieklasse der allgemeinen Anisotropie umfasst alle Tensoren;
ihre Symmetriegruppe enth"alt die identische Transformation
\Tf{ \alpha_{ij} = \delta_{ij}} und die Inversion
\Tf{ \alpha_{ij} = -\delta_{ij}\TknI[]}
da nur bei solchen Transformationen die Koordinaten unver"andert bleiben:}{
The anisotropy class of general anisotropy includes all tensors;
its symmetry group consists of the identical transformation\Tf{\alpha_{ij} = \delta_{ij}}
and the inversion \Lb \Tf{ \alpha_{ij} = -\delta_{ij}\Tk[]}
because only under these transformations the coordinates do not change. We have
}
%
\Af{
\Tilde{T}_{ij} = \alpha_{mi} \: \alpha_{nj} \: T_{mn}
                   = \delta_{mi} \: \delta_{nj} \: T_{mn}
                   = T_{ij} \TpnI }
%
\geen{\index{isotroper!Tensor@ Tensor}\index{Tensor!isotroper@, isotroper}%
Umgekehrt geh"oren zur Anisotropieklasse der Isotropie alle Tensoren,
deren Koordinaten gegen beliebige orthogonale Transformationen
invariant sind. Solche Tensoren haben wir bereits fr"uher als isotrop
bezeichnet, sie besitzen die Form}{
\index{isotropic!tensor@ tensor}%
\index{tensor!isotropic@, isotropic}%
On the other hand, the anisotropy class of isotropy includes  all tensors
whose coordinates are invariant under arbitrary orthogonal transformations.
We already introduced such tensors as isotropic tensors; they have the form
}
%
\Af{
\T[2]{T} = k \: \T[2]{\delta} \Tk}
%
\geen{denn f"ur die transformierten Koordinaten gilt mit der Orthogonalit"atsrelation
(\ref{2.6})}{
because for the transformed coordinates, we have, according to the orthogonality relation (\ref{2.6}),
}
%
\Af{
 \Tilde{T}_{ij}
 = \alpha_{mi} \: \alpha_{nj} \left( k \, \delta_{mn} \right)
 = k \: \alpha_{mi} \: \alpha_{mj}
 = k \: \delta_{ij} \Tp}
%
\geen{\index{Tensor!transversalisotroper@, transversalisotroper}
Als drittes Beispiel betrachten wir die Anisotropieklasse der
Transversalisotropie.\index{Transversalisotropie}
Die zugeh"orige Symmetriegruppe umfasst alle Drehungen bzw. Drehspiegelungen
mit einer festen Achse. Die allgemeine Form eines transversalisotropen
Tensors zweiter Stufe k"onnen wir aus Aufgabe~\ref{U5.6} "ubernehmen.
Ein transversalisotroper Tensor l"asst sich auf"|fassen als ein Tensor,
der nur von der Richtung \T{n} der Dreh- bzw. Drehspiegelungsachse
abh"angt: \Tf{ \T[2]{T} = \T[2]{f}( \T{n})\Tp[]}
Wir m"ussen also im Ergebnis von Aufgabe~\ref{U5.6} nur ber"ucksichtigen,
dass \T{n} ein (axialer) Einheitsvektor ist, und erhalten dann}{\index{tensor!transverse isotropic@, transverse isotropic}
As a third example,
we consider the anisotropy class of transverse isotropy.\index{transverse isotropy}
Its symmetry group includes all rotations
and rotary reflections with a fixed axis.
The general form of a transversely isotropic tensor of second order follows from Problem~\ref{U5.6}.
A~transversely isotropic tensor can be seen as a tensor
%\era{,}
which depends only on the direction \T{n}
of the axis of rotation or rotary reflection:
\Tf{ \T[2]{T} = \T[2]{f}( \T{n})\Tp[]}
Thus, it remains to ensure in the result to Problem~\ref{U5.6}
that \T{n} is an (axial) unit vector,
and we have
}
\begin{equation}
 \label{tensor_transversalisotrop}
 \T[2]{T} = \alpha \: \T[2]{\delta} + \beta \: \T{n} \, \T{n}
         + \gamma \: \T[3]{\varepsilon} \cdot \T{n} \Fp
\end{equation}
%
\geen{Wegen \Tf{ \T{n} \cdot \T{n} = 1} sind
$\alpha$, $\beta$, $\gamma$ hier anders als in Aufgabe~\ref{U5.6}
keine Funktionen, sondern beliebige Konstanten.}{
Since \Tf{ \T{n} \cdot \T{n} = 1\TknI[]}
here the $\alpha$, $\beta$, $\gamma$ are,
unlike in Problem~\ref{U5.6},
not functions, but arbitrary constants.
}

\geen{Wenn wir die $z$-Achse des kartesischen Koordinatensystems mit der Richtung
der Dreh- bzw. Drehspiegelungsachse zusammenfallen lassen,
also \Tf{ n_1 = n_2 = 0\Tk n_3\Lb = 1} w"ahlen,
hat \T[2]{T} die Koordinatenmatrix}{
If we choose the $z$-axis of the Cartesian coordinate system as the axis of rotation or rotary reflection, i.\,e.\  if
\Tf{ n_1 = n_2 = 0\Tk n_3 = 1\TknI[]} then \T[2]{T} has the coordinate matrix}
%
\Af{
 \begin{array}{@{}l!{=}l}
T_{ij} &
\begin{array}({@{}ccc@{}})
 \alpha & 0 & 0 \\
 0 & \alpha & 0 \\
 0 & 0 & \alpha
\end{array}
+
\begin{array}({@{}ccc@{}})
 0 & 0 & 0 \\
 0 & 0 & 0 \\
 0 & 0 & \beta
\end{array}
+
\begin{array}({@{}ccc@{}})
 0 & \gamma & 0 \\
 -\gamma & 0 & 0 \\
 0 & 0 & 0
\end{array}\\&\rule{0ex}{6ex}
\begin{array}({@{}ccc@{}})
 \alpha & \gamma & 0 \\
 -\gamma & \alpha & 0 \\
 0 & 0 & \alpha + \beta
\end{array}\Tp
\end{array}}
%
\geen{Durch Auswertung der Transformationsgleichungen kann man sich
leicht davon "uberzeugen, dass die Koordinaten von \T[2]{T}
unver"andert bleiben, wenn das Koordinatensystem um die
$z$-Achse gedreht wird:}{
It is easy to see that, if we evaluate the transformation equations, the
coordinates of \T[2]{T} remain unchanged under a rotation of the coordinate
system about the $z$-axis, i.\,e.\vadjust{\vfill\eject} we have}
%
\Af{
 \begin{array}{@{}l!{=}l}
  \Tilde{T}_{ij}
  & \alpha_{mi} \: \alpha_{nj} \: T_{mn}
  = \alpha_{im}^{\tT}  \, T_{mn} \: \alpha_{nj}\\
&\rule{0ex}{7ex}%
\begin{array}({@{}rrr@{}})
    \cosp & \sinp & 0 \\
   -\sinp & \cosp & 0 \\
    0 & 0 & 1
 \end{array}
\begin{array}({@{}ccc@{}})
   \alpha & \gamma & 0 \\
  -\gamma & \alpha & 0 \\
   0 & 0 & \alpha + \beta
 \end{array}
\begin{array}({@{}rrr@{}})
    \cosp & -\sinp & 0 \\
    \sinp &  \cosp & 0 \\
    0 & 0 & 1
 \end{array}\\
&\rule{0ex}{10ex}%
 \begin{array}({@{}ccc@{}})
   \begin{array}{@{}r@{}}
    \multicolumn{1}{@{}l@{}}{\alpha  \cosp} \\ {}- \gamma  \sinp
   \end{array}\rule[-3ex]{0em}{0ex} &
   \begin{array}{@{}r@{}}
    \multicolumn{1}{@{}l@{}}{\alpha  \sinp } \\ {}+ \gamma  \cosp
   \end{array} & 0 \\
   \begin{array}{@{}r@{}}
    \multicolumn{1}{@{}l@{}}{-\alpha \sinp } \\ {}- \gamma  \cosp
   \end{array}\rule[-3ex]{0em}{0ex} &
   \begin{array}{@{}r@{}}
     \multicolumn{1}{@{}l@{}}{\alpha  \cosp } \\ {}- \gamma  \sinp
   \end{array} & 0 \\
   0 & 0 & \alpha + \beta
 \end{array}
 \begin{array}({@{}rrr@{}})
    \cosp & -\sinp & 0 \\
    \sinp &  \cosp & 0 \\
    0 & 0 & 1
 \end{array}\\
&\rule{0ex}{10ex}%
\begin{array}({@{}ccc@{}})
    \begin{array}{@{}r@{}}
     \multicolumn{1}{@{}l@{}}{\alpha  \cosp[2] - \gamma  \sinp \, \cosp} \\
   {}+ \alpha  \sinp[2] + \gamma  \sinp \, \cosp
    \end{array}\rule[-3ex]{0em}{0ex} &
    \begin{array}{@{}r@{}}
   \multicolumn{1}{@{}l@{}}{- \alpha  \cosp \, \sinp + \gamma  \sinp[2]} \\
   {}+ \alpha  \cosp \sinp + \gamma  \cosp[2]
    \end{array}
    & 0 \\
    \begin{array}{@{}r@{}}
   \multicolumn{1}{@{}l@{}}{- \alpha  \cosp \, \sinp - \gamma  \cosp[2]} \\
   {}+ \alpha  \cosp \, \sinp - \gamma  \sinp[2]
    \end{array}\rule[-3ex]{0em}{0ex} &
    \begin{array}{c}
     \multicolumn{1}{@{}l@{}}{\alpha  \sinp[2] + \gamma  \sinp \, \cosp}  \\
   {}+ \alpha  \cosp[2] - \gamma  \sinp \, \cosp
    \end{array}
     & 0 \\
    0 & 0 & \alpha + \beta
 \end{array}\\
&\rule{0ex}{6ex}%
\begin{array}({@{}ccc@{}})
 \alpha & \gamma & 0 \\
 -\gamma & \alpha & 0 \\
 0 & 0 & \alpha + \beta
\end{array} \Tp
\end{array}}
\typeout{Monster-Matrizen: nicht visuell erkennbar}%
%
\geen{\index{symmetrischer (Anteil eines) Tensor(s)}%
\index{Tensor!symmetrischer@, symmetrischer}%
In der Klasse der transversalisotropen Tensoren sind einige spezielle Klassen
von Tensoren enthalten, die wir bereits fr"uher kennengelernt haben.
Wenn wir \Tf{\alpha\Lb = \cost\Tk \beta = \pm 1 - \cost }
und \Tf{ \gamma = - \sint } setzen, erhalten wir f"ur \T[2]{T} nach
(\ref{3.71}) bzw. (\ref{3.75}) die allgemeine Form eines orthogonalen Tensors
mit $\vartheta$ als Drehwinkel und \T{n} als Dreh- bzw. Drehspiegelungsachse.%
\index{orthogonaler!Tensor@ Tensor}\index{Tensor!orthogonaler@, orthogonaler}
Durch die Wahl von \Tf{\alpha = \beta = 0} wird \T[2]{T} antimetrisch, und
$\gamma \, \T{n}$ ist der zu \T[2]{T} geh"orende Vektor.%
\index{antimetrischer (Anteil eines) Tensor(s)}
\index{Tensor!antimetrischer@, antimetrischer}
Die Wahl von \Tf{ \gamma = 0 } f"uhrt auf einen symmetrischen Tensor,
und zwar auf einen solchen mit doppeltem Eigenwert $\alpha$ und einfachem
Eigenwert \Tf{\alpha + \beta\Tsk[]} \T{n} ist dann die zum einfachen
Eigenwert \Tf{\alpha + \beta} geh"orende Eigenrichtung.}{
\index{symmetric!tensor@ (part of a) tensor}%
\index{tensor!symmetric@, symmetric}%
The class of transversely isotropic tensors has some subclasses
of tensors which we have already seen earlier.
If we set \Tf{\alpha = \cost\Tk \beta = \pm 1 - \cost\Tk
\gamma = - \sint\TknI[]}
then we obtain for \T[2]{T},
according to (\ref{3.71}) and (\ref{3.75}),
the general form of an orthogonal tensor,
with the angle of rotation $\vartheta$ and the axis of rotation
or rotary reflection \T{n}.%
\index{orthogonal!tensor@ tensor}%
\index{tensor!orthogonal@, orthogonal}
If we set \Tf{\alpha = \beta = 0\TknI[]} then \T[2]{T} is antimetric and
$\gamma \, \T{n}$ is the corresponding vector of \T[2]{T}.%
\index{antimetric!(part of a) tensor}
\index{tensor!antimetric@, antimetric}
If we choose \Tf{ \gamma = 0 \TknI[]} then the tensor is symmetric
with an eigenvalue $\alpha$ of multiplicity two
and another eigenvalue \Tf{\alpha + \beta} of multiplicity one; \T{n} is the eigendirection corresponding to the  eigenvalue \Tf{\alpha + \beta} of multiplicity one.
}

\geen{Wir fassen das Ergebnis f"ur die behandelten Anisotropieklassen
von Tensoren zweiter Stufe noch einmal tabellarisch zusammen.
Bei den Anisotropieklassen w"achst die Menge der zugeh"origen
Tensoren \T[2]{T} von oben nach unten an, die Tensoren einer bestimmten
Anisotropieklasse sind immer in der nachfolgenden Anisotropieklasse enthalten.
Bei den Symmetriegruppen nimmt die Menge der zugeh"origen
orthogonalen Matrizen $\alpha_{ij}$ dagegen von unten nach oben zu,
die Matrizen einer Symmetriegruppe sind immer in der vorhergehenden
Symmetriegruppe enthalten.}{
We summarize the results of our discussion on anisotropy classes of second-order tensors in a table.
For the anisotropy classes,
the number of tensors \T[2]{T}\TknI[]
which are contained in the class,
increases from the first class to the last;
the tensors of a particular anisotropy class are always included
in the next anisotropy class.
For the symmetry groups, the number of
orthogonal matrices $\alpha_{ij}$
which are included in the class increases from the last class
to the first;
the matrices of a symmetry group are always contained in the previous symmetry group.}

\geen{
{\renewcommand{\arraystretch}{2}
\begin{tabular}{@{}l*{2}{|>{$}l<{$}}}
Anisotropieklasse & \text{allgemeiner~Tensor}\ \T[2]{T} & \text{Symmetriegruppe}\ \alpha_{ij} \\ \hline
Isotropie & k \, \T[2]{\delta} & \text{beliebig} \\
Transversalisotropie &
\alpha \, \T[2]{\delta} + \beta \, \T{n} \, \T{n}
         + \gamma \, \T[3]{\varepsilon} \cdot \T{n}
&
{\renewcommand{\arraystretch}{1.0}
 \begin{array}({@{}*{3}{>{\Ss}r}@{}})
    \cosp & -\sinp & 0 \\
    \sinp &  \cosp & 0 \\
    0 & 0 & 1
 \end{array}}\Tk \T{n} = \T{e}_z\\
allgemeine Anisotropie & \text{beliebig} & \pm \delta_{ij}
\end{tabular}}
}{}

%{\renewcommand{\arraystretch}{2}
\begin{table}[h]
\begin{tabular}{lll}%{@{}l*{2}{|>{$}l<{$}}}
Anisotropy class & \text{General~tensor}\ \T[2]{T} & \text{Symmetry group}\ $\alpha_{ij}$ \\
\midrule \starttabularbody
Isotropy & $k \, \T[2]{\delta} $& \text{arbitrary} \\
Transverse isotropy &
$\alpha \, \T[2]{\delta} + \beta \, \T{n} \, \T{n}
         + \gamma \, \T[3]{\varepsilon} \cdot \T{n} $
&
%{\renewcommand{\arraystretch}{1.0}
 $\begin{array}({*{3}{>{\Ss}r}})
    \cosp & -\sinp & 0 \\
    \sinp &  \cosp & 0 \\
    0 & 0 & 1
 \end{array}\Tk \T{n} = \T{e}_z$\\
General anisotropy & \text{arbitrary} & $\pm \delta_{ij}$  \\
\end{tabular}
\end{table}

\ParNo{4.}
\geen{Anisotropien lassen sich auch mithilfe isotroper Tensorfunktionen
ber"ucksichtigen.
Zur Erl"auterung betrachten wir die Span"-nungs"=Ver"-zer"-rungs"=Be"-zie"-hung
f"ur einen elastischen Festk"orper.
Als wir hierf"ur in Abschnitt~\ref{Abschnitt-5.1}  die Funktion
\Tf{\T[2]{T} = \T[2]{f}( \T[2]{D})}
zwischen dem symmetrischen Spannungstensor \T[2]{T}
und dem symmetrischen Verzerrungstensor \T[2]{D} notiert haben, sind wir
stillschweigend von einem isotropen Festk"orper ausgegangen, und nach
Abschnitt~\ref{5.4.4} Nr.\,2 lautet die Darstellung f"ur die Funktion \T[2]{f}:}{
Anisotropies can also be considered by isotropic tensor functions.
To explain this we consider the stress--strain relation for an elastic body.
When we introduced the function \Tf{\T[2]{T} = \T[2]{f}( \T[2]{D})} between the symmetric stress tensor \T[2]{T} and the symmetric strain tensor
\T[2]{D} in Section~\ref{Abschnitt-5.1}, we silently assumed an isotropic solid,
and, according to Section~\ref{5.4.4}, No.\,2,
the function \T[2]{f} has the following representation:
}
%
\Af{
\T[2]{T} = k_1 \, \T[2]{\delta} + k_2 \, \T[2]{D} + k_3 \, \T[2]{D}^2\Tk \quad
k_i = f( \tro{\T[2]{D}} \Tk \tro{\T[2]{D}^2} \Tk \tro{\T[2]{D}^3}) \Tp}
%
\geen{Wenn sich der Festk"orper dagegen transversalisotrop verh"alt,%
\index{Transversalisotropie} besitzt er eine ausgezeichnete Richtung \T{n},
die wir dann auch als Argument in die Funktion \T[2]{f} aufnehmen m"ussen,
d.\,h. wir suchen nach einer Darstellung f"ur
\Tf{\T[2]{T} = \T[2]{f}( \T[2]{D} \Tk \T{n})\Tp[]}
Das Ergebnis k"onnen wir aus Abschnitt~\ref{5.4.4} Nr.\,3 "ubernehmen,
wenn wir zus"atzlich die Symmetrie von \T[2]{T} ber"ucksichtigen
und beachten, dass \T{n} ein Einheitsvektor ist, also $\T{n}\cdot \T{n}$ nicht
zu den Invarianten geh"ort:}{
If, on the other hand, the solid is transversely isotropic,\index{transverse isotropy}
then it has a distinguished direction \T{n},
which we have to include in the argument list of the function \T[2]{f},
i.\,e.\ we are looking for a representation for
\Tf{\T[2]{T} = \T[2]{f}( \T[2]{D} \Tk \T{n})\Tp[]}
We can use the result from Section~\ref{5.4.4}, No.\,3,
if in addition we take into account that \T[2]{T} is symmetric
and  that \T{n} is a unit vector, i.\,e.\ that
$\T{n}\cdot \T{n}$ is no invariant, i.\,e.
}
%
\[%\begin{refequation}%[1]
\label{5.5a}%
 \begin{array}{@{}l}
 \T[2]{T} = k^\ast_1 \, \T[2]{\delta} + k^\ast_2 \, \T[2]{D} + k^\ast_3 \, \T[2]{D}^2
+ k^\ast_4 \, \T{n} \, \T{n} + k^\ast_5 ( \T[2]{D} \cdot \T{n} \, \T{n}\rule[-2ex]{0em}{0ex}
+ \T{n} \, \T{n} \cdot \T[2]{D} ) + k^\ast_6 \, \T[2]{D} \cdot \T{n} \, \T{n} \cdot \T[2]{D} \Tk\\
 k^\ast_i = f( \tro{\T[2]{D}} \Tk \tro{\T[2]{D}^2} \Tk \tro{\T[2]{D}^3} \Tk
            \T{n} \cdot \T[2]{D} \cdot \T{n} \Tk \T{n} \cdot \T[2]{D}^2 \cdot \T{n}) \Tp
 \end{array}
\tag{a}
\]%\end{refequation}%
%
\geen{Die Spannungs-Verzerrungs-Beziehung f"ur einen isotropen Festk"orper ist hierin
als Spezialfall enthalten, wenn \Tf{k^\ast_4 = k^\ast_5 = k^\ast_6 = 0} ist und
$k^\ast_1\TknI$ $k^\ast_2$ und $k^\ast_3$ nicht von \T{n} abh"angen.}{
This expression includes the stress--strain relation for an isotropic
solid as a special case, if we set  \Tf{k^\ast_4 = k^\ast_5 = k^\ast_6 = 0}
and if $k^\ast_1\TknI$ $k^\ast_2$, and $k^\ast_3$ do not depend on \T{n}.}

\geen{Wenn die Verzerrungen klein sind, kann man (\ref{5.5a}) durch einen linearen
Zusammenhang der Koordinaten von \T[2]{T} und \T[2]{D} approximieren.
Dann ist \Tf{k^\ast_3 = k^\ast_6 = 0\Tk k^\ast_2 = \alpha} und
\Tf{ k^\ast_5 = \beta } sind konstant, und $k^\ast_1$ und $k^\ast_4$ sind
lineare Funktionen der in \T[2]{D} linearen
Invarianten $\tro{\T[2]{D}}$ und $\T{n} \cdot \T[2]{D} \cdot \T{n}$:}{
For small strains we can approximate (\ref{5.5a})
by a linear relation between the coordinates of \T[2]{T} and  \T[2]{D}.
Then \Tf{k^\ast_3 = k^\ast_6 = 0\Tk k^\ast_2 = \alpha\TknI[]} and
\Tf{ k^\ast_5 = \beta} are constant, and $k^\ast_1$ and $k^\ast_4$
are linear functions of the invariants $\tro{\T[2]{D}}$ and
$\T{n} \cdot \T[2]{D} \cdot \T{n}$ which are linear in~\T[2]{D}, so we have
}
%
\Af{
 k^\ast_1 = \kappa \, \tro{\T[2]{D}} + \lambda \, \T{n} \cdot \T[2]{D} \cdot \T{n}\Tk \
 k^\ast_4 = \mu \, \tro{\T[2]{D}} + \nu \, \T{n} \cdot \T[2]{D} \cdot \T{n} \Tp}
%
\geen{In der Koordinatenschreibweise vereinfacht sich (\ref{5.5a}) dadurch zu}{
Then (\ref{5.5a}) simplifies in index notation to
}
%
\Af{
 \begin{array}{@{}l@{}c@{}l}
 T_{ij}& {}= {}&\left( \kappa \, D_{pp} + \lambda \, n_p \: D_{pq} \: n_q \right) \delta_{ij}
        + \left( \mu \, D_{pp} + \nu \, n_p \: D_{pq} \: n_q \right) n_i \: n_j\\
&& {}+ \alpha \, D_{ij} + \beta \, \left( D_{ip} \: n_p \: n_j + n_i \: n_p \: D_{pj} \right) \Tp
 \end{array}}
%
\geen{Durch Einf"uhrung geeigneter Kronecker-Symbole kann man $D_{kl}$ ausklammern:}{
If we introduce appropriate Kronecker symbols, we can factor out $D_{kl}$ as follows:}
%
\Af{
 \begin{array}{@{}l@{}c@{}>{\rule[-2ex]{0ex}{0ex}}l}
 T_{ij}&{} = {}& \left( \kappa \, \delta_{pk} \: \delta_{pl} \: D_{kl}
+ \lambda \, n_p \: \delta_{pk} \: D_{kl} \: \delta_{lq} \: n_q \right) \delta_{ij}\\
&&        {}+\left( \mu \, \delta_{pk} \: \delta_{pl} \: D_{kl}
               + \nu \, n_p \: \delta_{pk} \: D_{kl} \: \delta_{lq} \: n_q \right) n_i \: n_j
        + \alpha \, \delta_{ik} \: \delta_{jl} \: D_{kl}\\
&&
        {}+ \beta \, \left( \delta_{ik} \: D_{kl} \: \delta_{lp} \: n_p \: n_j
                        + n_i \: n_p \: \delta_{pk} \: D_{kl} \: \delta_{lj} \right)\\
&=&
\bigl\{ \kappa \, \delta_{ij}  \: \delta_{kl}
               + \lambda \, \delta_{ij} \: n_k \: n_l
               + \mu \, n_i  \: n_j \: \delta_{kl}
               + \nu \, n_i \: n_j \, n_k \: n_l
               + \alpha \, \delta_{ik} \: \delta_{jl}\\
&& {}+ \beta \, \left( \delta_{ik} \: n_j \: n_l + n_i \: n_k \: \delta_{jl} \right)
           \bigr\} D_{kl} \Tp
 \end{array}}
%
\geen{Da sowohl $T_{ij}$ als auch $D_{kl}$ symmetrisch sind,
k"onnen wir hierf"ur schreiben}{
Since both $T_{ij} $ and $D_{kl}$ are symmetric, we can write
}
%
\Af{
 \begin{array}{*{2}{@{}l}}
 T_{ij} ={} &\bigl\{ \kappa \, \delta_{ij}  \: \delta_{kl} \rule[-2ex]{0em}{0ex}
               + \lambda \, \delta_{ij} \: n_k \: n_l
               + \mu \, n_i \: n_j \: \delta_{kl}
               + \nu \, n_i \: n_j \: n_k \: n_l
               + {\textstyle \frac{1}{2}} \, \alpha
                 \left( \delta_{ik} \: \delta_{jl} + \delta_{il} \: \delta_{jk} \right)\\
&               {}+ {\textstyle \frac{1}{2}} \, \beta
                   \left( \delta_{ik} \: n_j \: n_l + n_i \: n_k \: \delta_{jl}
                        + \delta_{il} \: n_j \: n_k + n_i \: n_l \: \delta_{jk}
                              \right)  \bigr\} D_{kl} \Tp
 \end{array}}
%
\geen{Der Ausdruck in den geschweiften Klammern l"asst sich als Koordinaten eines
vierstufigen Elastizit"atstensors \T[4]{E} mit den Symmetrieeigenschaften}{
The expression in the curly brackets can be interpreted as the coordinates of a fourth-order elasticity
tensor \T[4]{E} with the symmetry properties
}
%
\Af{
E_{ijkl} = E_{jikl} = E_{ijlk} \Fk}
%
\geen{interpretieren. Wir erhalten damit abgek"urzt}{so we can shorten this to}
%
\Af{
 T_{ij} = E_{ijkl} \: D_{kl}  \Tp}
%
\geen{\index{Anisotropie|)}
Die Konstanten $\alpha\Tk \beta\Tk \kappa\Tk \lambda\Tk \mu$ und $\nu$
m"ussen (eventuell unter weiteren physikalischen Annahmen) experimentell
bestimmt werden.}{
\index{anisotropy|)}%
The constants $\alpha\Tk \beta\Tk \kappa\Tk \lambda\Tk \mu$, and $\nu$
must be determined from experiments
(possibly by making further physical assumptions).
}





\end{document}
